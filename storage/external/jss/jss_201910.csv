title,abstract
Research article - Understanding the order of agile practice introduction: Comparing agile maturity models and practitioners’ experience,"AbstractContext: Agile maturity models (AMMs) suggest that agile practices are introduced in a certain order. However, whether the order of agile practice introduction as suggested in the AMMs is relevant in industry has not been evaluated in an empirical study.Objectives: In this study, we want to investigate: (1) order of agile practice introduction mentioned in AMMs, (2) order of introducing agile practices in industry, and (3) similarities and differences between (1) and (2).Methods: We conducted a literature survey to identify strategies proposed by the AMMs. We then compared the AMMs’ suggestions to the strategies used by practitioners, which we elicited from a survey and a series of interviews from an earlier study.Results: The literature survey revealed 12 AMMs which provide explicit mappings of agile practices to maturity levels. These mappings showed little agreement on when practices should be introduced. Comparison of the AMMs’ suggestions and the empirical study revealed that the guidance suggested by AMMs are not aligned with industry practice.Conclusion: Currently, AMMs do not provide sufficient information to guide agile adoption in industry. Our results suggest that there might be no universal strategy for agile adoption that works better than others."
Research article - Software developer productivity loss due to technical debt—A replication and extension study examining developers’ development work,"AbstractSoftware companies need to deliver customer value continuously, both from a short- and long-term perspective. However, software development can be impeded by technical debt (TD). Although significant theoretical work has been undertaken to describe the negative effects of TD, little empirical evidence exists on how much wasted time and additional activities TD causes. The study aims to explore the consequences of TD in terms of wastage of development time. This study investigates on which activities this wasted time is spent and whether different TD types impact the wasted time differently. This study reports the results of a longitudinal study surveying 43 developers and including16 interviews followed by validation by an additional study using a different and independent dataset and focused on replicating the findings addressing the findings. The analysis of the reported wasted time revealed that developers waste, on average, 23% of their time due to TD and that developers are frequently forced to introduce new TD. The most common activity on which additional time is spent is performing additional testing. The study provides evidence that TD hinders developers by causing an excessive waste of working time, where the wasted time negatively affects productivity."
Research article - Aligning software engineering education with industrial needs: A meta-analysis,"AbstractContextAccording to various reports, many software engineering (SE) graduates often face difficulties when beginning their careers, which is mainly due to misalignment of the skills learned in university education with what is needed in the software industry.ObjectiveOur objective is to perform a meta-analysis to aggregate the results of the studies published in this area to provide a consolidated view on how to align SE education with industry needs, to identify the most important skills and also existing knowledge gaps.MethodTo synthesize the body of knowledge, we performed a systematic literature review (SLR), in which we systematically selected a pool of 35 studies and then conducted a meta-analysis using data extracted from those studies.ResultsVia a meta-analysis and using data from 13 countries and over 4,000 data points, highlights of the SLR include: (1) software requirements, design, and testing are the most important skills; and (2) the greatest knowledge gaps are in configuration management, SE models and methods, SE process, design (and architecture), as well as in testing.ConclusionThis paper provides implications for both educators and hiring managers by listing the most important SE skills and the knowledge gaps in the industry."
Research article - Summarizing vulnerabilities’ descriptions to support experts during vulnerability assessment activities,"AbstractVulnerabilities affecting software and systems have to be promptly fixed, to prevent violations to integrity, availability and confidentiality policies of targeted organizations. Once a vulnerability is discovered, it is published on the Common Vulnerabilities and Exposures (CVE) database, freely available on the web. However, vulnerabilities are described using natural language, which makes them hard to be automatically interpreted by machines. As a consequence, vulnerability assessment activities tend to be time-consuming and imprecise, as the assessors must manually read the majority of the vulnerabilities concerning the perimeter to be protected, to make a decision on which vulnerabilities have the highest priority for patching. In this paper we present CVErizer, an approach able to automatically generate summaries of daily posted vulnerabilities and categorize them according to a taxonomy modeled for industry. We empirically assess the classification capabilities of the approach on a set of 3369 pre-labeled CVE records and perform an end-to-end evaluation of CVErizer summaries involving 15 cybersecurity master students and 4 professional security experts. Our study demonstrates the high performance of the proposed approach in correctly extracting and classifying information from CVE descriptions. Summaries are also considered highly useful for helping analysts during the vulnerability assessment processes."
Research article - Foundations for measuring IT-outsourcing success and failure,"AbstractWe implemented five easy-to-complete questionnaires in Excel, which could serve as early warning signals for practitioners interested in the odds of their IT-outsourcing deals and could serve to redirect their course when still possible. The questionnaires are based on our earlier published longitudinal, observational study on 30 representative ITO-deals in the Netherlands, of which we know whether they failed or not. Our questionnaires predicted their outcome correctly. To help redirect the course of a dubious deal, we developed a questionnaire estimating the odds in relation to boosting strongly significant critical success determinants. Another questionnaire guides practitioners how to further improve on less critical factors. There are no specific reasons that limit our results to the Dutch situation, which makes it promising, therefore, to apply the Excel as an aid in improving ITO deals in other contexts."
Research article - Evaluating and empirically improving the visual syntax of use case diagrams,"AbstractUse case modeling is a forefront technique to specify functional requirements of a system. Many research works related to use case modeling have been devoted to improving various aspects of use case modeling and its utilization in software development processes. One key aspect of use case models that has thus far been overlooked by the research community is the visual perception of use case diagrams by its readers. Any model is used transfer a mental idea by a modeler to a model reader. Even if a use case diagram is constructed flawlessly, if it is misread or misinterpreted by its reader then the intrinsic purpose of modeling has failed. This paper provides a two-fold contribution. Firstly, this paper presents an evaluation of the cognitive effectiveness of use case diagrams notation. The evaluation is based on theory principles and empirical evidence mainly from the cognitive science field. Secondly, it provides empirically validated improvements to the use case diagram notation that enhances its cognitive effectiveness. Empirical validation of the improvements is drawn by conducting an industrial survey using business analyst professionals. Empirical validation is also drawn by conducting an experiment using software engineering professionals as subjects."
Research article - Do concern mining tools really help requirements analysts? An empirical study of the vetting process,"AbstractSoftware requirements are often described in natural language because they are useful to communicate and validate. Due to their focus on particular facets of a system, this kind of specifications tends to keep relevant concerns (also known as early aspects) from the analysts’ view. These concerns are known as crosscutting concerns because they appear scattered among documents. Concern mining tools can help analysts to uncover concerns latent in the text and bring them to their attention. Nonetheless, analysts are responsible for vetting tool-generated solutions, because the detection of concerns is currently far from perfect. In this article, we empirically investigate the role of analysts in the concern vetting process, which has been little studied in the literature. In particular, we report on the behavior and performance of 55 subjects in three case-studies working with solutions produced by two different tools, assessed in terms of binary classification measures. We discovered that analysts can improve “bad” solutions to a great extent, but performed significantly better with “good” solutions. We also noticed that the vetting time is not a decisive factor to their final accuracy. Finally, we observed that subjects working with solutions substantially different from those of existing tools (better recall) can also achieve a good performance."
Research article - Efficient anytime algorithms to solve the bi-objective Next Release Problem,"AbstractThe Next Release Problem consists in selecting a subset of requirements to develop in the next release of a software product. The selection should be done in a way that maximizes the satisfaction of the stakeholders while the development cost is minimized and the constraints of the requirements are fulfilled. Recent works have solved the problem using exact methods based on Integer Linear Programming. In practice, there is no need to compute all the efficient solutions of the problem; a well-spread set in the objective space is more convenient for the decision maker. The exact methods used in the past to find the complete Pareto front explore the objective space in a lexicographic order or use a weighted sum of the objectives to solve a single-objective problem, finding only supported solutions. In this work, we propose five new methods that maintain a well-spread set of solutions at any time during the search, so that the decision maker can stop the algorithm when a large enough set of solutions is found. The methods are called anytime due to this feature. They find both supported and non-supported solutions, and can complete the whole Pareto front if the time provided is long enough."
Research article - M3 - A hybrid measurement-modeling approach for CPU-bound applications on cross-platform architectures,"AbstractPredicting performance of CPU intensive applications for a target platform is of significant importance to IT industries. However, the target hardware platform for which we want to predict the performance is often different from the testbed on which the application performance measurements are done, and may not be unavailable for deployment for various practical reasons. This paper presents M3, a Measure-Measure-Model method, which uses a pipeline of three steps to address this problem. The methodology starts with measuring CPU service demands of the application on the testbed. Then, it builds clones that mimic the application code in terms of the type of operations, the number and size of network calls with external servers and API calls made at different layers of the technology stack. The clones are simple and easy to deploy, yet demonstrate the same speedup factor between the source and the target as the original application. The clones are then deployed on the testbed and on the target to estimate the application CPU service demand under light load generation. In the final step, this estimated CPU service demand is fed into specific performance modeling tools that are capable of predicting application performance on the target under arbitrary higher workload. Predictions made using this approach are validated against direct measurements made on five applications in Java and PHP, and on a number of combinations of testbed and target platforms (Intel and AMD servers) and the prediction error is always less than 20%."
Research article - Evolution of statistical analysis in empirical software engineering research: Current state and steps forward,"AbstractSoftware engineering research is evolving and papers are increasingly based on empirical data from a multitude of sources, using statistical tests to determine if and to what degree empirical evidence supports their hypotheses. To investigate the practices and trends of statistical analysis in empirical software engineering (ESE), this paper presents a review of a large pool of papers from top-ranked software engineering journals. First, we manually reviewed 161 papers and in the second phase of our method, we conducted a more extensive semi-automatic classification of papers spanning the years 2001–2015 and 5196 papers.Results from both review steps was used to: i) identify and analyse the predominant practices in ESE (e.g., using t-test or ANOVA), as well as relevant trends in usage of specific statistical methods (e.g., nonparametric tests and effect size measures) and, ii) develop a conceptual model for a statistical analysis workflow with suggestions on how to apply different statistical methods as well as guidelines to avoid pitfalls.Lastly, we confirm existing claims that current ESE practices lack a standard to report practical significance of results. We illustrate how practical significance can be discussed in terms of both the statistical analysis and in the practitioner’s context."
Research article - Reproducing performance bug reports in server applications: The researchers’ experiences,"AbstractPerformance is one of the key aspects of non-functional qualities as performance bugs can cause significant performance degradation and lead to poor user experiences. While bug reports are intended to help developers to understand and fix bugs, they are also extensively used by researchers for finding benchmarks to evaluate their testing and debugging approaches. Although researchers spend a considerable amount of time and effort in finding usable performance bugs from bug repositories, they often get only a few. Reproducing performance bugs is difficult even for performance bugs that are confirmed by developers with domain knowledge. The amount of information disclosed in a bug report may not always be sufficient to reproduce the performance bug for researchers, and thus hinders the usability of bug repository as the resource for finding benchmarks. In this paper, we study the characteristics of confirmed performance bugs by reproducing them using only informations available from the bug report to examine the challenges of bug reproduction from the perspective of researchers. We spent more than 800 h over the course of six months to study and to try to reproduce 93 confirmed performance bugs, which are randomly sampled from two large-scale open-source server applications. We (1) studied the characteristics of the reproduced performance bug reports; (2) summarized the causes of failed-to-reproduce performance bug reports from the perspective of researchers by reproducing bugs that have been solved in bug reports; (3) shared our experience on suggesting workarounds to improve the bug reproduction success rate; (4) delivered a virtual machine image that contains a set of 17 ready-to-execute performance bug benchmarks. The findings of our study provide guidance and a set of suggestions to help researchers to understand, evaluate, and successfully replicate performance bugs."
Research article - Modeling stack overflow tags and topics as a hierarchy of concepts,"AbstractDevelopers rely on online Q&A forums to look up technical solutions, to pose questions on implementation problems, and to enhance their community profile by contributing answers. Many popular developer communication platforms, such as the Stack Overflow Q&A forum, require threads of discussion to be tagged by their contributors for easier lookup in both asking and answering questions. In this paper, we propose to leverage Stack Overflow’s tags to create a hierarchical organization of concepts discussed on this platform. The resulting concept hierarchy couples tags with a model of their relevancy to prospective questions and answers. For this purpose, we configure and apply a supervised multi-label hierarchical topic model to Stack Overflow questions and demonstrate the quality of the model in several ways: by identifying tag synonyms, by tagging previously unseen Stack Overflow posts, and by exploring how the hierarchy could aid exploratory searches of the corpus. The results suggest that when traversing the inferred hierarchical concept model of Stack Overflow the questions become more specific as one explores down the hierarchy and more diverse as one jumps to different branches. The results also indicate that the model is an improvement over the baseline for the detection of tag synonyms and that the model could enhance existing ensemble methods for suggesting tags for new questions. The paper indicates that the concept hierarchy as a modeling imperative can create a useful representation of the Stack Overflow corpus. This hierarchy can be in turn integrated into development tools which rely on information retrieval and natural language processing, and thereby help developers more efficiently navigate crowd-sourced online documentation."
Research article - Scented since the beginning: On the diffuseness of test smells in automatically generated test code,"AbstractSoftware testing represents a key software engineering practice to ensure source code quality and reliability. To support developers in this activity and reduce testing effort, several automated unit test generation tools have been proposed. Most of these approaches have the main goal of covering as more branches as possible. While these approaches have good performance, little is still known on the maintainability of the test code they produce, i.e.,whether the generated tests have a good code quality and if they do not possibly introduce issues threatening their effectiveness. To bridge this gap, in this paper we study to what extent existing automated test case generation tools produce potentially problematic test code. We consider seven test smells, i.e.,suboptimal design choices applied by programmers during the development of test cases, as measure of code quality of the generated tests, and evaluate their diffuseness in the unit test classes automatically generated by three state-of-the-art tools such as Randoop, JTExpert, and Evosuite. Moreover, we investigate whether there are characteristics of test and production code influencing the generation of smelly tests. Our study shows that all the considered tools tend to generate a high quantity of two specific test smell types, i.e.,Assertion Roulette and Eager Test, which are those that previous studies showed to negatively impact the reliability of production code. We also discover that test size is correlated with the generation of smelly tests. Based on our findings, we argue that more effective automated generation algorithms that explicitly take into account test code quality should be further investigated and devised."
Research article - Augmenting Java method comments generation with context information based on neural networks,"AbstractCode comments are crucial to program comprehension. In this paper, we propose a novel approach ContextCC to automatically generate concise comments for Java methods based on neural networks, leveraging techniques of program analysis and natural language processing. Firstly, ContextCC employs program analysis techniques, especially abstract syntax tree parsing, to extract context information including methods and their dependency. Secondly, it filters code and comments out of the context information to build up a high-quality data set based on a set of pre-defined templates and rules. Finally, ContextCC trains a code comment generation model based on recurrent neural networks. Experiments are conducted on Java projects crawled from GitHub. We show empirically that the performance of ContextCC is superior to state-of-the-art baseline methods."
Review article - Towards mixed criticality task scheduling in cyber physical systems: Challenges and perspectives,"AbstractCyber physical systems (CPSs) are a fast-evolving technology based on a strong synergy between heterogeneous sensing, networking, computation and control modules. When coping with critical applications that require real-time performance and autonomous operation in uncertain conditions, the design of such complex systems is still facing significant difficulties. A particular challenge in this respect derives from the software intensive nature of these systems - the need to develop flexible and specifically tailored task scheduling techniques. In our view, an appropriate line of thinking is to take advantage of mixed criticality concepts following the lessons learned from avionics and automotive domains, where complexity, safety, determinism and real-time constraints are extreme. From this perspective, our work aims at facilitating the integration of mixed criticality systems-based strategy in cyber physical systems by identifying the particularities of the latter and their influence on scheduling mechanisms, by describing the standard mixed-criticality task model in the cyber physical systems context, and by analyzing and proposing the most suitable scheduling algorithms to be implemented in cyber physical systems. Moreover, the perspectives on future developments in this area are discussed, as new horizons in research arise with the integration of mixed criticality concepts in the cyber physical systems context."
Research article - Towards complex product line variability modelling: Mining relationships from non-boolean descriptions,"AbstractSoftware product line engineering relies on systematic reuse and mass customisation to reduce the development time and cost of a software system family. The extractive adoption of a product line requires to extract variability information from the description of a collection of existing software systems to model their variability. With the increasing complexity of software systems, software product line engineering faces new challenges including variability extraction and modelling. Extensions of existing boolean variability models, such as multi-valued attributes or UML-like cardinalities, were proposed to enhance their expressiveness and support variability modelling in complex product lines. In this paper, we propose an approach to extract complex variability information, i.e., involving features as well as multi-valued attributes and cardinalities, in the form of logical relationships. This approach is based on Formal Concept Analysis and Pattern Structures, two mathematical frameworks for knowledge discovery that bring theoretical foundations to complex variability extraction algorithms. We present an application on product comparison matrices representing complex descriptions of software system families. We show that our method does not suffer from scalability issues and extracts all pertinent relationships, but that it also extracts numerous accidental relationships that need to be filtered."
Research article - File-level socio-technical congruence and its relationship with bug proneness in OSS projects,"AbstractCoordination is important in software development. Socio-Technical Congruence (STC) is proposed to measure the match between coordination requirements and actual coordination activities. The previous work of Cataldo et al. computes STC in commercial projects and finds it related to software failures. In this paper, we study the relationship between file-level STC and bug proneness in Open Source Software (OSS) projects. We apply the fundamental STC framework to the OSS data setting and present a method of computing file-level STC based on our available data. We also propose a derivative STC metric called Missing Developer Links (MDL), which is to measure the amount of coordination breakdowns. In our empirical analysis on five OSS projects, we find that MDL is more related to bug proneness than STC. Furthermore, STC or MDL can be computed based on different types of file networks and developer networks, and we find out the best file network and the best developer network via an empirical study. We also evaluate the usefulness of STC or MDL metrics in bug prediction. This work is promising to help detect coordination issues in OSS projects."
Research article - LoopFix: an approach to automatic repair of buggy loops,"AbstractBugs may be present in various places in a program. Bugs contained in loops (hereafter buggy loops) are challenging to fix using existing bug fixing techniques. In this work, we propose LoopFix, an approach that aims to repair buggy loops automatically. LoopFix takes a program and a test suite including at least one failed test case as inputs, and generates a patch to fix the bug. LoopFix first leverages on existing bug localization techniques to obtain ranked buggy statements. After that, LoopFix exploits a component based program synthesis approach to synthesize a patch based on the runtime information obtained through symbolic execution. Finally, LoopFix validates the patch with the given test suite. We have implemented LoopFix in a prototype tool and compared the performance of LoopFix with Angelix, S3 and JFix on three widely adopted datasets, i.e., IntroClass, Defects4J and Loops. Our experiments show that LoopFix fixes about 30% of buggy loops and performs more effective than the other tools on buggy loops."
Research article - Expression caching for runtime verification based on parameterized probabilistic models,"AbstractSelf-adaptive software systems change their behaviors to adapt to their environmental changes at runtime. Runtime verification, which checks the correctness of behaviors after adaptation, sometimes uses probabilistic model checking, because the verification has to deal with uncertainty. However, since probabilistic model checking is usually computation intensive and time consuming, a more efficient verification mechanism is desired. A possible approach is to pre-generate some expressions for model checking at design time and execute model checking simply by evaluating the expressions at runtime. A problem with this approach is that when environmental changes require changes of the system model, these expressions need to be re-generated at runtime. In order to cope with such significant changes, we develop a caching mechanism that reduces computational time at runtime. We also introduce a parameterization technique in order to improve the efficiency of caching. The experimental results show that our new implementation of the caching mechanism greatly improves the computational time of runtime verification."
Research article - Combining data analytics and developers feedback for identifying reasons of inaccurate estimations in agile software development,"AbstractBackground: Effort estimations are critical tasks greatly influencing the accomplishment of software projects. Despite their recognized relevance, little is yet known what indicators for inaccurate estimations exist, and which are the reasons of inaccurate estimations.Aims: In this manuscript, we aim at contributing to this existing gap. To this end, we implemented a tool that combines data analytics and developers’ feedback, and we employed that tool in a study. In that study, we explored the most common reasons of inaccurate user story estimations and the possible indicators of inaccurate estimations.Method: We relied on a mixed method approach used to study reasons and indicators for the identification and prediction of inaccurate estimations in practical agile software development contexts.Results: Our results add to the existing body of knowledge in multiple ways. We elaborate causes for inaccurate estimations going beyond the borders of existing literature; for instance, we show that lack of developers’ experience is the most common reason of inaccurate estimations. Further, our results suggest, for example, that the higher the complexity, the higher the uncertainty in the estimation.Conclusions: Overall, our results strengthen our confidence in the usefulness of using data analytics with human-in-the-loop mechanisms to improve effort estimations."
Research article - An empirical study of configuration changes and adoption in Android apps,"AbstractAndroid platform is evolving rapidly. Therefore, evolution and maintenance of Android apps are major concerns among developers. One of the essential components of each app is an Android manifest file, which is a configuration file used to declare various key attributes of apps. This paper presents an empirical study to understand app evolution through configuration changes. The results of this study will help developers in identifying change-proneness attributes, including change patterns and the reason behind the change, understanding the adoption of different attributes introduced in different versions of the Android platform, and understanding effort distribution pattern in configuration changes and taking proactive measures to reduce the effort. In this paper, we use a data mining approach. We analyze commit histories of Android manifest files of 908 apps to understand the app evolution. The results of this study show that most of the apps extend core functionalities and improve user interface over time, configuration changes are mostly influenced by functionalities extension, platform evolution, and bug reports, very few numbers of existing apps adopt new attributes introduced by the platform, apps are generally slow in adopting new attributes, and significant effort is wasted in changing configuration and then reverting back the change."
