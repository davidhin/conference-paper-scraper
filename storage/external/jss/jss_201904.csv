title,abstract
Research article - Fine-grained just-in-time defect prediction,"AbstractDefect prediction models focus on identifying defect-prone code elements, for example to allow practitioners to allocate testing resources on specific subsystems and to provide assistance during code reviews. While the research community has been highly active in proposing metrics and methods to predict defects on long-term periods (i.e.,at release time), a recent trend is represented by the so-called short-term defect prediction (i.e.,at commit-level). Indeed, this strategy represents an effective alternative in terms of effort required to inspect files likely affected by defects. Nevertheless, the granularity considered by such models might be still too coarse. Indeed, existing commit-level models highlight an entire commit as defective even in cases where only specific files actually contain defects.In this paper, we first investigate to what extent commits are partially defective; then, we propose a novel fine-grained just-in-time defect prediction model to predict the specific files, contained in a commit, that are defective. Finally, we evaluate our model in terms of (i) performance and (ii) the extent to which it decreases the effort required to diagnose a defect. Our study highlights that: (1) defective commits are frequently composed of a mixture of defective and non-defective files, (2) our fine-grained model can accurately predict defective files with an AUC-ROC up to 82% and (3) our model would allow practitioners to save inspection efforts with respect to standard just-in-time techniques."
Research article - Efficient accelerator sharing in virtualized environments: A Xeon Phi use-case,"AbstractHigh performance computing experts and scientists increasingly pay attention to heterogeneous processing and most systems today are built with some form of heterogeneity. At the same time, a large amount of HPC workloads is executed in cloud computing environments, due to the benefits that cloud offers both for the users and the infrastructure providers. In this context, there is a growing need to bridge the gap between the accelerator ecosystem and the world of virtualization, which is the building block of cloud computing environments. Hence, future accelerator platforms need to be designed in a virtualization-friendly approach, both in the software and in the hardware level.In this paper we extend our previous work and introduce vPHI, a transparent framework that enables sharing of Xeon Phi devices between multiple virtual machines. We design vPHI based on the paravirtualization technique and provide compatibility with the accelerator’s native transport layer to the upper level software stack components. In this way, with vPHI existing applications can be used without any source code or binary modifications. The evaluation of our framework in the popular offload mode of execution shows promising results with vPHI exhibiting minimal overhead for the computational phases in a deployment with multiple (up to 8) VMs. vPHI can enable better accelerator utilization, increasing up to 3.4x the total throughput versus a single host application. We also discuss the applicability of our approach to future accelerator technologies and in this way form a path to bring the accelerator use cases closer to the cloud computing world."
Research article - A semi-partitioned model for mixed criticality systems,"AbstractMany Mixed Criticality algorithms have been developed with an assumption that lower criticality-level tasks may be abandoned in order to guarantee the schedulability of higher-criticality tasks when the criticality level of the system changes. But it is valuable to explore means by which all of the tasks remain schedulable through these criticality level changes. This paper introduces a semi-partitioned model for a multi-core platform that allows all of the tasks to remain schedulable if only a bounded number of cores increase their criticality level. In such a model, some lower-criticality tasks are allowed to migrate instead of being abandoned. Detailed response time analysis for this model is derived. This paper also introduces possible approaches for establishing migration routes. Together with related previous work, an appropriate semi-partitioned model for mixed criticality systems hosted on multi-core platforms is recommended."
Research article - Achieving change requirements of feature models by an evolutionary approach,"AbstractFeature models are a widely used modeling notation for variability and commonality management in software product line (SPL) engineering. In order to keep an SPL and its feature model aligned, feature models must be changed by including/excluding new features and products, either because faults in the model are found or to reflect the normal evolution of the SPL. The modification of the feature model to be made to satisfy these change requirements can be complex and error-prone. In this paper, we present a method that is able to automatically update a feature model in order to satisfy a given update request. The method is based on an evolutionary algorithm that iteratively applies structure-preserving mutations to the original model, until the model is completely updated or some other termination condition occurs. Among all the possible models achieving the update request, the method privileges those structurally simpler. We evaluate the approach on real-world feature models; although it does not guarantee to completely update all the possible feature models, empirical analysis shows that, on average, around 89% of requested changes are applied."
Research article - A meta-model for software protections and reverse engineering attacks,"AbstractSoftware protection techniques are used to protect valuable software assets against man-at-the-end attacks. Those attacks include reverse engineering to steal confidential assets, and tampering to break the software’s integrity in unauthorized ways. While their ultimate aims are the original assets, attackers also target the protections along their attack path. To allow both humans and tools to reason about the strength of available protections (and combinations thereof) against potential attacks on concrete applications and their assets, i.e., to assess the true strength of layered protections, all relevant and available knowledge on the relations between the relevant aspects of protections, attacks, applications, and assets need to be collected, structured, and formalized. This paper presents a software protection meta-model that can be instantiated to construct a formal knowledge base that holds precisely that information. The presented meta-model is validated against existing models and taxonomies in the domain of software protection, and by means of prototype tools that we developed to help non-modelling-expert software defenders with populating a knowledge base and with extracting and inferring practically useful information from it. All discussed tools are available as open source, and we evaluate their use as part of a software protection work flow on an open source application and industrial use cases."
Research article - Architecting with microservices: A systematic mapping study,"AbstractContextA microservice architecture is composed of a set of small services, each running in its own process and communicating with lightweight mechanisms. Many aspects on architecting with microservices are still unexplored and existing research is still far from being crispy clear.ObjectiveWe aim at identifying, classifying, and evaluating the state of the art on architecting with microservices from the following perspectives: publication trends, focus of research, and potential for industrial adoption.MethodWe apply the systematic mapping methodology. We rigorously selected 103 primary studies and we defined and applied a classification framework to them for extracting key information for subsequent analysis. We synthesized the obtained data and produced a clear overview of the state of the art.ResultsThis work contributes with (i) a classification framework for research studies on architecting with microservices, (ii) a systematic map of current research of the field, (iii) an evaluation of the potential for industrial adoption of research results, and (iv) a discussion of emerging findings and implications for future research.ConclusionThis study provides a solid, rigorous, and replicable picture of the state of the art on architecting with microservices. Its results can benefit both researchers and practitioners of the field."
