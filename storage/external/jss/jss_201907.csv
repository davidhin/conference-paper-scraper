title,abstract
Research article - Uncertainty-wise test case generation and minimization for Cyber-Physical Systems,"AbstractCyber-Physical Systems (CPSs) typically operate in highly indeterminate environmental conditions, which require the development of testing methods that must explicitly consider uncertainty in test design, test generation, and test optimization. Towards this direction, we propose a set of uncertainty-wise test case generation and test case minimization strategies that rely on test ready models explicitly specifying subjective uncertainty. We propose two test case generation strategies and four test case minimization strategies based on the Uncertainty Theory and multi-objective search. These strategies include a novel methodology for designing and introducing indeterminacy sources in the environment during test execution and a novel set of uncertainty-wise test verdicts. We performed an extensive empirical study to select the best algorithm out of eight commonly used multi-objective search algorithms, for each of the four minimization strategies, with five use cases of two industrial CPS case studies. The minimized set of test cases obtained with the best algorithm for each minimization strategy were executed on the two real CPSs. The results showed that our best test strategy managed to observe 51% more uncertainties due to unknown indeterminate behaviors of the physical environments of the CPSs as compared to the other test strategies. Also, the same test strategy managed to observe 118% more unknown uncertainties as compared to the unique number of known uncertainties."
Research article - Verifying fragility in digital systems with uncertainties using DSVerifier v2.0,"AbstractControl-system robustness verification with respect to implementation aspects lacks automated verification approaches for checking stability and performance of uncertain control systems, when considering finite word-length (FWL) effects. Here we describe and evaluate novel verification procedures for digital systems with uncertainties, based on software model checking and satisfiability modulo theories, named as DSVerifier v2.0, which is able to check robust stability of closed-loop control systems with respect to FWL effects. In particular, we describe our verification algorithms to check for limit-cycle oscillations (LCOs), output quantization error, and robust non-fragile stability on common closed-loop associations of digital control systems (i.e., series and feedback). DSVerifier v2.0 model checks new properties of closed-loop systems (e.g., LCO), including stability and output quantization error for uncertain plant models, and considers unknown parameters and FWL effects. Experimental results over a large set of benchmarks show that 35%, 34%, and 41% of success can be reached for stability, LCO, and output quantization error verification procedures, respectively, for a set of 396 closed-loop control system implementations and realizations."
Research article - Automatically detecting the scopes of source code comments,"AbstractComments convey useful information about the system functionalities and many methods for software engineering tasks take comments as an important source for many software engineering tasks such as code semantic analysis, code reuse and so on. However, unlike structural doc comments, it is challenging to identify the relationship between the functional semantics of the code and its corresponding textual descriptions nested inside the code and apply it to automatic analyzing and mining approaches in software engineering tasks efficiently.In this paper, we propose a general method for the detection of source code comment scopes. Based on machine learning, our method utilized features of code snippets and comments to detect the scopes of source code comments automatically in Java programs. On the dataset of comment-statement pairs from 4 popular open source projects, our method achieved a high accuracy of 81.45% in detecting the scopes of comments. Furthermore, the results demonstrated the feasibility and effectiveness of our comment scope detection method on new projects.Moreover, our method was applied to two specific software engineering tasks in our studies: analyzing software repositories for outdated comment detection and mining software repositories for comment generation. As a general approach, our method provided a solution to comment-code mapping. It improved the performance of baseline methods in both tasks, which demonstrated that our method is conducive to automatic analyzing and mining approaches on software repositories."
Research article - Managing inter-model inconsistencies in model-based systems engineering: Application in automated production systems engineering,"AbstractTo cope with the challenge of managing the complexity of automated production systems, model-based approaches are applied increasingly. However, due to the multitude of different disciplines involved in automated production systems engineering, e.g., mechanical, electrical, and software engineering, several modeling languages are used within a project to describe the system from different perspectives. To ensure that the resulting system models are not contradictory, the necessity to continuously diagnose and handle inconsistencies within and in between models arises. This article proposes a comprehensive approach that allows stakeholders to specify, diagnose, and handle inconsistencies in model-based systems engineering. In particular, to explicitly capture the dependencies and consistency rules that must hold between the disparate engineering models, a dedicated graphical modeling language is proposed. By means of this language, stakeholders can specify, diagnose, and handle inconsistencies in the accompanying inconsistency management framework. The approach is implemented based on the Eclipse Modeling Framework (EMF) and evaluated based on a demonstrator project as well as a small user experiment. First findings indicate that the approach is expressive enough to capture typical dependencies and consistency rules in the automated production system domain and that it requires less effort compared to manually developing inter-model inconsistency management solutions."
Research article - Communication channels in safety analysis: An industrial exploratory case study,"AbstractContext: Safety analysis is a predominant activity in developing safety-critical systems. It is a highly cooperative task among multiple functional departments due to increasingly sophisticated safety-critical systems and close-knit development processes. Communication occurs pervasively.Motivation: Effective communication channels among multiple functional departments influence safety analysis quality as well as a safe product delivery. However, the use of communication channels during safety analysis is sometimes arbitrary and poses challenges.Objective: In this article, we aim to investigate the existing communication channels, their usage frequencies, their purposes and challenges during safety analysis in industry.Method: We conducted a multiple case study by surveying 39 experts and interviewing 21 experts in safety-critical companies including software developers, quality engineers and functional safety managers. Direct observations and documentation review were also conducted.Results: Popular communication channels during safety analysis include formal meetings, project coordination tools, documentation and telephone. Email, personal discussion, training, internal communication software and boards are also in use. Training involving safety analysis happens 1-4 times per year, while other aforementioned communication channels happen ranging from 1-4 times per day to 1-4 times per month. We summarise 28 purposes of using these aforementioned communication channels. Communication happens mostly for the purpose of clarifying safety requirements, fixing temporary problems, conflicts and obstacles and sharing safety knowledge. The top 10 challenges are: (1) sensitiveness and confidentiality of safety analysis information; (2) fragmented safety analysis information; (3) inconsistent safety analysis information; (4) asynchronous channels; (5) a lack of tool support; (6) misunderstanding between developers and safety analysts; (7) language, geographic and culture limitations; (8) unwillingness to communicate (groupthink); (9) storage, authority, regulation and monitoring of safety analysis information; (10) a lack of documentation concerning safety analysis to support communication.Conclusion: During safety analysis, to use communication channels effectively and avoid challenges, a clear purpose of communication during safety analysis should be established at the beginning. We have limitations primarily on the research context namely the scope of domains, participants and countries. To derive countermeasures of fixing the top 10 challenges are potential next steps."
Research article - Towards the definitive evaluation framework for cross-platform app development approaches,"AbstractMobile app development is hindered by device fragmentation and vendor-specific modifications. Boundaries between devices blur with PC-tablet hybrids on the one side and wearables on the other. Future apps need to support a host of app-enabled devices with differing capabilities, along with their software ecosystems. Prior work on cross-platform app development concerned concepts and prototypes, and compared approaches that target smartphones. To aid choosing an appropriate framework and to support the scientific assessment of approaches, an up-to-date comparison framework is needed. Extending work on a holistic, weighted set of assessment criteria, we propose what could become the definitive framework for evaluating cross-platform approaches. We have based it on sound abstract concepts that allow extensions. The weighting capabilities offer customisation to avoid the proverbial comparison of apples and oranges lurking in the variety of available frameworks. Moreover, it advises on multiple development situations based on a single assessment. In this article, we motivate and describe our evaluation criteria. We then present a study that assesses several frameworks and compares them to Web Apps and native development. Our findings suggest that cross-platform development has seen much progress but the challenges are ever growing. Therefore, additional support for app developers is warranted."
Research article - A systematic literature review on crowdsourcing in software engineering,"AbstractBackgroundCrowdsourcing outsources a task to large groups of people by open call format, and it recently plays significant role for software practitioners.AimThe purpose of this study is to conduct a comprehensive overview on crowdsourcing in software engineering (CSE), concerning business models, tools, platforms, software development processes, and software economics.MethodWe conducted a systematic literature review on CSE. We identified 158 relevant studies and 6 secondary studies. We further reviewed 67 primary studies that passed our quality assessment criteria. We defined 10 research questions and synthesized different approaches used in primary studies regarding each question.ResultsMajority of studies report the application of crowdsourcing for coding and testing tasks. Crowdsourcing follows a unique methodology in which project planning, task specification and deployment have more emphasis. There is not enough literature on effort estimation approaches in CSE and associated cost factors. Complexity of the task and its expected duration play significant role in estimation.ConclusionsFuture studies should focus more on economic models, experience reports, specific software development methodologies, and strategic pricing mechanism for CSE."
Research article - Efficient runtime metaprogramming services for Java,"AbstractThe Java programming language and platform provide many optimizations to execute statically typed code efficiently. Although Java has gradually incorporated more dynamic features across its versions, it does not provide several metaprogramming features supported by most dynamic languages, such as structural intercession (the ability to dynamically modify the structure of classes) and dynamic code generation. Therefore, we propose a method to add those metaprogramming features to Java in order to increase its runtime adaptiveness, while taking advantage of the robustness of its static type system and the performance of its virtual machine. We support the dynamic addition, deletion and replacement of class methods and fields, and dynamic code generation. The metaprogramming services are provided as a library, so neither the Java language nor its virtual machine are modified. We evaluate our system, called JMPLib, and compare it with the existing metaprogramming systems for the Java platform and other highly optimized dynamic languages. JMPLib obtains similar runtime performance to the existing fastest system that modifies the implementation of the Java virtual machine. Moreover, our system introduces no performance penalty when metaprogramming is not used, and consumes fewer memory resources than the rest of implementations for the Java platform."
Research article - Static correction of Maude programs with assertions,"AbstractIn this paper, we present a novel transformation method for Maude programs featuring both automatic program diagnosis and correction. The input of our method is a reference specification A of the program behavior that is given in the form of assertions together with an overly general program R whose execution might violate the assertions. Our correction technique translates R into a refined program R′ in which every computation is also a computation in R that satisfies the assertions of A. The technique is first formalized for topmost rewrite theories, and then we generalize it to larger classes of rewrite theories that support nested structured configurations. Our technique copes with infinite space states and does not require the knowledge of any failing run. We report experiments that assess the effectiveness of assertion-driven correction."
Research article - Swarm debugging: The collective intelligence on interactive debugging,"AbstractOne of the most important tasks in software maintenance is debugging. To start an interactive debugging session, developers usually set breakpoints in an integrated development environment and navigate through different paths in their debuggers. We started our work by asking what debugging information is useful to share among developers and study two pieces of information: breakpoints (and their locations) and sessions (debugging paths). To answer our question, we introduce the Swarm Debugging concept to frame the sharing of debugging information, the Swarm Debugging Infrastructure (SDI) with which practitioners and researchers can collect and share data about developers’ interactive debugging sessions, and the Swarm Debugging Global View (GV) to display debugging paths. Using the SDI, we conducted a large study with professional developers to understand how developers set breakpoints. Using the GV, we also analyzed professional developers in two studies and collected data about their debugging sessions. Our observations and the answers to our research questions suggest that sharing and visualizing debugging data can support debugging activities."
Research article - Employing rule mining and multi-objective search for dynamic test case prioritization,"AbstractTest case prioritization (TP) is widely used in regression testing for optimal reordering of test cases to achieve specific criteria (e.g., higher fault detection capability) as early as possible. In our earlier work, we proposed an approach for black-box dynamic TP using rule mining and multi-objective search (named as REMAP) by defining two objectives (fault detection capability and test case reliance score) and considering test case execution results at runtime. In this paper, we conduct an extensive empirical evaluation of REMAP by employing three different rule mining algorithms and three different multi-objective search algorithms, and we also evaluate REMAP with one additional objective (estimated execution time) for a total of 18 different configurations (i.e., 3 rule mining algorithms ×  3 search algorithms ×  2 different set of objectives) of REMAP. Specifically, we empirically evaluated the 18 variants of REMAP with 1) two variants of random search while using two objectives and three objectives, 2) three variants of greedy algorithm based on one objective, two objectives, and three objectives, 3) 18 variants of static search-based prioritization approaches, and 4) six variants of rule-based prioritization approaches using two industrial and three open source case studies. Results showed that the two best variants of REMAP with two objectives and three objectives significantly outperformed the best variants of competing approaches by 84.4% and 88.9%, and managed to achieve on average 14.2% and 18.8% higher Average Percentage of Faults Detected per Cost (APFDc) scores."
Research article - What are the factors affecting the handover process in open source development?,"AbstractBackgroundHandover is common in open source software (OSS) development, which could have a negative impact on software quality and progress.ObjectiveWe aim to identify factors associated with the handover process for future improvements.MethodWe first propose a metric, i.e. Active Days Coverage (abbr. ADC) together with an algorithm, i.e., Handover Duration Identification (abbr. HDI) to identify the handover processes in open software projects automatically. To evaluate our method, we selected two sample sets (i.e. sample set A and sample set B) from Github. With the sample set A, an automatic identification (to identify possible handover processes) together with an email inquiry (to identify actual handover processes) have been conducted. With the sample set B, we analyze fourteen potential factors impacting a handover process using the stepwise regression method.ResultsThe precision, recall and accuracy of our identification method reach 0.67, 0.73 and 0.65 respectively. The rate of correct identification of HDI algorithm is over 0.5 on average. Six factors were identified as the major factors impacting a handover process as well as seven combinations of these six factors were tested by stepwise regression method to explore possible correlation with the corresponding handover duration, among which five combinations show R2 greater than 0.4 with one reaches 0.493.ConclusionThis study implies that handover can be identified automatically. Developers usually follow a common handover process under various context. Moreover, although a significant correlation between the duration of a handover process and the combination of certain factors could be observed, there is no single factor that has a significant correlation with the duration of a handover process."
