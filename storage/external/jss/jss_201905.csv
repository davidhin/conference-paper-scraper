title,abstract
Research article - Performance analysis of radio spectrum for cognitive radio wireless networks using discrete time Markov chain,"AbstractCognitive radio (CR) arises as an important technique for wireless network with the aim to provide better utilization of radio spectrum, which is being utilized sporadically in some areas. IEEE 802.22 wireless regional area network (WRAN) is the first standard for CR technology designed to opportunistically utilize the unused or under-utilized TV bands. A WRAN cell normally consists of a number of customer premises equipments (CPEs)/CR users and a base station (BS) having master/slave architecture. When a CPE is powered on, it first attempts to associate with the BS. In this paper, a discrete time Markov chain model (DTMC) is presented to show the association process of CPEs with the BS. To the best of our knowledge, this paper is the first in which DTMC Model is analyzed and investigated for WRAN. Using this model, various parameters such as association time, expected return time to the respective backoff stage, first passage time, etc., are derived. Finally, the evaluation results are provided to analyze the system's performance."
Research article - Real-time control architecture based on Xenomai using ROS packages for a service robot,"AbstractThis paper proposes a real-time (RT) control architecture based on Xenomai, an RT embedded Linux, to control a service robot along with non-real-time (NRT) robot operating system (ROS) packages. Most software, including device drivers and ROS, are developed to operate under the standard Linux kernel that does not provide RT guarantees. Standard Linux system calls in an RT context stimulates mode switching, resulting in non-deterministic responses and stability problems such as priority inversion and kernel panic. This paper overcomes such issues through a communication interface between RT and NRT tasks, termed cross-domain datagram protocol. The proposed architecture supports priority-based scheduling of multiple tasks while exposing an interface compatible with the original ROS packages. Moreover, it enables standard device driver operation inside RT tasks without developing RT device drivers that requires significant amount of development time. Feasibility is proven by implementation on a Raspberry Pi 3, a low-cost open embedded hardware platform, and conducted various experiments to analyze its performance and applied it to a service robot using ROS navigation packages. The results indicate that the proposed architecture can effectively provide an RT environment without stability issues when utilizing ROS packages and standard device drivers."
Research article - Architectural Tactics for Big Data Cybersecurity Analytics Systems: A Review,"AbstractContextBig Data Cybersecurity Analytics (BDCA) systems leverage big data technologies for analyzing security events data to protect organizational networks, computers, and data from cyber attacks.ObjectiveWe aimed at identifying the most frequently reported quality attributes and architectural tactics for BDCA systems.MethodWe used Systematic Literature Review (SLR) method for reviewing 74 papers.ResultOur findings are twofold: (i) identification of 12 most frequently reported quality attributes for BDCA systems; and (ii) identification and codification of 17 architectural tactics for addressing the identified quality attributes. The identified tactics include six performance tactics, four accuracy tactics, two scalability tactics, three reliability tactics, and one security and usability tactic each.ConclusionOur study reveals that in the context of BDCA (a) performance, accuracy and scalability are the most important quality concerns (b) data analytics is the most critical architectural component (c) despite the significance of interoperability, modifiability, adaptability, generality, stealthiness, and privacy assurance, these quality attributes lack explicit architectural support (d) empirical investigation is required to evaluate the impact of the codified tactics and explore the quality trade-offs and dependencies among the tactics and (e) the reported tactics need to be modelled using a standardized modelling language such as UML."
Research article - A comparison and evaluation of variants in the coupling between objects metric,"AbstractThe Coupling Between Objects metric (CBO) is a widely-used metric but, in practice, ambiguities in its correct implementation have led to different values being computed by different metric tools and studies. CBO has often been shown to correlate with defect occurrence in software systems, but the use of different calculations is commonly overlooked. This paper investigates the varying interpretations of CBO used by those metrics tools and researchers and defines a set of metrics representing the different computational approaches used. These metrics are calculated for a large-scale Java system and logistic regression used to correlate them with defect data obtained by analysing the system's version tracking records. The different variations of CBO are shown to have significantly different correlations to defects. Regarding results, a clear binary divide was found between CBO values which, on the one hand, predicted a defect and, on the other, those that did not. The results, therefore, show that a clarification or unambiguous re-definition of CBO is both desirable and essential for a general consensus on its use. Moreover, applications of the metric must pay close attention to the actual method of calculation being used and, conclusions and comparisons made as a result."
Research article - Data prefetching and file synchronizing for performance optimization in Hadoop-based hybrid cloud,"AbstractDriven by the technical factors such as system reliability, bandwidth constraints, data confidentiality and security, as well as the economic factors such as initial capital expenditure and re-occurring operating expenditure, today's cloud computing tends to adopt hybrid cloud model. However, because hybrid clouds scale both numerically and geographically, the network delay becomes the main constraint in remote file system access. To hide network latency and reduce job completion time in Hadoop-based hybrid cloud data access, a scheduling-aware data prefetching scheme to enhance non-local map task's data locality in Hadoop-based centralized hybrid cloud (CHCDLOS-Prefetch) and a file synchronizing method to decrease job execution delay in Hadoop-based distributed hybrid cloud (DHCDLO-Sync) are proposed. In the former, input data for non-local map tasks are fetched ahead of time to target compute nodes by making use of idle network bandwidth. In the latter, considered from job level scheduling, data files with high popularity are proactively synchronized beforehand among sub-clouds to strength intra sub-cloud data locality in distributed hybrid cloud. Extensive experimental results illustrate that compared to the Capacity, the Fair and the DARE algorithms, our proposed algorithms improve hybrid cloud performance more significantly in data locality and job completion time."
Research article - Safety for mobile robotic systems: A systematic mapping study from a software engineering perspective,"AbstractRobotic research is making huge progress. However, existing solutions are facing a number of challenges preventing them from being used in our everyday tasks: (i) robots operate in unknown environments, (ii) robots collaborate with each other and even with humans, and (iii) robots shall never injure people or create damages. Researchers are targeting those challenges from various perspectives, producing a fragmented research landscape.We aim at providing a comprehensive and replicable picture of the state of the art from a software engineering perspective on existing solutions aiming at managing safety for mobile robotic systems. We apply the systematic mapping methodology on an initial set of 1274 potentially relevant research papers, we selected 58 primary studies and analyzed them according to a systematically-defined classification framework.This work contributes with (i) a classification framework for methods or techniques for managing safety when dealing with the software of mobile robotic systems (MSRs), (ii) a map of current software methods or techniques for software safety for MRSs, (iii) an elaboration on emerging challenges and implications for future research, and (iv) a replication package for independent replication and verification of this study. Our results confirm that generally existing solutions are not yet ready to be used in everyday life. There is the need of turn-key solutions ready to deal with all the challenges mentioned above."
Research article - A motifs-based Maximum Entropy Markov Model for realtime reliability prediction in System of Systems,"AbstractSystem of Systems (SoS) based on service composition is considered as an effective way to build large-scale complex software systems. It regards the system as a service and integrates multiple component systems into a new system. The performance of the component system may fluctuate at any time because of the complex and changeable running state and external environment of the component system, which will affect the running of the SoS. The online reliability prediction technology is used to predict the reliability of the component system of an SoS in the near future. It aims to find errors and correct them in time so as to ensure that the SoS can run continuously and smoothly. To tackle the reliability prediction problem of component system in a dynamic and uncertain environment, the paper integrates Maximum Entropy Markov Model (MEMM) with time series motifs to achieve a new prediction model (m_MEMM), which is referred to as motifs-based MEMM. Extensive experiments are conducted to demonstrate the effectiveness and accuracy of the proposed approach."
Research article - Towards understanding bugs in an open source cloud management stack: An empirical study of OpenStack software bugs,"AbstractCloud management stack (CMS) provides convenience for organizations in managing their cloud platforms. CMS software is complex and bugs in it can cause serious damage to the cloud environment. Therefore, an in-depth understanding of CMS bugs can help developers detect and fix them. In this paper, we conduct a thorough empirical study of several key characteristics of bugs in OpenStack — the most popular open source CMS. Our study computes general statistics for about 50K OpenStack bugs, including the evolution of bugs, the distribution of bugs, and the duration of bugs. We then selected 579 bugs for an in-depth study. In particular, we study the input factors for triggering the bugs, the consequences of the bugs, and how the bugs are fixed. The findings of this study provide a set of lessons learned and guidance to aid practitioners and researchers to better handle bugs in CMS software."
Research article - The Robot Operating System: Package reuse and community dynamics,"AbstractROS, the Robot Operating System, offers a core set of software for operating robots that can be extended by creating or using existing packages, making it possible to write robotic software that can be reused on different hardware platforms. With thousands of packages available per stable distribution, encapsulating algorithms, sensor drivers, etc., it is the de facto middleware for robotics. Like any software ecosystem, ROS must evolve in order to keep meeting the requirements of its users. In practice, packages may end up being abandoned between releases: no one may be available to update a package, or newer packages offer similar functionality. As such, we wanted to identify and understand the evolution challenges faced by the ROS ecosystem. In this article, we report our findings after interviewing 19 ROS developers in depth, followed by a focus group (4 participants) and an online survey of 119 ROS community members. We specifically focused on the issues surrounding package reuse and how to contribute to existing packages. To conclude, we discuss the implications of our findings, and propose five recommendations for overcoming the identified issues, with the goal of improving the health of the ROS ecosystem."
Research article - Unsupervised learning approach for web application auto-decomposition into microservices,"AbstractNowadays, large monolithic web applications are manually decomposed into microservices for many reasons including adopting a modern architecture to ease maintenance and increase reusability. However, the existing approaches to refactor a monolithic application do not inherently consider the application scalability and performance. We devise a novel method to automatically decompose a monolithic application into microservices to improve the application scalability and performance. Our proposed decomposition method is based on a black-box approach that uses the application access logs and an unsupervised machine-learning method to auto-decompose the application into microservices mapped to URL partitions having similar performance and resource requirements. In particular, we propose a complete automated system to decompose an application into microservices, deploy the microservices using appropriate resources, and auto-scale the microservices to maintain the desired response time. We evaluate the proposed system using real web applications on a public cloud infrastructure. The experimental evaluation shows an improved performance of the auto-created microservices compared with the monolithic version of the application and the manually created microservices."
Research article - Model transformation for analyzing dependability of AADL model by using HiP-HOPS,"AbstractThe Architecture Analysis and Design Language (AADL) has emerged as a potential future standard in aerospace, automobile and avionics industries for model-based development of dependability-critical systems. As AADL is relatively new, some existing analysis methods and tools are not able to accept AADL models. In this paper we show that, by using model transformation techniques, we can automatically transform AADL models into a form that is directly executable by fault-tree-based dependability analysis and optimisation tools. This model transformation opens a path by which AADL models may benefit from automatic synthesis and analysis of fault trees, temporal fault tree analysis, multiple failure mode and effects analysis and model architecture optimisation.In this paper, we present a new model transformation framework. The core of the framework is a novel transformation from a state machine-based error model to a fault-tree model. The framework has been implemented as a plug-in (AADL2HiP-HOPS) for the AADL model development tool OSATE. The plug-in may be used to transform AADL models into a state-of-the-art dependability analysis and optimisation tool: HiP-HOPS. To illustrate the transformation and subsequent HiP-HOPS analysis, an example AADL model is transformed."
Research article - A weighted fuzzy classification approach to identify and manipulate coincidental correct test cases for fault localization,"AbstractIdentifying the location of faults effectively and accurately is highly important in the debugging process of software engineering. Coverage-based Fault Localization (CBFL) has been widely studied that can alleviate the effort of developers to find the faults position using the execution information of test cases. Coincidental Correct (CC) test cases are the specific test cases that execute the faulty statements but with a correct output, which have been illustrated with a negative effect on the accuracy of CBFL. In this paper, we propose a weighted fuzzy classification approach to identify CC test cases and three fuzzy strategies are suggested to manipulate CC test cases for CBFL. Firstly, we present a simple but efficient approach to identify some CC test cases for single fault programs, which provide labeled samples that enable the application of supervised classification algorithms for CC identification. Then, a Fuzzy Weighted K-Nearest Neighbor (FW-KNN) algorithm is proposed to classify potential CC from the passed test cases, in which a ‘weighted’ similarity measure and a “weighted” CC probability computation are presented. Finally, three fuzzy CC test cases manipulation strategies are presented to mitigate the impact of CC test cases in CBFL. Various empirical studies are conducted on 190 faulty versions of 12 programs to investigate the impact of “weighted” and “fuzzy” methods for CC identification by the comparison of the effectiveness and efficiency between FW-KNN and three popular cluster and classification techniques. The results indicate that the proposed FW-KNN has higher accuracy and lower time cost. The Precision, Recall and False Positive Rate of FW-KNN is 96.47%, 83.40% and 2.85%, respectively. Besides, by utilizing code block coverage, the time cost can be reduced by 72.97% in average compared to statement coverage. The experimental results also indicate that the fault localization accuracy of CBFL can be improved by the proposed CC test cases manipulation strategies."
Research article - Astor: Exploring the design space of generate-and-validate program repair beyond GenProg,"AbstractThis article contributes to defining the design space of program repair. Repair approaches can be loosely characterized according to the main design philosophy, in particular “generate- and-validate” and synthesis-based approaches. Each of those repair approaches is a point in the design space of program repair. Our goal is to facilitate the design, development and evaluation of repair approaches by providing a framework that: a) contains components commonly present in most approaches, b) provides built-in implementations of existing repair approaches. This paper presents a Java framework named Astor that focuses on the design space of generate-and-validate repair approaches. The key novelty of Astor is to provides explicit extension points to explore the design space of program repair. Thanks to those extension points, researchers can both reuse existing program repair components and implement new ones. Astor includes 6 unique implementations of repair approaches in Java, including GenProg for Java called jGenProg. Researchers have already defined new approaches over Astor. The implementations of program repair approaches built already available in Astor are capable of repairing, in total, 98 real bugs from 5 large Java programs. Astor code is publicly available on Github: https://github.com/SpoonLabs/astor."
Research article - Preference based multi-objective algorithms applied to the variability testing of software product lines,"AbstractEvolutionary Multi-Objective Algorithms (EMOAs) have been applied to derive products for the variability testing of Software Product Lines (SPLs), which is a complex task impacted by many factors, such as the number of products to be tested, coverage criteria, and efficacy to reveal faults. But such algorithms generally produce a lot of solutions that are uninteresting to the tester. This happens because traditional search algorithms do not take into consideration the user preferences. To ease the selection of the best solutions and avoid effort generating uninteresting solutions, this work introduces an approach that applies Preference-Based Evolutionary Multi-objective Algorithms (PEMOAs) to solve the problem. The approach is multi-objective, working with the number of products to be tested, pairwise coverage and mutation score. It incorporates the preferences before the evolution process and uses the Reference Point (RP) method. Two PEMOAs are evaluated: R-NSGA-II and r-NSGA-II, using two different formulations of objectives, and three kinds of RPs. PEMOAs outperform the traditional NSGA-II by generating a greater number of solutions in the Region of Interest (ROI) associated to the RPs. The use of PEMOAs can reduce the tester’s burden in the task of selecting a better and reduced set of products for SPL testing."
Research article - Developing a model-driven reengineering approach for migrating PL/SQL triggers to Java: A practical experience,"AbstractModel-driven software engineering (MDE) techniques are not only useful in forward engineering scenarios, but can also be successfully applied to evolve existing systems. RAD (Rapid Application Development) platforms emerged in the nineties, but the success of modern software technologies motivated that a large number of enterprises tackled the migration of their RAD applications, such as Oracle Forms. Our research group has collaborated with a software company in developing a solution to migrate PL/SQL monolithic code on Forms triggers and program units to Java code separated in several tiers.Our research focused on the model-driven reengineering process applied to develop the migration tool for the conversion of PL/SQL code to Java. Legacy code is represented in form of KDM (Knowledge-Discovery Metamodel) models. In this paper, we propose a software process to implement a model-driven re-engineering. This process integrates a TDD-like approach to incrementally develop model transformations with three kinds of validations for the generated code. The implementation and validation of the re-engineering approach are explained in detail, as well as the evaluation of some issues related with the application of MDE."
