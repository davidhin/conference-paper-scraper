title,abstract
Research article - Distributing relational model transformation on MapReduce,"AbstractMDE has been successfully adopted in the production of software for several domains. As the models that need to be handled in MDE grow in scale, it becomes necessary to design scalable algorithms for model transformation (MT) as well as suitable frameworks for storing and retrieving models efficiently. One way to cope with scalability is to exploit the wide availability of distributed clusters in the Cloud for the parallel execution of MT. However, because of the dense interconnectivity of models and the complexity of transformation logic, the efficient use of these solutions in distributed model processing and persistence is not trivial.This paper exploits the high level of abstraction of an existing relational MT language, ATL, and the semantics of a distributed programming model, MapReduce, to build an ATL engine with implicitly distributed execution. The syntax of the language is not modified and no primitive for distribution is added. Efficient distribution of model elements is achieved thanks to a distributed persistence layer, specifically designed for relational MT. We demonstrate the effectiveness of our approach by making an implementation of our solution publicly available and using it to experimentally measure the speed-up of the transformation system while scaling to larger models and clusters."
Research article - Lascad : Language-agnostic software categorization and similar application detection,"AbstractCategorizing software and detecting similar programs are useful for various purposes including expertise sharing, program comprehension, and rapid prototyping. However, existing categorization and similar software detection tools are not sufficient. Some tools only handle applications written in certain languages or belonging to specific domains like Java or Android. Other tools require significant configuration effort due to their sensitivity to parameter settings, and may produce excessively large numbers of categories. In this paper, we present a more usable and reliable approach of Language-Agnostic Software Categorization and similar Application Detection (Lascad). Our approach applies Latent Dirichlet Allocation (LDA) and hierarchical clustering to programs’ source code in order to reveal which applications implement similar functionalities. Lascad is easier to use in cases when no domain-specific tool is available or when users want to find similar software in different programming languages.To evaluate Lascad’s capability of categorizing software, we used three labeled data sets: two sets from prior work and one larger set that we created with 103 applications implemented in 19 different languages. By comparing Lascad with prior approaches on these data sets, we found Lascad to be more usable and outperform existing tools. To evaluate Lascad’s capability of similar application detection, we reused our 103-application data set and a newly created unlabeled data set of 5220 applications. The relevance scores of the Top-1 retrieved applications within these two data sets were, separately, 70% and 71%. Overall, Lascad effectively categorizes and detects similar programs across languages."
Research article - Efficiently detecting structural design pattern instances based on ordered sequences,"AbstractIn software engineering, a design pattern is a general reusable solution to a commonly occurring problem within a given context in software design. Design patterns reveal much about the high-level abstract designs of software systems. Accurately discovering design pattern instances in software systems helps developers and maintainers to understand the original design and implementation, and to facilitate the re-development, upgrade and maintenance. In recent years, numerous approaches have been proposed to discover design pattern instances from system source code. Among them, many transform the source code and design patterns into graphs, and then discover the isomorphic sub-graphs of design patterns from the graph of software system. However, as testing sub-graph isomorphism is an NP-complete problem, those approaches usually fail to achieve satisfactory efficiency. On the other hand, a real time response of detecting pattern instance is in fact essential. To address this problem, we propose a novel efficient approach to detect structural design pattern instances based on directed sub-graph isomorphism. In particular, we put forward a well-designed search order, or Ordered Sequences, by which the candidate pattern instances can be rapidly detected. Because the Ordered Sequences guide the search process in such an order that the most representative classes are discovered first, a large number of irrelevant classes can be filtered out at early stage, which greatly reduces the search space. We employ our approach on four well-known open-source systems. The results of extensive experiments for discovering instances of all GoF structural design patterns verify that our approach obtains 100% recall and the high precision. In addition, the experiment conducted on two other large scale open-source projects indicates that our approach runs significantly faster than the compared approach."
Research article - Filling in the missing link between simulation and application in opportunistic networking,"AbstractIn the domain of opportunistic networking, just like in any other domain of computer science, the engineering process should span all stages between an original idea and the validation of its implementation in real conditions. Yet most researchers often stop halfway along this process: they rely on simulation to validate the protocols and distributed applications they design, and neglect to go further. Their algorithms are thus only rarely implemented for real, and when they are, the validation of the resulting code is usually performed at a very small scale. Therefore, the results obtained are hardly repeatable or comparable to others.LEPTON is an emulation platform that can help bridge the gap between pure simulation and fully operational implementation, thus allowing developers to observe how the software they develop (instead of pseudo-code that simulates its behavior) performs in controlled, repeatable conditions.In this paper we present LEPTON, an emulation platform we developed, and we show how existing opportunistic networking systems can be adapted to run with this platform. Taking two existing middleware systems as use cases, we also demonstrate that running demanding scenarios with LEPTON constitute an excellent stress test and a powerful tool to improve the opportunistic systems under test."
Research article - Web service discovery based on goal-oriented query expansion,"AbstractWith the broad adoption of service-oriented architecture, many software systems have been developed by composing loosely-coupled Web services. Service discovery, a critical step of building service-based systems (SBSs), aims to find a set of candidate services for each functional task to be performed by an SBS. The keyword-based search technology adopted by existing service registries is insufficient to retrieve semantically similar services for queries. Although many semantics-aware service discovery approaches have been proposed, they are hard to apply in practice due to the difficulties in ontology construction and semantic annotation. This paper aims to help service requesters (e.g., SBS designers) obtain relevant services accurately with a keyword query by exploiting domain knowledge about service functionalities (i.e., service goals) mined from textual descriptions of services. We firstly extract service goals from services’ textual descriptions using an NLP-based method and cluster service goals by measuring their semantic similarities. A query expansion approach is then proposed to help service requesters refine initial queries by recommending similar service goals. Finally, we develop a hybrid service discovery approach by integrating goal-based matching with two practical approaches: keyword-based and topic model-based. Experiments conducted on a real-world dataset show the effectiveness of our approach."
Research article - Early evaluation of technical debt impact on maintainability,"AbstractIt is widely claimed that Technical Debt is related to quality problems being often produced by poor processes, lack of verification or basic incompetence. Several techniques have been proposed to detect Technical Debt in source code, as identification of modularity violations, code smells or grime buildups. These approaches have been used to empirically demonstrate the relation among Technical Debt indicators and quality harms. However, these works are mainly focused on programming level, when the system has already been implemented. There may also be sources of Technical Debt in non-code artifacts, e.g. requirements, and its identification may provide important information to move refactoring efforts to previous stages and reduce future Technical Debt interest. This paper presents an empirical study to evaluate whether modularity anomalies at requirements level are directly related to maintainability attributes affecting systems quality and increasing, thus, system's interest. The study relies on a framework that allows the identification of modularity anomalies and its quantification by using modularity metrics. Maintainability metrics are also used to assess dynamic maintainability properties. The results obtained by both sets of metrics are pairwise compared to check whether the more modularity anomalies the system presents, the less stable and more difficult to maintain it is."
Research article - Supporting semi-automatic co-evolution of architecture and fault tree models,"AbstractDuring the whole life-cycle of software-intensive systems in safety-critical domains, system models must consistently co-evolve with quality evaluation models like fault trees. However, performing these co-evolution steps is a cumbersome and often manual task. To understand this problem in detail, we have analyzed the evolution and mined common changes of architecture and fault tree models for a set of evolution scenarios of a part of a factory automation system called Pick and Place Unit. On the other hand, we designed a set of intra- and inter-model transformation rules which fully cover the evolution scenarios of the case study and which offer the potential to semi-automate the co-evolution process. In particular, we validated these rules with respect to completeness and evaluated them by a comparison to typical visual editor operations. Our results show a significant reduction of the amount of required user interactions in order to realize the co-evolution."
Research article - A generic approach to model generation operations,"AbstractModel generation operations are important artifacts in MDE applications. These approaches can be used for model verification, model finding, and others. In many scenarios, model transformations can as well be represented by a model generation operation. This often comes with the advantage of being bidirectional and supporting increments. However, most part of model generation approaches do not target several operation kinds, but narrower scenarios by mapping the generation problem into solver specific problems. They are efficient, but often don’t have a supporting framework. In this paper, we present an approach and framework that allows to specify and to execute model operations that can be represented in terms of model generation operations. We first introduce a model search layer that can be used with different solvers. We illustrate this layer with a driving example implemented using Alloy/SAT solver. On top of this, we introduce a transformation layer, which specification are translated into the model search layer, independently from any solver. The solution is natively bidirectional, incremental and it is not restricted to one-and-one scenarios. The approach is illustrated by two use cases and with 3 different scenarios, backed by a full, extensible and free implementation."
Research article - Transferring interactive search-based software testing to industry,"AbstractContext: Search-Based Software Testing (SBST), and the wider area of Search-Based Software Engineering (SBSE), is the application of optimization algorithms to problems in software testing, and software engineering, respectively. New algorithms, methods, and tools are being developed and validated on benchmark problems. In previous work, we have also implemented and evaluated Interactive Search-Based Software Testing (ISBST) tool prototypes, with a goal to successfully transfer the technique to industry.Objective: While SBST and SBSE solutions are often validated on benchmark problems, there is a need to validate them in an operational setting, and to assess their performance in practice. The present paper discusses the development and deployment of SBST tools for use in industry, and reflects on the transfer of these techniques to industry.Method: In addition to previous work discussing the development and validation of an ISBST prototype, a new version of the prototype ISBST system was evaluated in the laboratory and in industry. This evaluation is based on an industrial System under Test (SUT) and was carried out with industrial practitioners. The Technology Transfer Model is used as a framework to describe the progression of the development and evaluation of the ISBST system, as it progresses through the first five of its seven steps.Results: The paper presents a synthesis of previous work developing and evaluating the ISBST prototype, as well as presenting an evaluation, in both academia and industry, of that prototype’s latest version. In addition to the evaluation, the paper also discusses the lessons learned from this transfer.Conclusions: This paper presents an overview of the development and deployment of the ISBST system in an industrial setting, using the framework of the Technology Transfer Model. We conclude that the ISBST system is capable of evolving useful test cases for that setting, though improvements in the means the system uses to communicate that information to the user are still required. In addition, a set of lessons learned from the project are listed and discussed. Our objective is to help other researchers that wish to validate search-based systems in industry, and provide more information about the benefits and drawbacks of these systems."
Research article - Quality of software requirements specification in agile projects: A cross-case analysis of six companies,"AbstractAgile Software Development (ASD) has several limitations concerning its requirements engineering activities. Improving the quality of Software Requirements Specifications (SRSs) in ASD may help to gain a competitive advantage in the software industry. Based on the findings of a Systematic Mapping study, six industrial case studies in different contexts were conducted to investigate and characterize the requirements specification activity in ASD. Data collected from documents, observations, and interviews with software engineers were triangulated, analyzed, and synthesized using Grounded Theory and Meta-Ethnography. The analysis and cross-synthesis of the six case studies resulted in a model describing the phenomenon. This model defines the simplicity and objectivity as essential quality factors of SRSs in ASD. The main factors that affect the SRSs quality in ASD projects are related to their customer-driven nature that leads to prolix SRSs, hindering its understanding from the developer perspective. The emerged model is supported by explanations and provides a deeper understanding of the requirements specification activity in ASD. This creates opportunities for further studies and improvements in SRSs for ASD in industry."
Research article - MULAPI: Improving API method recommendation with API usage location,"AbstractDuring the evolution of a software system, a large number of feature requests are continuously proposed by users. To implement these feature requests, developers often utilize existing third-party libraries and make use of Application Programming Interfaces (APIs) to accelerate the feature implementation process. However, it is not always obvious which API methods are suitable and where these API methods can be used in the target program.In this paper, we propose an approach, MULAPI (Method Usage and Location for API), to recommend API methods and figure out the API usage location where these API methods would be used. MULAPI employs feature location to identify feature related files as API usage location. Further, these feature related files are taken into account to recommend API methods by exploring the source code repository and API libraries as well. We evaluate MULAPI on more than 1000 feature requests of eight Java projects (Axis/Java, CXF, Hadoop Common, Hbase, Struts2, Hadoop HDFS, Hive and Hadoop Map/Reduce), and recommend API methods from ten third-party libraries. The empirical results show that MULAPI can accurately recommend API methods and usage location, and moreover, MULAPI improves the effectiveness of API method recommendation, compared with the state-of-the-art approach."
Research article - On some end-user programming constructs and their understandability,"AbstractContext: End-user programming is becoming more and more important. However, existing programming paradigms and the languages based on them seem far-removed from what end-user programmers would need, especially in the area of Management Information.Objective: To evaluate the understandability of a set of programming constructs based on the spreadsheet metaphor from the point of view of end-user programmers in the context of Management Information. The examined set comprises single assignment with exemplary computations, data-driven iterations, selection by colours, and read-write heads (we refer to this as Board Programming).Method:A series of experiments was performed with students of Management Engineering, split into an experimental group and a control group. Each participant was given a piece of code expressed either with the proposed programming construct (experimental group) or its classical counterpart (control group). Their task was to predict the results. For the purpose of evaluation, the FACT indicators of understandability (First attempt failure rate, Attempt number, Cancellation ratio, prediction Time) were proposed and measured.Results:Three of the four examined features, i.e. single assignment with exemplary computations, data-driven iterations, and read-write heads, proved to increase understandability of the chosen programs with regard to three out of the four FACT indicators, and these results were statistically significant. Selection by colours was not as effective as expected: the FACT indicator values were improved by that feature, but the difference was not statistically significant.Conclusions:The described programming constructs appear to be an interesting option when designing an end-user programming language for domain experts in the field of Management Information."
Research article - Unusual events in GitHub repositories,"AbstractIn large and active software projects, it becomes impractical for a developer to stay aware of all project activity. While it might not be necessary to know about each commit or issue, it is arguably important to know about the ones that are unusual. To investigate this hypothesis, we identified unusual events in 200 GitHub projects using a comprehensive list of ways in which an artifact can be unusual and asked 140 developers responsible for or affected by these events to comment on the usefulness of the corresponding information. Based on 2,096 answers, we identify the subset of unusual events that developers consider particularly useful, including large code modifications and unusual amounts of reviewing activity, along with qualitative evidence on the reasons behind these answers. Our findings provide a means for reducing the amount of information that developers need to parse in order to stay up to date with development activity in their projects."
Research article - The exception handling riddle: An empirical study on the Android API,"AbstractWe examine the use of the Java exception types in the Android platform’s Application Programming Interface (API) reference documentation and their impact on the stability of Android applications. We develop a method that automatically assesses an API’s quality regarding the exceptions listed in the API’s documentation. We statically analyze ten versions of the Android platform’s API (14–23) and 3539 Android applications to determine inconsistencies between exceptions that analysis can find in the source code and exceptions that are documented. We cross-check the analysis of the Android platform’s API and applications with crash data from 901,274 application execution failures (crashes). We discover that almost 10% of the undocumented exceptions that static analysis can find in the Android platform’s API source code manifest themselves in crashes. Additionally, we observe that 38% of the undocumented exceptions that developers use in their client applications to handle API methods also manifest themselves in crashes. These findings argue for documenting known might-thrown exceptions that lead to execution failures. However, a randomized controlled trial we run shows that relevant documentation improvements are ineffective and that making such exceptions checked is a more effective way for improving applications’ stability."
Research article - Enable more frequent integration of software in industry projects,"AbstractBased on interviews with 20 developers from two case study companies that develop large-scale software-intensive embedded systems, this paper presents twelve factors that affect how often developers commit software to the mainline. The twelve factors are grouped into four themes: “Activity planning and execution”, “System thinking”, “Speed” and “Confidence through test activities”. Based on the interview results and a literature study we present the EMFIS model, which allows companies to explicate a representation of the organization's current situation regarding continuous integration impediments, and visualizes what the organization must focus on in order to enable more frequent integration of software. The model is used to perform an assessment of the twelve factors, where the ratings from participants representing the developers are summarized separately from ratings from participants representing the enablers (responsible for processes, development tools, test environments etc.). The EMFIS model has been validated in workshops and interviews, which in total included 46 individuals in five case study companies. The model was well received during the validation, and was appreciated for its simplicity and its ability to show differences in rating between developers and enablers."
