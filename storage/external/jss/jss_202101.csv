title,abstract
Research article - An evolutionary approach for generating software models: The case of Kromaia in Game Software Engineering,"AbstractIn the context of Model-Driven Engineering applied to video games, software models are high-level abstractions that represent source code implementations of varied content such as the stages of the game, vehicles, or enemy entities (e.g., final bosses).In this work, we present our Evolutionary Model Generation (EMoGen) approach to generate software models that are comparable in quality to the models created by human developers. Our approach is based on an evolution (mutation and crossover) and assessment cycle to generate the software models. We evaluated the software models generated by EMoGen in the Kromaia video game, which is a commercial video game released on Steam and PlayStation 4. Each model generated by EMoGen has more than 1000 model elements.The results, which compare the software models generated by our approach and those generated by the developers, show that our approach achieves results that are comparable to the ones created manually by the developers in the retail and digital versions of the video game case study. However, our approach only takes five hours of unattended time in comparison to ten months of work by the developers. We perform a statistical analysis, and we make an implementation of EMoGen readily available."
Research article - A systematic mapping study of developer social network research,"AbstractDeveloper social networks (DSNs) are a tool for the analysis of community structures and collaborations between developers in software projects and software ecosystems. Within this paper, we present the results of a systematic mapping study on the use of DSNs in software engineering research. We identified 255 primary studies on DSNs. We mapped the primary studies to research directions, collected information about the data sources and the size of the studies, and conducted a bibliometric assessment. We found that nearly half of the research investigates the structure of developer communities. Other frequent topics are prediction systems build using DSNs, collaboration behavior between developers, and the roles of developers. Moreover, we determined that many publications use a small sample size regarding the number of projects, which could be problematic for the external validity of the research. Our study uncovered several open issues in the state of the art, e.g., studying inter-company collaborations, using multiple information sources for DSN research, as well as general lack of reporting guidelines or replication studies."
Research article - Concepts of variation control systems,"AbstractVersion control systems are an integral part of today’s software engineering. They facilitate the collaborative management of revisions (sequential versions) and variants (concurrent versions) of software systems under development. Typical version control systems maintain revisions of files and variants of whole software systems. Variants are supported via branching or forking mechanisms that conceptually clone whole systems in a coarse-grained way. Unfortunately, such cloning leads to high maintenance efforts. To avoid these disadvantages and support fine-grained variation, developers need to employ custom configuration mechanisms, which leads to a misappropriation of tools and undesired context switches. Addressing this trade-off, a number of variation control systems has been conceived, providing a richer set of capabilities for handling variants. Variation control systems decompose a software system into finer-grained variable entities and offer high-level metaphors to automatically manage this variability. In this paper, we classify and compare variation control systems and illustrate their core concepts and characteristics. All investigated variation control systems offer an iterative (checkout–modify–commit) workflow, but there are essential differences affecting developers. We highlight challenges and discuss research perspectives for developing the next generation of version and variation control systems."
Research article - Interdisciplinary effects of technical debt in companies with mechatronic products — a qualitative study,"AbstractDigitalization of products and production systems requires a fusion of mechatronic disciplines, where interfaces between mechanical, electrical, and software engineering are inevitable. The increasingly rapid pace of innovations in mechatronic systems triggers decisions being taken under time and cost pressure. At times, compromises in technical solutions are made, neglecting their long-term damage to the system. Technical debt (TD), a concept from software engineering, refers to short-term benefits that lead to long-term negative consequences, e.g., in the form of more difficult maintainability or evolvability. This also applies to mechatronic systems, yet the knowledge of TD characteristics and correlations in the interdisciplinary life cycle has only received little attention. This first comprehensive survey investigates TD in mechatronics systematically and across sectors. 50 experts, of whom 42% hold positions as department heads, from 21 renowned companies and 10 sectors in the German-speaking region supported this study with real scenarios where TD caused damage to their system. 94 informative TD incidents that were classified into twelve TD types were recorded, of which 2/3 have not yet been eliminated and posed a potential risk to the system. TD emerges most frequently in the first three stages of the life cycle, where the consequences rarely remain isolated at their source but are forwarded to later phases and disciplines in the life cycle. In contrast to the research focus in software engineering, the multi-domain analysis of mechatronic TD issues reveals that software engineers are most burdened by Requirements TD and Infrastructure TD in the interdisciplinary environment."
Research article - Accessibility and Software Engineering Processes: A Systematic Literature Review,"AbstractGuidelines, techniques, and methods have been presented in the literature in recent years to contribute to the development of accessible software and to promote digital inclusion. Considering that software product quality depends on the quality of the development process, researchers have investigated how to include accessibility during the software development process in order to obtain accessible software. Two Systematic Literature Reviews (SLR) have been conducted in the past to identify such research initiatives. This paper presents a new SLR, considering the period from 2011 to 2019. The review of 94 primary studies showed the distribution of publications on different phases of the software life cycle, mainly the design and testing phases. The study also identified, for the first time, papers about accessibility and software process establishment. This result reinforces that, in fact, accessibility is not characterized as a property of the final software only. Instead, it evolves over the software life cycle. Besides, this study aims to provide designers and developers with an updated view of methods, tools, and other assets that contribute to process enrichment, valuing accessibility, as well as shows the gaps and challenges which deserve to be investigated."
Research article - Enabling consistency in view-based system development — The Vitruvius approach,"AbstractDuring the development of large software-intensive systems, developers use several modeling languages and tools to describe a system from different viewpoints. Model-driven and view-based technologies have made it easier to define domain-specific languages and transformations.Nevertheless, using several languages leads to fragmentation of information, to redundancies in the system description, and eventually to inconsistencies. Inconsistencies have negative impacts on the system’s quality and are costly to fix. Often, there is no support for consistency management across multiple languages. Using a single language is no practicable solution either, as it is overly complex to define, use, and evolve such a language. View-based development is a suitable approach to deal with complex systems, and is widely used in other engineering disciplines. Still, we need to cope with the problems of fragmentation and consistency.In this paper, we present the Vitruvius approach for consistency in view-based modeling. We describe the approach by formalizing the notion of consistency, presenting languages for consistency preservation, and defining a model-driven development process. Furthermore, we show how existing models can be integrated. We have evaluated our approach at two case studies from component-based and embedded automotive software development, using our prototypical implementation based on the Eclipse Modeling Framework."
Research article - Crowdsourced Behavior-Driven Development,"AbstractKey to the effectiveness of crowdsourcing approaches for software engineering is workflow design, describing how complex work is organized into small, relatively independent microtasks. This paper, we introduce a Behavior-Driven Development (BDD) workflow for accomplishing programming work through self-contained microtasks, implemented as a preconfigured environment called CrowdMicroservices. In our approach, a client, acting on behalf of a software team, describes a microservice as a set of endpoints with paths, requests, and responses. A crowd then implements the endpoints, identifying individual endpoint behaviors that they test, implement, debug, create new functions, and interact with persistence APIs as needed. To evaluate our approach, we conducted a feasibility study in which a small crowd worked to implement a small ToDo microservice. The crowd created an implementation with only four defects, completing 350 microtasks and implementing 13 functions. We discuss the implications of these findings for incorporating crowdsourced programming contributions into traditional software projects."
Research article - An automated model-based approach to repair test suites of evolving web applications,"AbstractCapture–Replay tools are widely used for the automated testing of web applications The scripts written for these Capture–Replay tools are strongly coupled with the web elements of web applications. These test scripts are sensitive to changes in web elements and require repairs as the web pages evolve. In this paper, we propose an automated model-based approach to repair the Capture–Replay test scripts that are broken due to such changes. Our approach repairs the test scripts that may be broken due to the breakages (e.g., broken locators, missing web elements) reported in the existing test breakage taxonomy. Our approach is based on a DOM-based strategy and is independent of the underlying Capture–Replay tool. We developed a tool to demonstrate the applicability of the approach. We perform an empirical study on seven subject applications. The results show that the approach successfully repairs the broken test scripts while maintaining the same DOM coverage and fault-finding capability. We also evaluate the usefulness of the repaired test scripts according to the opinion of professional testers. We conduct an experiment to compare our approach with the state-of-the-art DOM-based test repair approach, WATER. The comparison results show that our approach repairs more test breakages than WATER."
Research article - Are game engines software frameworks? A three-perspective study,"AbstractGame engines help developers create video games and avoid duplication of code and effort, like frameworks for traditional software systems. In this paper, we explore open-source game engines along three perspectives: literature, code, and human. First, we explore and summarize the academic literature on game engines. Second, we compare the characteristics of the 282 most popular engines and the 282 most popular frameworks in GitHub. Finally, we survey 124 engine developers about their experience with the development of their engines. We report that: (1) Game engines are not well-studied in software-engineering research with few studies having engines as object of research. (2) Open-source game engines are slightly larger in terms of size and complexity and less popular and engaging than traditional frameworks. Their programming languages differ greatly from frameworks. Engine projects have shorter histories with less releases. (3) Developers perceive game engines as different from traditional frameworks. Generally, they build game engines to (a) better control the environment and source code, (b) learn about game engines, and (c) develop specific games. We conclude that open-source game engines have differences compared to traditional open-source frameworks although this differences do not demand special treatments."
Research article - Translation from layout-based to visual android test scripts: An empirical evaluation,"AbstractMobile GUI tests can be classified as layout-based – i.e. using GUI properties as locators – or Visual – i.e. using widgets’ screen captures as locators –. Visual test scripts require significant maintenance efforts to be kept aligned with the tested application as it evolves or it is ported to different devices.This work aims to conceptualize a translation-based approach to automatically derive Visual tests from existing layout-based counterparts or repair them when graphical changes occur, and to develop a tool that implements and validates the approach.We present TOGGLE, a tool that translates Espresso layout-based tests for Android apps to Visual tests that conform to either SikuliX, EyeAutomate, or a combination of the two tools’ syntax. An experiment is conducted to measure the precision of the translation approach, which is evaluated on maintenance tasks triggered by graphical changes due to device diversity.Our results demonstrate the feasibility of a translation-based approach, show that script portability to different devices is improved (from 32% to 93%), and indicate that translation can repair up to 90% of Visual locators in failing tests.GUI test translation mitigates challenges with Visual tests like maintenance effort and portability, enabling their wider use in industrial practice."
"Research article - A systematic literature review on Technical Debt prioritization: Strategies, processes, factors, and tools","AbstractBackgroundSoftware companies need to manage and refactor Technical Debt issues. Therefore, it is necessary to understand if and when refactoring of Technical Debt should be prioritized with respect to developing features or fixing bugs.ObjectiveThe goal of this study is to investigate the existing body of knowledge in software engineering to understand what Technical Debt prioritization approaches have been proposed in research and industry.MethodWe conducted a Systematic Literature Review of 557 unique papers published until 2020, following a consolidated methodology applied in software engineering. We included 44 primary studies.ResultsDifferent approaches have been proposed for Technical Debt prioritization, all having different goals and proposing optimization regarding different criteria. The proposed measures capture only a small part of the plethora of factors used to prioritize Technical Debt qualitatively in practice. We present an impact map of such factors. However, there is a lack of empirical and validated set of tools.ConclusionWe observed that Technical Debt prioritization research is preliminary and there is no consensus on what the important factors are and how to measure them. Consequently, we cannot consider current research conclusive. In this paper, we therefore outline different directions for necessary future investigations."
Research article - Predicting the emergence of community smells using socio-technical metrics: A machine-learning approach,"AbstractCommunity smells represent sub-optimal conditions appearing within software development communities (e.g., non-communicating sub-teams, deviant contributors, etc.) that may lead to the emergence of social debt and increase the overall project’s cost. Previous work has studied these smells under different perspectives, investigating their nature, diffuseness, and impact on technical aspects of source code. Furthermore, it has been shown that some socio-technical metrics like, for instance, the well-known socio-technical congruence, can potentially be employed to foresee their appearance. Yet, there is still a lack of knowledge of the actual predictive power of such socio-technical metrics. In this paper, we aim at tackling this problem by empirically investigating (i) the potential value of socio-technical metrics as predictors of community smells and (ii) what is the performance of within- and cross-project community smell prediction models based on socio-technical metrics. To this aim, we exploit a dataset composed of 60 open-source projects and consider four community smells such as Organizational Silo, Black Cloud, Lone Wolf, and Bottleneck. The key results of our work report that a within-project solution can reach F-Measure and AUC-ROC of 77% and 78%, respectively, while cross-project models still require improvements, being however able to reach an F-Measure of 62% and overcome a random baseline. Among the metrics investigated, socio-technical congruence, communicability, and turnover-related metrics are the most powerful predictors of the emergence of community smells."
Research article - Do scaling agile frameworks address global software development risks? An empirical study,"AbstractDriven by the need to coordinate activities of multiple agile development teams cooperating to produce a large software product, software-intensive organizations are turning to scaling agile software development frameworks. Despite the growing adoption of various scaling agile frameworks, there is little empirical evidence of how effective their practices are in mitigating risk, especially in global software development (GSD), where project failure is a known problem.In this study, we develop a GSD Risk Catalog of 63 risks to assess the degree to which two scaling agile frameworks–Disciplined Agile Delivery (DAD) and the Scaled Agile Framework (SAFe)–address software project risks in GSD. We examined data from two longitudinal case studies implementing each framework to identify the extent to which the framework practices address GSD risks.Scaling agile frameworks appear to help companies eliminate or mitigate many traditional risks in GSD, especially relating to users and customers. However, several important risks were not eliminated or mitigated. These persistent risks in the main belonged to the Environment quadrant highlighting the inherent risk in developing software across geographic boundaries. Perhaps these frameworks (and arguably any framework), would have difficulty alleviating, issues that appear to be outside the immediate control of the organization."
Research article - Toward the automatic classification of Self-Affirmed Refactoring,"AbstractThe concept of Self-Affirmed Refactoring (SAR) was introduced to explore how developers document their refactoring activities in commit messages, i.e., developers explicit documentation of refactoring operations intentionally introduced during a code change. In our previous study, we have manually identified refactoring patterns and defined three main common quality improvement categories including internal quality attributes, external quality attributes, and code smells, by only considering refactoring-related commits. However, this approach heavily depends on the manual inspection of commit messages. In this paper, we propose a two-step approach to first identify whether a commit describes developer-related refactoring events, then to classify it according to the refactoring common quality improvement categories. Specifically, we combine the N-Gram TF–IDF feature selection with binary and multiclass classifiers to build a new model to automate the classification of refactorings based on their quality improvement categories. We challenge our model using a total of 2,867 commit messages extracted from well engineered open-source Java projects. Our findings show that (1) our model is able to accurately classify SAR commits, outperforming the pattern-based and random classifier approaches, and allowing the discovery of 40 more relevant SAR patterns, and (2) our model reaches an F-measure of up to 90% even with a relatively small training dataset."
Research article - Large scale quality transformation in hybrid development organizations – A case study,"AbstractAs the software industry transitions to a subscription-based software-as-a-service (SaaS) model, software development companies are transforming to hybrid development organizations with increased adoption of Agile and Continuous Integration/ Continuous Delivery (CI/CD) development practices for newer products while continuing to use Waterfall methods for older products. This transformation is a huge undertaking impacting all aspects of the software development life cycle (SDLC), including the quality management system. This paper presents a case study of a large-scale transformation of a legacy quality management system to a modern system developed and implemented at Cisco Systems. The framework for this transformation is defined by six distinct areas: metrics, process, measurement, reporting, quality analytics, and culture & leadership. Our implementation leveraged recent advances in Machine Learning (ML), Artificial Intelligence (AI), connected data, integrated operations, and big data technologies to solve the challenges created by a hybrid software development organization. We believe this case study will help researchers and industry leaders understand the benefits and potential challenges of such sizeable transformations."
Research article - A security pattern detection framework for building more secure software,"AbstractSecurity patterns are one of the reusable building blocks of a secure software architecture that provide solutions to particular recurring security problems in given contexts. Incomplete or nonstandard implementation of security patterns may produce vulnerabilities and invite attackers. Therefore, the detection of security patterns improves the quality of security features. In this paper, we propose a security pattern detection (SPD) framework and its internal pattern matching techniques. The framework provides a platform for data extraction, pattern matching, and semantic analysis techniques. We implement ordered matrix matching (OMM) and non-uniform distributed matrix matching (NDMM) techniques. The OMM technique detects a security pattern matrix inside the target system matrix (TSM). The NDMM technique determines whether the relationships between all classes of a security pattern are similar to the relationships between some classes of the TSM. The semantic analysis is used to reduce the rate of false positives. We evaluate and compare the performance of the proposed SPD framework using both matching techniques based on four case studies independently. The results show that the NDMM technique provides the location of the security patterns, and it is highly flexible, scalable and has high accuracy with acceptable memory and time consumption for large projects."
Research article - Assurance and certification of cyber–physical systems: The AMASS open source ecosystem,"AbstractMany cyber–physical systems (CPS) are subject to rigorous assurance and certification processes to provide confidence that undue risks are not posed and thus the systems are trustworthy. These processes are complex and time-consuming and tool support can greatly aid in their execution. In line with other trends for systems and software engineering, the need for and interest in open source tools for assurance and certification is growing and different initiatives have been launched. As a concrete example, we report on our experience in developing the AMASS open source ecosystem. This ecosystem includes (1) an open source tool platform that supports the main CPS assurance and certification activities, (2) external tools with added-value features, and (3) an open community of developers and users. The platform integrates existing solutions for system modelling, process engineering, and compliance and argumentation management. We also present the application of the AMASS tool platform in 11 industrial case studies from five different application domains. The results show that the platform is a feasible means for CPS assurance and certification and that practitioners find benefits in assurance-oriented system modelling and in integrated system assurance information, among other areas. Nonetheless, improvement opportunities also exist, most notably regarding tool interoperability and usability."
Research article - Uncertainty-aware specification and analysis for hardware-in-the-loop testing of cyber-physical systems,"AbstractHardware-in-the-loop (HiL) testing is important for developing cyber-physical systems (CPS). HiL test cases manipulate hardware, are time-consuming and their behaviors are impacted by the uncertainties in the CPS environment. To mitigate the risks associated with HiL testing, engineers have to ensure that (1) test cases are well-behaved, e.g., they do not damage hardware, and (2) test cases can execute within a time budget. Leveraging the UML profile mechanism, we develop a domain-specific language, HITECS, for HiL test case specification. Using HITECS, we provide uncertainty-aware analysis methods to check the well-behavedness of HiL test cases. In addition, we provide a method to estimate the execution times of HiL test cases before the actual HiL testing. We apply HITECS to an industrial case study from the satellite domain. Our results show that: (1) HITECS helps engineers define more effective assertions to check HiL test cases, compared to the assertions defined without any systematic guidance; (2) HITECS verifies in practical time that HiL test cases are well-behaved; (3) HITECS is able to resolve uncertain parameters of HiL test cases by synthesizing conditions under which test cases are guaranteed to be well-behaved; and (4) HITECS accurately estimates HiL test case execution times."
Research article - Security modelling and formal verification of survivability properties: Application to cyber–physical systems,"AbstractThe modelling and verification of systems security is an open research topic whose complexity and importance needs, in our view, the use of formal and non-formal methods. This paper addresses the modelling of security using misuse cases and the automatic verification of survivability properties using model checking. The survivability of a system characterises its capacity to fulfil its mission (promptly) in the presence of attacks, failures, or accidents, as defined by Ellison. The original contributions of this paper are a methodology and its tool support, through a framework called surreal. The methodology starts from a misuse case specification enriched with UML profile annotations and obtains, as a by-product, a survivability assessment model (SAM). Using predefined queries the survivability properties are proved in the SAM. A total of fourteen properties have been formulated and also implemented in surreal, which encompasses tools to model the security specification, to create the SAM and to prove the properties. Finally, the paper validates the methodology and the framework using a cyber–physical system (CPS) case study, in the automotive field."
Research article - Does code quality affect pull request acceptance? An empirical study,"AbstractBackgroundPull requests are a common practice for making contributions and reviewing them in both open-source and industrial contexts.ObjectiveOur goal is to understand whether quality flaws such as code smells, anti-patterns, security vulnerabilities, and coding style violations in a pull request’s code affect the chance of its acceptance when reviewed by a maintainer of the project.MethodWe conducted a case study among 28 Java open-source projects, analyzing the presence of 4.7 M code quality flaws in 36 K pull requests. We analyzed further correlations by applying logistic regression and six machine learning techniques. Moreover, we manually validated 10% of the pull requests to get further qualitative insights on the importance of quality issues in cases of acceptance and rejection.ResultsUnexpectedly, quality flaws measured by PMD turned out not to affect the acceptance of a pull request at all. As suggested by other works, other factors such as the reputation of the maintainer and the importance of the delivered feature might be more important than other qualities in terms of pull request acceptance.Conclusions. Researchers have already investigated the influence of the developers’ reputation and the pull request acceptance. This is the first work investigating code style violations and specifically PMD rules. We recommend that researchers further investigate this topic to understand if different measures or different tools could provide some useful measures."
Research article - A critical review on the evaluation of automated program repair systems,"AbstractAutomated Program Repair (APR) has attracted significant attention from software engineering research and practice communities in the last decade. Several teams have recorded promising performance in fixing real bugs and there is a race in the literature to fix as many bugs as possible from established benchmarks. Gradually, repair performance of APR tools in the literature has gone from being evaluated with a metric on the number of generated plausible patches to the number of correct patches. This evolution is necessary after a study highlighting the overfitting issue in test suite-based automatic patch generation. Simultaneously, some researchers are also insisting on providing time cost in the repair scenario as a metric for comparing state-of-the-art systems.In this paper, we discuss how the latest evaluation metrics of APR systems could be biased. Since design decisions (both in approach and evaluation setup) are not always fully disclosed, the impact on repair performance is unknown and computed metrics are often misleading. To reduce notable biases of design decisions in program repair approaches, we conduct a critical review on the evaluation of patch generation systems and propose eight evaluation metrics for fairly assessing the performance of APR tools. Eventually, we show with experimental data on 11 baseline program repair systems that the proposed metrics allow to highlight some caveats in the literature. We expect wide adoption of these metrics in the community to contribute to boosting the development of practical, and reliably performable program repair tools."
Research article - A comprehensive study of automatic program repair on the QuixBugs benchmark,"AbstractAutomatic program repair papers tend to repeatedly use the same benchmarks. This poses a threat to the external validity of the findings of the program repair research community. In this paper, we perform an empirical study of automatic repair on a benchmark of bugs called QuixBugs, which has been little studied. In this paper, (1) We report on the characteristics of QuixBugs; (2) We study the effectiveness of 10 program repair tools on it; (3) We apply three patch correctness assessment techniques to comprehensively study the presence of overfitting patches in QuixBugs. Our key results are: (1) 16/40 buggy programs in QuixBugs can be repaired with at least a test suite adequate patch; (2) A total of 338 plausible patches are generated on the QuixBugs by the considered tools, and 53.3% of them are overfitting patches according to our manual assessment; (3) The three automated patch correctness assessment techniques, RGTEvosuite, RGTInputSampling and GTInvariants, achieve an accuracy of 98.2%, 80.8% and 58.3% in overfitting detection, respectively. To our knowledge, this is the largest empirical study of automatic repair on QuixBugs, combining both quantitative and qualitative insights. All our empirical results are publicly available on GitHub in order to facilitate future research on automatic program repair."
