title,abstract
Research article - Don’t run on fumes—Parametric gas bounds for smart contracts,"AbstractGas is a measurement unit of the computational effort that it will take to execute every single replicated operation that takes part in the Ethereum blockchain platform. If a transaction exceeds the amount of gas allotted by the user (known as gas limit), an out-of-gas exception is raised and its execution is interrupted. One of the main open problems in the analysis of Ethereum smart contracts is the inference of sound bounds on their gas consumption.We present, to the best of our knowledge, the first static analysis that is able to infer sound parametric (i.e., non-constant) gas bounds for smart contracts. The inferred bounds can be parametric on the sizes of the input parameters for the functions, but also they can be parametric on the contract state, or blockchain data. Our gas analysis is developed at EVM bytecode level, in which Ethereum gas model is defined.Our analysis is implemented in a tool named Gastap, Gas-Aware Smart contracT Analysis Platform, which takes as input a smart contract and automatically infers sound gas upper-bounds for its public functions. Gastap has been applied over 318,093 functions fetched from the Ethereum blockchain, and succeeded to obtain gas bounds for 90.24% of them."
Research article - Building and evaluating a theory of architectural technical debt in software-intensive systems,"AbstractArchitectural technical debt in software-intensive systems is a metaphor used to describe the “big” design decisions (e.g., choices regarding structure, frameworks, technologies, languages, etc.) that, while being suitable or even optimal when made, significantly hinder progress in the future. While other types of debt, such as code-level technical debt, can be readily detected by static analyzers, and often be refactored with minimal or only incremental efforts, architectural debt is hard to be identified, of wide-ranging remediation cost, daunting, and often avoided.In this study, we aim at developing a better understanding of how software development organizations conceptualize architectural debt, and how they deal with it. In order to do so, in this investigation we apply a mixed empirical method, constituted by a grounded theory study followed by focus groups. With the grounded theory method we construct a theory on architectural technical debt by eliciting qualitative data from software architects and senior technical staff from a wide range of heterogeneous software development organizations. We applied the focus group method to evaluate the emerging theory and refine it according to the new data collected.The result of the study, i.e., a theory emerging from the gathered data, constitutes an encompassing conceptual model of architectural technical debt, identifying and relating concepts such as its symptoms, causes, consequences, management strategies, and communication problems. From the conducted focus groups, we assessed that the theory adheres to the four evaluation criteria of classic grounded theory, i.e., the theory fits its underlying data, is able to work, has relevance, and is modifiable as new data appears.By grounding the findings in empirical evidence, the theory provides researchers and practitioners with novel knowledge on the crucial factors of architectural technical debt experienced in industrial contexts."
Research article - Market-oriented online bi-objective service scheduling for pleasingly parallel jobs with variable resources in cloud environments,"AbstractIn this paper, we study the market-oriented online bi-objective service scheduling problem for pleasingly parallel jobs with variable resources in cloud environments, from the perspective of SaaS (Software-as-as-Service) providers who provide job-execution services. The main process of scheduling SaaS services in clouds is: a SaaS provider purchases cloud instances from IaaS providers to schedule end users’ jobs and charges users accordingly. This problem has several particular features, such as the job-oriented end users, the pleasingly parallel jobs with soft deadline constraints, the online settings, and the variable numbers of resources. For maximizing both the revenue and the user satisfaction rate, we design an online algorithm for SaaS providers to optimally purchase IaaS instances and schedule pleasingly parallel jobs. The proposed algorithm can achieve competitive objectives in polynomial run-time. The theoretical analysis and simulations based on real-world Google job traces as well as synthetic datasets validate the effectiveness and efficiency of our algorithm."
Research article - Code smell detection by deep direct-learning and transfer-learning,"AbstractContext:An excessive number of code smells make a software system hard to evolve and maintain. Machine learning methods, in addition to metric-based and heuristic-based methods, have been recently applied to detect code smells; however, current methods are considered far from mature.Objective:First, explore the feasibility of applying deep learning models to detect smells without extensive feature engineering. Second, investigate the possibility of applying transfer-learning in the context of detecting code smells.Methods:We train smell detection models based on Convolution Neural Networks and Recurrent Neural Networks as their principal hidden layers along with autoencoder models. For the first objective, we perform training and evaluation on C# samples, whereas for the second objective, we train the models from C# code and evaluate the models over Java code samples and vice-versa.Results:We find it feasible to detect smells using deep learning methods though the models’ performance is smell-specific. Our experiments show that transfer-learning is definitely feasible for implementation smells with performance comparable to that of direct-learning. This work opens up a new paradigm to detect code smells by transfer-learning especially for the programming languages where the comprehensive code smell detection tools are not available."
Research article - Data quality certification using ISO/IEC 25012: Industrial experiences,"AbstractThe most successful organizations in the world are data-driven businesses. Data is at the core of the business of many organizations as one of the most important assets, since the decisions they make cannot be better than the data on which they are based. Due to this reason, organizations need to be able to trust their data. One important activity that helps to achieve data reliability is the evaluation and certification of the quality level of organizational data repositories. This paper describes the results of the application of a data quality evaluation and certification process to the repositories of three European organizations belonging to different sectors. We present findings from the point of view of both the data quality evaluation team and the organizations that underwent the evaluation process. In this respect, several benefits have been explicitly recognized by the involved organizations after achieving the data quality certification for their repositories (e.g., long-term organizational sustainability better internal knowledge of data, and a more efficient management of data quality). As a result of this experience, we have also identified a set of best practices aimed to enhance the data quality evaluation process."
Research article - Studying test-driven development and its retainment over a six-month time span,"AbstractIn this paper, we investigate the effect of TDD, as compared to a non-TDD approach, as well as its retainment (or retention) over a time span of (about) six months. To pursue these objectives, we conducted a (quantitative) longitudinal cohort study with 30 novice developers (i.e., third-year undergraduate students in Computer Science). We observed that TDD affects neither the external quality of software products nor developers’ productivity. However, we observed that the participants applying TDD produced significantly more tests, with a higher fault-detection capability, than those using a non-TDD approach. As for the retainment of TDD, we found that TDD is retained by novice developers for at least six months."
Research article - SLA-aware multiple migration planning and scheduling in SDN-NFV-enabled clouds,"AbstractIn Software-Defined Networking (SDN)-enabled cloud data centers, live migration is a key approach used for the reallocation of Virtual Machines (VMs) and Virtual Network Functions (VNFs). Using live migration, cloud providers can address their dynamic resource management and fault tolerance objectives without interrupting the service of users. However, performing multiple live migrations in arbitrary order can lead to service degradation. Therefore, efficient migration planning is essential to reduce the impact of live migration overheads. In addition, to prevent Quality of Service (QoS) degradations and Service Level Agreement (SLA) violations, it is necessary to set priorities for different live migration requests with various urgency. In this paper, we propose SLAMIG, a set of algorithms that composes deadline-aware multiple migration grouping algorithm and on-line migration scheduling to determine the sequence of VM/VNF migrations. The experimental results show that our approach with reasonable algorithm runtime can efficiently reduce the number of deadline misses and has a good migration performance compared with the one-by-one scheduling and two state-of-the-art algorithms in terms of total migration time, average execution time, downtime, and transferred data. We also evaluate and analyze the impact of multiple migrations on QoS and energy consumption."
Research article - Multilayered review of safety approaches for machine learning-based systems in the days of AI,"AbstractThe unprecedented advancement of artificial intelligence (AI) in recent years has altered our perspectives on software engineering and systems engineering as a whole. Nowadays, software-intensive intelligent systems rely more on a learning model than thousands of lines of codes. Such alteration has led to new research challenges in the engineering process that can ensure the safe and beneficial behavior of AI systems. This paper presents a literature survey of the significant efforts made in the last fifteen years to foster safety in complex intelligent systems. This survey covers relevant aspects of AI safety research including safety requirements engineering, safety-driven design at both system and machine learning (ML) component level, validation and verification from the perspective of software and system engineers. We categorize these research efforts based on a three-layered conceptual framework for developing and maintaining AI systems. We also perform a gap analysis to emphasize the open research challenges in ensuring safe AI. Finally, we conclude the paper by providing future research directions and a road map for AI safety."
Research article - On introducing automatic test case generation in practice: A success story and lessons learned,"AbstractThe level and quality of automation dramatically affects software testing activities, determines costs and effectiveness of the testing process, and largely impacts on the quality of the final product. While costs and benefits of automating many testing activities in industrial practice (including managing the quality process, executing large test suites, and managing regression test suites) are well understood and documented, the benefits and obstacles of automatically generating system test suites in industrial practice are not well reported yet, despite the recent progresses of automated test case generation tools. Proprietary tools for automatically generating test cases are becoming common practice in large software organizations, and commercial tools are becoming available for some application domains and testing levels. However, generating system test cases in small and medium-size software companies is still largely a manual, inefficient and ad-hoc activity.This paper reports our experience in introducing techniques for automatically generating system test suites in a medium-size company. We describe the technical and organizational obstacles that we faced when introducing automatic test case generation in the development process of the company, and present the solutions that we successfully experienced in that context. In particular, the paper discusses the problems of automating the generation of test cases by referring to a customized ERP application that the medium-size company developed for a third party multinational company, and presents ABT2.0, the test case generator that we developed by tailoring ABT, a research state-of-the-art GUI test generator, to their industrial environment. This paper presents the new features of ABT2.0, and discusses how these new features address the issues that we faced."
Research article - Evaluating the effectiveness of risk containers to isolate change propagation,"AbstractPrevious studies indicate that error-proneness risks can be isolated into risk containers created from architectural designs, to help detect and mitigate such risks early on. Like error-proneness, change propagation may lead to higher implementation and maintenance costs. We used automated tools to analyse four software development projects using three risk container types, each type based on a different architectural perspective. A strong and significant correlation between design change propagation and implementation co-change was observed for all three container types. We found that Design Rule Containers (DRCs), based on class diagrams, are the most effective for isolating change propagation because they have the least amount of container overlap, highest levels of internal coupling, highest co-change probability between classes that share containers, and the most change sets isolated in containers. Developers from two projects were able to justify why design dependencies had resulted in the top five DRCs being predicted to isolate the most change propagation. This and the previous error-proneness research suggests DRCs are an effective technique to detect and contain code maintainability risks at the design stage. These results provide some evidence that class diagrams are more useful than use case sequence diagrams for analysing maintainability risks in designs."
Research article - Facilitating program comprehension with call graph multilevel hierarchical abstractions,"AbstractProgram comprehension is a fundamental prerequisite for software maintenance and evolution. In order to understand a software structure, developers often read its codebase or documentation—if available and not outdated. Both approaches are tedious, time-consuming, and inefficient. Recent methods and tools have emerged to facilitate program comprehension, such as static call graphs, which depict the structure of the software system as a directed graph. However, the usage of call graphs still faces two main challenges: (1) large call graphs can be difficult to understand, and (2) they are limited to a single level of granularity, such as function calls. In this paper, we introduce a coarsening technique to create multi-level, hierarchical representations of the call graph. Specifically, we propose a hierarchical clustering approach of the execution paths to visualize the call graph at different granularity levels and for different software units, including packages, classes, and functions. Our overarching goal is to assist software developers in understanding the software system from a high-level of abstraction to the low-level of implementation with the ability to focus on particular parts of the system individually. To validate our approach and tool support, we conducted a user study of 18 software engineers from more than 11 industries who carried out several tasks using our system and then answered a survey. The results demonstrate that our approach is feasible to automatically construct multi-level abstractions of the call graph and hierarchically cluster them into meaningful abstractions. A video demo of the tool is available at https://rakanalanazi.github.io/CodEx/."
Research article - Product-line assurance cases from contract-based design,"AbstractAssurance cases are used to argue in a structured, and evidence-supported way, that a property such as safety or security is satisfied by a system. In some domains however, instead of single systems, product lines with many system-variants are engineered, to satisfy the needs of different customers. In such context, single-system methods for assurance-case creation suffer from scalability issues because the underlying assumption is that the evidence and arguments can be created per system variant. This paper presents a novel method for product-line assurance-case creation where all the arguments and the evidence are created without analyzing each system variant. Consequently, the effort to create an assurance case scales with the complexity of system variants, instead with their number. The method is based on a contract-based design framework for cyber–physical systems, which is extended to define the conditions under which all system variants satisfy a particular property. These conditions are used to define an assurance-case pattern, which can be instantiated for arbitrary product lines. Moreover, the defined pattern is modular to enable step-wise assurance-case creation. Finally, an exploratory case study is performed on a real product-line from the heavy-vehicle manufacturer Scania to evaluate the applicability of the presented method."
Research article - A comparative study of test code clones and production code clones,"AbstractClones are one of the most widespread code smells, known to negatively affect the evolution of software systems. While there is a large body of research on detecting, managing, and refactoring clones in production code, clones in test code are often neglected in today’s literature. In this paper we provide empirical evidence that further research on clones in test code is warranted. By analysing the clones in five representative open-source systems and comparing production code clones to test code clones, we observe that test code contains twice as many clones as production code. A detailed analysis reveals that most test clones are of Type II and Type III, and that many tests are duplicated multiple times with slight modifications. Moreover, current clone detection tools suffer from false negatives, and that this occurs more frequently in test code than in production code (NiCad = 76%, CPD = 90%, iClones = 12%). So even from a tools perspective, specific fine-tuning for test code is needed."
