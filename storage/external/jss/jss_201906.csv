title,abstract
Research article - Latency-aware Virtualized Network Function provisioning for distributed edge clouds,"AbstractThe emergence of Network Function Virtualization (NFV) enabled decoupling network functionality from dedicated hardware and placing them upon generic computing resources. Moreover, the introduction of edge computing paradigm which utilized the resources at the network edges brings reduced end-to-end latency. With these technologies, Virtualized Network Functions (VNFs) can be placed in anywhere either in the central clouds to utilize more resources or in the network edges to reduce the end-to-end latency.In this work, we propose a dynamic resource provisioning algorithm for VNFs to utilize both edge and cloud resources. Adapting to dynamically changing network volumes, the algorithm automatically allocates resources in both the edge and the cloud for VNFs. The algorithm considers the latency requirement of different applications in the service function chain, which allows the latency-sensitive applications to reduce the end-to-end network delay by utilizing edge resources over the cloud. We evaluate our algorithm in the simulation environment with large-scale web application workloads and compare with the state-of-the-art baseline algorithm. The result shows that the proposed algorithm reduces the end-to-end response time by processing 77.9% more packets in the edge nodes compared to the application non-aware algorithm."
Research article - Execution allowance based fixed priority scheduling for probabilistic real-time systems,AbstractReal-time systems tend to be probabilistic in nature because of the performance variations of complex chips. We present an execution allowance based fixed priority scheduling scheme for probabilistic real-time systems. This scheme consists of a probabilistic Worst Case Execution Time reshaping algorithm and a fixed priority scheduling strategy. It assigns a specific execution allowance to each task and schedules tasks under the Rate Monotonic policy. We present a schedulability analysis and show how to determine an appropriate execution allowance for each task. Evaluation shows that our proposed scheme can significantly outperform the existing approaches.
Research article - How enterprise architecture improves the quality of IT investment decisions,"AbstractAccording to literature, enterprise architecture (EA) is supposed to support IT investment decision-making. However, it is not yet clear how EA can do that. The objective of this study is to explore how EA can support IT investment decisions. A quantitative research approach was chosen, in which data were collected from a survey of 142 participants. These data were used to perform a comparative analysis between top and bottom quartile organizations on 1) the EA maturity, 2) the use of EA artifacts in the preparation of IT investments, and 3) the key insights that EA provides in preparation of IT investments. We found that top quartile organizations are more mature in all EA maturity areas. They also make more extensive use of different types of EA artifacts in the preparation of IT investment decisions, especially diagnostic and actionable artifacts. Finally, EA provides top quartile organizations with more key insights in the preparation of IT investment decisions, and in particular, strategic insights. As a result of our research we created a conceptual model that integrates seven propositions. Further research is required to test these propositions and develop instruments to aid enterprise architects to effectively support IT investment decisions."
Research article - An auction-based incentive mechanism for heterogeneous mobile clouds,"AbstractTraditional mobile cloud computing (MCC) adopts a onefold mobile device and public cloud paradigm. As the mobile device capabilities continue to develop, their opportunistic utilization in MCC has recently gained popularity. The new paradigm is a hybrid/heterogeneous mobile cloud (HMC) where mobile devices, cloudlets, and private/public cloud form a shared resource network for task offloading. However, mobile device users are discouraged from sharing their devices for running foreign tasks due to the battery life and privacy concerns. To incentivize mobile device users to utilize and participate in the HMC offloading service, we designed a task offloading market for the HMC service, where a mobile user can compete as a seller with others by bidding its redundant computing resources, and another mobile user as a buyer can pay the bidding price and offload the task to the winning user. To enable an incentive and fair competition of the mobile cloud offloading market, we propose a reverse auction-based incentive mechanism, mCloudAuc, to provide real-time auctions. The proposed auction algorithm demonstrates computation efficiency, truthfulness, and individual rationality for the participants through proof and multiple simulations. Our prototype implementation of mCloudAuc on Android platform has also shown its feasibility in practice."
"Research article - Not all bugs are the same: Understanding, characterizing, and classifying bug types","AbstractModern version control systems, e.g., GitHub, include bug tracking mechanisms that developers can use to highlight the presence of bugs. This is done by means of bug reports, i.e., textual descriptions reporting the problem and the steps that led to a failure. In past and recent years, the research community deeply investigated methods for easing bug triage, that is, the process of assigning the fixing of a reported bug to the most qualified developer. Nevertheless, only a few studies have reported on how to support developers in the process of understanding the type of a reported bug, which is the first and most time-consuming step to perform before assigning a bug-fix operation. In this paper, we target this problem in two ways: first, we analyze 1280 bug reports of 119 popular projects belonging to three ecosystems such as Mozilla, Apache, and Eclipse, with the aim of building a taxonomy of the types of reported bugs; then, we devise and evaluate an automated classification model able to classify reported bugs according to the defined taxonomy. As a result, we found nine main common bug types over the considered systems. Moreover, our model achieves high F-Measure and AUC-ROC (64% and 74% on overall, respectively)."
Research article - Energy-efficient low-latency audio on android,"AbstractCounting more than two billion devices, Android is nowadays one of the most popular open-source general-purpose operating systems, based on Linux. Because of the diversity of applications that can be installed, it manages a number of different workloads, many of them requiring performance/QoS guarantees. When running audio processing applications, the user would like an uninterrupted, glitch-free, output stream that reacts to the user input, typically with a delay not bigger than 4−10 ms, while keeping the energy consumption of the mobile device as low as possible.This work focuses on improvements to the real-time audio processing performance on Android. Such improvements are achieved by using a deadline based scheduler and an adaptive scheduling strategy that dynamically and proactively modulates the allocated runtime. The proposed strategy is evaluated through an extensive set of experiments, showing that (1) compared to the existing way to ensure low-latency audio processing, the proposed mechanism provides an energy saving of almost 40%, and (2) compared to the existing way to achieve a good balance between power consumption and latency in a glitch-free audio processing experience, the proposed solution reduces audio latency from 26.67 ms to 2.67 ms, at the expense of a limited power consumption increase of 6.25%."
Research article - Co-change patterns: A large scale empirical study,"AbstractCo-Change Clustering is a modularity assessment technique that reveals how often changes are localized in modules and whether a change propagation represents design problems. This technique is centered on co-change clusters, which are highly inter-related source code files considering co-change relations. In this paper, we conduct a series of empirical analysis in a large corpus of 133 popular software projects on GitHub. We describe six co-change patterns by projecting them over the directory structure. We mine 1802 co-change clusters and 1719 co-change clusters (95%) are covered by the six co-change patterns. In this study, we aim to answer two central questions: (i) Are co-change patterns detected in different programming languages? (ii) How do different co-change patterns relate to rippling, activity density, ownership, and team diversity on clusters? We conclude that Encapsulated and Well-Confined clusters (Wrapped) implement well-defined and confined concerns. Octopus clusters are proportionally numerous regarding to other patterns. They relate significantly with ripple effect, activity, ownership, and diversity in development teams. Although Crosscutting are scattered over directories, they implement well-defined concerns. Despite they present higher activity compared to Wrapped clusters, it is not necessarily easy to get rid of them, suggesting that support tools may play a crucial role."
Research article - An empirical study on pareto based multi-objective feature selection for software defect prediction,"AbstractThe performance of software defect prediction (SDP) models depend on the quality of considered software features. Redundant features and irrelevant features may reduce the performance of the constructed models, which require feature selection methods to identify and remove them. Previous studies mostly treat feature selection as a single objective optimization problem, and multi-objective feature selection for SDP has not been thoroughly investigated. In this paper, we propose a novel method MOFES (Multi-Objective FEature Selection), which takes two optimization objectives into account. One optimization objective is to minimize the number of selected features, this objective is related to the cost analysis of this problem. Another objective is to maximize the performance of the constructed SDP models, this objective is related to the benefit analysis of this problem. MOFES utilizes Pareto based multi-objective optimization algorithms (PMAs) to solve this problem. In our empirical study, we design and conduct experiments on RELINK and PROMISE datasets, which are gathered from real open source projects. Firstly, we analyze the influence of different PMAs on MOFES and find that NSGA-II can achieve the best performance on both datasets. Then, we compare MOFES method with 22 state-of-the-art filter based and wrapper based feature selection methods, and find that MOFES can effectively select fewer but closely related features to construct high-quality models. Moreover, we also analyze the frequently selected features by MOFES, and these findings can be used to provide guidelines on gathering high-quality SDP datasets. Finally, we analyze the computational cost of MOFES and find that MOFES only needs 107 seconds on average."
Review article - A survey of self-admitted technical debt,"AbstractTechnical Debt is a metaphor used to express sub-optimal source code implementations that are introduced for short-term benefits that often need to be paid back later, at an increased cost. In recent years, various empirical studies have focused on investigating source code comments that indicate Technical Debt often referred to as Self-Admitted Technical Debt (SATD). Since the introduction of SATD as a concept, an increasing number of studies have examined various aspects pertaining to SATD. Therefore, in this paper we survey research work on SATD, analyzing the characteristics of current approaches and techniques for SATD detection, comprehension, and repayment. To motivate the submission of novel and improved work, we compile tools, resources, and data sets made available to replicate or extend current SATD research. To set the stage for future work, we identify open challenges in the study of SATD, areas that are missing investigation, and discuss potential future research avenues."
Review article - ElasticSFC: Auto-scaling techniques for elastic service function chaining in network functions virtualization-based clouds,"AbstractIt is anticipated that future networks support network functions, such as firewalls, load balancers and intrusion prevention systems in a fully automated, flexible, and efficient manner. In cloud computing environments, network functions virtualization (NFV) aims to reduce cost and simplify operations of such network services through the virtualization technologies. To enforce network policies in NFV-based cloud environments, network services are composed of virtualized network functions (VNFs) that are chained together as service function chains (SFCs). All network traffic matching a policy must traverse network functions in the chain in a sequence to comply with it. While SFC has drawn considerable attention, relatively little has been given to dynamic auto-scaling of VNF resources in the service chain. Moreover, most of the existing approaches focus only on allocating computing and network resources to VNFs without considering the quality of service requirements of the service chain such as end-to-end latency. Therefore, in this paper, we define a unified framework for building elastic service chains. We propose a dynamic auto-scaling algorithm called ElasticSFC to minimize the cost while meeting the end-to-end latency of the service chain. The experimental results show that our proposed algorithm can reduce the cost of SFC deployment and SLA violation significantly."
Research article - Systematic composition of independent language features,"AbstractSystematic reuse is crucial to efficiently engineer and deploy software languages to software experts and domain experts alike. But “software languages are software too”, and hence their engineering, customization, and reuse are subject to similar challenges. To this effect, we propose an approach for composing independent, grammar-based language syntax modules in a structured way that realizes a separation of concerns among the participants in the life cycle of the languages. We present a refined concept of systematic and controlled syntactic variability of extensible software language product lines through identification of syntax variation points and derivation of variants from independently developed features. This facilitates reuse of software languages and reduces the efforts of engineering and customizing languages for specific domains. We realized our concept with the MontiCore language workbench and assessed it through a case study on architecture description languages. Ultimately, systematic and controlled software language reuse reduces the effort of software language engineering and fosters the applicability of software languages."
Research article - Where is my feature and what is it about? A case study on recovering feature facets,"AbstractDevelopers commonly use features to define, manage, and communicate functionalities of a system. Unfortunately, the locations of features in code and other characteristics (feature facets), relevant for evolution and maintenance, are often poorly documented. Since developers change, and knowledge fades with time, such information often needs to be recovered. Modern projects boast a richness of information sources, such as pull requests, release logs, and otherwise specified domain knowledge. However, it is largely unknown from what sources the features, their locations, and their facets can be recovered. We present an exploratory study on identifying such information in two popular, variant-rich, and long-living systems: The 3D-printer firmware Marlin and the Android application Bitcoin-wallet. Besides the available information sources, we also investigated the projects’ communities, communications, and development cultures. Our results show that a multitude of information sources (e.g., commit messages and pull requests) is helpful to recover features, locations, and facets to different extents. Pull requests were the most valuable source to recover facets, followed by commit messages and the issue tracker. As many of the studied information sources are, so far, rarely exploited in techniques for recovering features and their facets, we hope to inspire researchers and tool builders with our results."
Research article - Synthesizing tradeoff spaces with quantitative guarantees for families of software systems,"AbstractDesigning software in a way that guarantees run-time behavior while achieving an acceptable balance among multiple quality attributes is an open problem. Providing guarantees about the satisfaction of the same requirements under uncertain environments is even more challenging. Tools and techniques to inform engineers about poorly-understood design spaces in the presence of uncertainty are needed, so that engineers can explore the design space, especially when tradeoffs are crucial. To tackle this problem, we describe an approach that combines synthesis of spaces of system design alternatives from formal specifications of architectural styles with probabilistic formal verification. The main contribution of this paper is a formal framework for specification-driven synthesis and analysis of design spaces that provides formal guarantees about the correctness of system behaviors and satisfies quantitative properties (e.g., defined over system qualities) subject to uncertainty, which is treated as a first-class entity. We illustrate our approach in two case studies: a service-based adaptive system and a mobile robotics architecture. Our results show how the framework can provide useful insights into how average case probabilistic guarantees can differ from worst case guarantees, emphasizing the relevance of combining quantitative formal verification methods with structural synthesis, in contrast with techniques based on simulation and dynamic analysis that can only provide estimates about average case probabilistic properties."
Research article - Modelling equivalence classes of feature models with concept lattices to assist their extraction from product descriptions,"AbstractSoftware product line engineering gathers a set of methods to help create, manage and maintain a collection of similar software systems. Variability modelling is a focal point of this paradigm, where feature models (FMs) are the prevalent notation. Migration from single system development to software product lines is a spreading topic in software engineering. To ease the migration, research has been done to automatically extract FMs from software descriptions, but most of these approaches are defined in a functional manner based on an ad-hoc variability analysis. In this paper, we propose a theoretical view on FM extraction from software descriptions based on Formal Concept Analysis (FCA). It is a structural framework for variability representation which allows to lay down theoretical foundation to variability extraction. We propose an original mapping between relationships expressed in FMs and the ones emphasised in FCA conceptual structures. We show that conceptual structures represent equivalence classes of FMs that steer the user choices during their synthesis, and propose a reverse engineering method based on them. We discuss its applicability and show that the combinatorial explosion of concept lattices can be avoided by the use of two sub-orders embodying the necessary information concerning variability."
Research article - Feature-oriented contract composition,"AbstractA software product line comprises a set of products that share a common code base, but vary in specific characteristics called features. Ideally, features of a product line are developed in isolation and composed subsequently. Product lines are increasingly used for safety–critical software, for which quality assurance becomes indispensable. While the verification of product lines gained considerable interest in research over the last decade, the subject of how to specify product lines is only covered rudimentarily. A challenge to overcome is composition; similar to inheritance in object-oriented programming, features of a product line may refine other features along with their specifications. To investigate how refinement and composition of specifications can be established, we derive a notion of feature-oriented contracts comprising preconditions, postconditions, and framing conditions of a method. We discuss six mechanisms to perform contract composition between original and refining contracts. Moreover, we identify and discuss desired properties for contract composition and evaluate which properties are established by which mechanism. Our three main insights are that (a) contract refinement is seldom but crucial, (b) the Liskov principle does not apply to features, and (c) it is sufficient to accommodate techniques from object-orientation in the contract-composition mechanisms for handling frame refinements."
