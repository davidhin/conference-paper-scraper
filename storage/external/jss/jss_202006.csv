title,abstract
Research article - Using likely invariants for test data generation,"AbstractVarious approaches have been developed to tackle the problem of automatic test data generation. Among them search-based methods use metaheuristic algorithms to guide search in the input space of the program under test. This paper presents a new approach for improving search-based test data generation methods. This approach is based on learning the relationships between program input values and program parts covered by those values. The learned relationships are used to accelerate achieving test coverage goals. We introduce the concepts of branch likely invariant and path likely invariant as the basis for the learning method. In addition, we utilize simple predicates (based on some predefined templates) over program input variables to generate better initial candidate solutions, and use the mutation of the mentioned predicates to cover unexplored program parts. The current version of the proposed approach only considers numeric and string input parameters. To evaluate the performance of the proposed approach, a series of experiments have been carried out on a number of different benchmark programs. Through experiments and analysis, we show that the proposed approach enhances the effectiveness of common search-based test data generation methods, in terms of the coverage percentage."
Research article - The effect of transactive memory systems on process tailoring in software projects: The moderating role of task conflict and shared temporal cognitions,"AbstractContemporary software projects are unique and volatile, leading development teams to modify standard development processes and continue to make adjustments as needed. Adjusting software project development to accommodate the variance and dynamics is called software process tailoring (SPT). Because SPT critically determines how projects are conducted, its performance merits investigation. However, the extant literature lacks empirical evidence of the underlying effects that operate and influence the performance of SPT. Specifically, SPT is a team-based activity that requires the exchange of knowledge and opinions among members to yield an integrative tailoring solution; SPT is also a highly conflicting process involving task and temporal conflicts. Given these characteristics, teams’ operational mechanisms that increase SPT performance remain unknown. To address the aforementioned gaps, this study adopts the transactive memory systems (TMS) theory to develop a research model to explore how a team's TMS affects SPT performance with task conflict and shared temporal cognitions (STC) acting as moderators. By examining 102 software project teams, we found that TMS has a positive impact on SPT performance. Surprisingly, task conflict reduces the effect of TMS on SPT performance, whereas STC amplifies the influence of TMS-SPT performance."
Research article - Requirements for adopting software process lines,"AbstractA Software Process Line (SPrL) is potentially suitable for constructing software development methodologies by reusing core assets. However, adopting this approach without prior assessment of its suitability can lead to failure. The aim of this paper is to identify a set of requirements that can be used for deciding whether to adopt the SPrL approach in an organization. Identification of the requirements was accomplished in two stages: the characteristics important in method tailoring were first identified via a Systematic Mapping Study (SMS) that focused on analyzing 43 primary studies; the degree of importance of the identified characteristics was then determined using a questionnaire survey in which 31 experts participated. By analyzing the results of the SMS and the survey, we have identified 12 product-related, 22 project-related, and 10 organization-related requirements. In addition to these requirements, we have also identified two relevant requirements by studying previous research on Software Product Lines (SPL) and Business Process Lines (BPL). The requirements thus identified can help organizations decide on whether to adopt the SPrL approach: the more an organization satisfies the requirements, the more frequently method tailoring occurs in that organization, and hence, the more justified it is to adopt the SPrL approach."
Research article - Lexical content as a cooperation aide: A study based on Java software,"AbstractCollaborative development is a paradigm shift in software development. Loosely coupled developers coordinate their work via distributed versioning systems (SVN, Git, and others), code reviews and priority-led bug tracking systems. This development approach allows many different developers to input additional source code to the same source artifact.This article focuses on the lexical content of the source code produced in a collaborative environment. The lexical content is described as the ‘dictionary’ of the key terms contained within a source artifact. We posit that the lexical content of a Java class will increase as long as more developers add more content to the same class.We analyse the 100 top-ranked GitHub applications (at the time of the sampling) written in Java. Each of their classes is reduced to its lexical content, its size (in LOCs) recorded, as well as the number of different developers who contributed to its source code.Our results show that (i) the lexical content of Java classes is bounded in size, (ii) more developers make the size of the lexical content larger, and (iii) the lexical content of a system’s classes might increase with more developers, but depending on its application domain.The implications for practitioners are two-fold: (i) classes with a large set of lexical content should be split in multiple classes, to minimize the need for further maintenance; and (ii) classes developed by many developers should adhere to specific guidelines so that its lexical content does not increase boundlessly. We tested our results in a tailored case study and we confirmed our findings: larger-than-threshold class corpora tend to deteriorate the class cohesion."
Research article - ARC: Anomaly-aware Robust Cloud-integrated IoT service composition based on uncertainty in advertised quality of service values,"AbstractFrom the IoT perspective, each intelligent device can be considered as a potential source of service. Since several services perform the same function, albeit with different quality of service (QoS) parameters, service composition becomes a crucial problem to find an optimal set of services to automate a typical business process. The majority of prior research has investigated the service composition problem with the assumption that advertised QoS values are deterministic and do not change over time. However, factors like sensors failure and network topology changes cause uncertainty in the advertised QoS values. To address this challenge, we propose a novel Anomaly-aware Robust service Composition (ARC) to deal with the problem of uncertainty of QoS values in a dynamic environment of Cloud and IoT. The proposed approach uses Bertsimas and Sim mathematical robust optimization method, which is independent of the statistical distribution of QoS values, to compose services. Moreover, our approach exploits a machine learning-based anomaly detection technique to improve the stability of the solution with a fine-grained identification of abnormal QoS records. The results demonstrate that our approach achieves 14.55% of the average improvement in finding optimal solutions compared to the previous works, such as information theory-based and clustering-based methods."
Research article - On testing machine learning programs,"AbstractNowadays, we are witnessing a wide adoption of Machine learning (ML) models in many software systems. They are even being tested in safety-critical systems, thanks to recent breakthroughs in deep learning and reinforcement learning. Many people are now interacting with systems based on ML every day, e.g., voice recognition systems used by virtual personal assistants like Amazon Alexa or Google Home. As the field of ML continues to grow, we are likely to witness transformative advances in a wide range of areas, from finance, energy, to health and transportation. Given this growing importance of ML-based systems in our daily life, it is becoming utterly important to ensure their reliability. Recently, software researchers have started adapting concepts from the software testing domain (e.g., code coverage, mutation testing, or property-based testing) to help ML engineers detect and correct faults in ML programs. This paper reviews current existing testing practices for ML programs. First, we identify and explain challenges that should be addressed when testing ML programs. Next, we report existing solutions found in the literature for testing ML programs. Finally, we identify gaps in the literature related to the testing of ML programs and make recommendations of future research directions for the scientific community. We hope that this comprehensive review of software testing practices will help ML engineers identify the right approach to improve the reliability of their ML-based systems. We also hope that the research community will act on our proposed research directions to advance the state of the art of testing for ML programs."
Research article - Leading successful government-academia collaborations using FLOSS and agile values,"AbstractGovernment and academia share concerns for efficiently and effectively servicing societal demands, which includes the development of e-government software. Government-academia partnerships can be a valuable approach for improving productivity in achieving these goals. However, governmental and academic institutions tend to have very different agendas and organizational and managerial structures, which can hinder the success of such collaborative projects. In order to identify effective approaches to overcome collaboration barriers, we systematically studied the case of the Brazilian Public Software portal project, a 30-month government-academia collaboration that, using Free/Libre/Open Source Software practices and agile methods for project management, developed an unprecedented platform in the context of the Brazilian government. We gathered information from experience reports and data collection from repositories and interviews to derive a collection of practices that contributed to the success of the collaboration. In this paper, we describe how the data analysis led to the identification of a set of three high-level decisions supported by the adoption of nine best practices that improved the project performance and enabled professional training of the whole team."
Research article - MSL: A pattern language for engineering self-adaptive systems,"AbstractIn architecture-based self-adaptation of decentralized systems, design patterns have been introduced to ease the design of complex adaptation solutions that usually require the interaction of different MAPE-K (Monitor-Analyze-Plan-Execute over a shared Knowledge) control loops, each dealing with an adaptation concern of the managed system. Such MAPE patterns have been proposed by means of a graphical notation, but without a well-defined way to document them and to express the semantics of components interactions.In this paper, we propose an approach to overcome these limitations. We present a domain-specific language, called MSL for MAPE Specification Language, to define and instantiate MAPE patterns and to give semantics to some semantic variation points of the equivalent graphical notation for MAPE pattern. We also provide a formal semantics of the language by means of self-adaptive Abstract State Machines, an extension of the Abstract State Machines (ASMs) formalism to model self-adaptation. Such semantics definition comes with an automatic transformation of MSL models into formal executable models, and opens to the possibility of performing rigorous analysis (validation w.r.t. the adaptation requirements and verification of adaptation properties) of MSL models. Moreover, we present our current results toward a (long-term) realization of an MSL-centric framework, where MSL is the notation of a modeling front-end, on top of richer and more specific modeling, analysis, and implementation back-end frameworks.As proof of concept of our approach, we show the application of MSL and its formal support to a running case study in the field of home automation, by modeling an adaptive control of a virtual smart home developed with the OpenHAB runtime platform."
Research article - On Adaptive Change Recommendation,"AbstractAs the complexity of a software system grows, it becomes harder for developers to be aware of all the dependencies between its artifacts (e.g., files or methods). Change impact analysis helps to overcome this challenge, by recommending relevant source-code artifacts related to a developer’s current changes. Association rule mining has shown promise in determining change impact by uncovering relevant patterns in the system’s change history.State-of-the-art change impact mining typically uses a change history of tens of thousands of transactions. For efficiency, targeted association rule mining constrains the transactions used to those potentially relevant to answering a particular query. However, it still considers all the relevant transactions in the history.This paper presents Atari, a new adaptive approach that further constrains targeted association rule mining by considering a dynamic selection of the relevant transactions. Our investigation of adaptive change impact mining empirically studies fourteen algorithm variants. We show that adaptive algorithms are viable, can be just as applicable as the start-of-the-art complete-history algorithms, and even outperform them for certain queries. However, more important than this direct comparison, our investigation motivates and lays the groundwork for the future study of adaptive techniques, and their application to challenges such as on-the-fly impact analysis at GitHub-scale."
Research article - Satisfaction and its correlates in agile software development,"AbstractIn this paper we address the topic of software development team members satisfaction with their development process. We present an in-depth analysis of the results of a nationwide survey about software development in Switzerland. We wanted to find out if satisfaction relates to the applied development method, and to the use of various practices, and impacts on business, team and software issues. We found that higher satisfaction is reported more by those using Agile development than with plan-driven processes. We explored the different perspectives of developers and those with a management role and found a high consistency of satisfaction between Agile developers and Agile management, and differences with those using working plan-driven methods. We found that certain practices and impacts have high correlations to satisfaction, and that collaborative processes are closely related to satisfaction. We then explored the relationship between satisfaction and various other perspectives. Our results in this analysis are principally descriptive, but we think they can be a relevant contribution to understand the challenges for everyone involved in Agile development."
Research article - Modeling programs hierarchically with stack-augmented LSTM,"AbstractProgramming language modeling has attracted extensive attention in recent years, and it plays an essential role in program processing fields. Statistical language models, which are initially designed for natural languages, have been generally used for modeling programming languages. However, different from natural languages, programming languages contain explicit and hierarchical structure that is hard to learn by traditional statistical language models. To address this challenge, we propose a novel Stack-Augmented LSTM neural network for programming language modeling. Adding a stack memory component into the LSTM network enables our model to capture the hierarchical information of programs through the PUSH and POP operations, which further allows our model capturing the long-term dependency in the programs. We evaluate the proposed model on three program analysis tasks, i.e., code completion, program classification, and code summarization. Evaluation results show that our proposed model outperforms baseline models in all the three tasks, indicating that by capturing the structural information of programs with a stack, our proposed model can represent programs more precisely."
