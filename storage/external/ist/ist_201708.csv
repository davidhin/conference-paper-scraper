title,abstract
Review article - Test case design for context-aware applications: Are we there yet?,"AbstractContextCurrent software systems have increasingly implemented context-aware adaptations to handle the diversity of conditions of their surrounding environment. Therefore, people are becoming used to a variety of context-aware software systems (CASS). This context-awareness brings challenges to the software construction and testing because the context is unpredictable and may change at any time. Therefore, software engineers need to consider the dynamic context changes while testing CASS. Different test case design techniques (TCDT) have been proposed to support the testing of CASS. However, to the best of our knowledge, there is no analysis of these proposals on the advantages, limitations and their effective support to context variation during testing. ObjectiveTo gather empirical evidence on TCDT concerned with CASS by identifying, evaluating and synthesizing knowledge available in the literature.MethodTo undertake a secondary study (quasi-Systematic Literature Review) on TCDT for CASS regarding their assessed quality characteristics, used coverage criteria, test type, and test technique.ResultsFrom 833 primary studies published between 2004 and 2014, just 17 studies regard the design of test cases for CASS. Most of them focus on functional suitability. Furthermore, some of them take into account the changes in the context by providing specific test cases for each context configuration (static perspective) during the test execution. These 17 studies revealed five challenges affecting the design of test cases and 20 challenges regarding the testing of CASS. Besides, seven TCDT are not empirically evaluated.ConclusionA few TCDT partially support the testing of CASS. However, it has not been observed evidence on any TCDT supporting the truly context-aware testing, which that can adapt the expected output based on the context variation (dynamic perspective) during the test execution. It is an open issue deserving greater attention from researchers to increase the testing coverage and ensure users confidence in CASS."
Research article - A genetic algorithm-based approach for automated refactoring of component-based software,"AbstractContext: During its lifecycle, a software system undergoes repeated modifications to quickly fulfill new requirements, but its underlying design is not properly adjusted after each update. This leads to the emergence of bad smells. Refactoring provides a de facto behavior-preserving approach to eliminate these anomalies. However, manually determining and performing useful refactorings is a formidable challenge, as stated in the literature. Therefore, framing object-oriented automated refactoring as a search-based technique has been proposed. However, the literature shows that search-based refactoring of component-based software has not yet received proper attention.Objective: This paper presents a genetic algorithm-based approach for the automated refactoring of component-based software. This approach consists of detecting component-relevant bad smells and eliminating these bad smells by searching for the best sequence of refactorings using a genetic algorithm.Method: Our approach consists of four steps. The first step includes studying the literature related to component-relevant bad smells and formulating bad smell detection rules. The second step involves proposing a catalog of component-relevant refactorings. The third step consists of constructing a source code model by extracting facts from the source code of a component-based software. The final step seeks to identify the best sequence of refactorings to apply to reduce the presence of bad smells in the source code model using a genetic algorithm. The latter uses bad smell detection rules as a fitness function and the catalog of refactorings as a means to explore the search space.Results: As a case study, we conducted experiments on an unbiased set of four real-world component-based applications. The results indicate that our approach is able to efficiently reduce the total number of bad smells by more than one half, which is an acceptable value compared to the recent literature. Moreover, we determined that our approach is also accurate in refactoring only components suffering from bad smells while leaving the remaining components untouched whenever possible. Furthermore, a statistical analysis shows that our genetic algorithm outperforms random search and local search in terms of efficiency and accuracy on almost all the systems investigated in this work.Conclusion: This paper presents a search-based approach for the automated refactoring of component-based software. To the best of our knowledge, our approach is the first to focus on component-based refactoring, whereas the state-of-the-art approaches focus only on object-oriented refactoring."
Research article - Benefits and drawbacks of software reference architectures: A case study,"AbstractContextSoftware Reference Architectures (SRAs) play a fundamental role for organizations whose business greatly depends on the efficient development and maintenance of complex software applications. However, little is known about the real value and risks associated with SRAs in industrial practice.ObjectiveTo investigate the current industrial practice of SRAs in a single company from the perspective of different stakeholders.MethodAn exploratory case study that investigates the benefits and drawbacks perceived by relevant stakeholders in nine SRAs designed by a multinational software consulting company.ResultsThe study shows the perceptions of different stakeholders regarding the benefits and drawbacks of SRAs (e.g., both SRA designers and users agree that they benefit from reduced development costs; on the contrary, only application builders strongly highlighted the extra learning curve as a drawback associated with mastering SRAs). Furthermore, some of the SRA benefits and drawbacks commonly highlighted in the literature were remarkably not mentioned as a benefit of SRAs (e.g., the use of best practices). Likewise, other aspects arose that are not usually discussed in the literature, such as higher time-to-market for applications when their dependencies on the SRA are managed inappropriately.ConclusionsThis study aims to help practitioners and researchers to better understand real SRAs projects and the contexts where these benefits and drawbacks appeared, as well as some SRA improvement strategies. This would contribute to strengthening the evidence regarding SRAs and support practitioners in making better informed decisions about the expected SRA benefits and drawbacks. Furthermore, we make available the instruments used in this study and the anonymized data gathered to motivate others to provide similar evidence to help mature SRA research and practice."
Research article - Less is more: Minimizing code reorganization using XTREE,"AbstractContext: Developers use bad code smells to guide code reorganization. Yet developers, textbooks, tools, and researchers disagree on which bad smells are important. How can we offer reliable advice to developers about which bad smells to fix?Objective: To evaluate the likelihood that a code reorganization to address bad code smells will yield improvement in the defect-proneness of the code.Method: We introduce XTREE, a framework that analyzes a historical log of defects seen previously in the code and generates a set of useful code changes. Any bad smell that requires changes outside of that set can be deprioritized (since there is no historical evidence that the bad smell causes any problems).Evaluation: We evaluate XTREE’s recommendations for bad smell improvement against recommendations from previous work (Shatnawi, Alves, and Borges) using multiple data sets of code metrics and defect counts.Results: Code modules that are changed in response to XTREE’s recommendations contain significantly fewer defects than recommendations from previous studies. Further, XTREE endorses changes to very few code metrics, so XTREE requires programmers to do less work. Further, XTREE’s recommendations are more responsive to the particulars of different data sets. Finally XTREE’s recommendations may be generalized to identify the most crucial factors affecting multiple datasets (see the last figure in paper).Conclusion: Before undertaking a code reorganization based on a bad smell report, use a framework like XTREE to check and ignore any such operations that are useless; i.e. ones which lack evidence in the historical record that it is useful to make that change. Note that this use case applies to both manual code reorganizations proposed by developers as well as those conducted by automatic methods."
Review article - Static analysis of android apps: A systematic literature review,"AbstractContextStatic analysis exploits techniques that parse program source code or bytecode, often traversing program paths to check some program properties. Static analysis approaches have been proposed for different tasks, including for assessing the security of Android apps, detecting app clones, automating test cases generation, or for uncovering non-functional issues related to performance or energy. The literature thus has proposed a large body of works, each of which attempts to tackle one or more of the several challenges that program analyzers face when dealing with Android apps.ObjectiveWe aim to provide a clear view of the state-of-the-art works that statically analyze Android apps, from which we highlight the trends of static analysis approaches, pinpoint where the focus has been put, and enumerate the key aspects where future researches are still needed.MethodWe have performed a systematic literature review (SLR) which involves studying 124 research papers published in software engineering, programming languages and security venues in the last 5 years (January 2011–December 2015). This review is performed mainly in five dimensions: problems targeted by the approach, fundamental techniques used by authors, static analysis sensitivities considered, android characteristics taken into account and the scale of evaluation performed.ResultsOur in-depth examination has led to several key findings: 1) Static analysis is largely performed to uncover security and privacy issues; 2) The Soot framework and the Jimple intermediate representation are the most adopted basic support tool and format, respectively; 3) Taint analysis remains the most applied technique in research approaches; 4) Most approaches support several analysis sensitivities, but very few approaches consider path-sensitivity; 5) There is no single work that has been proposed to tackle all challenges of static analysis that are related to Android programming; and 6) Only a small portion of state-of-the-art works have made their artifacts publicly available.ConclusionThe research community is still facing a number of challenges for building approaches that are aware altogether of implicit-Flows, dynamic code loading features, reflective calls, native code and multi-threading, in order to implement sound and highly precise static analyzers."
Research article - An industry experience report on managing product quality requirements in a large organization,"AbstractContextEliciting, managing and implementing product quality requirements (in-short quality requirements) in a large organization can be challenging when many stakeholders are involved and projects run in parallel; sometimes with varying priorities with regards to quality. In this case from a public organization in Norway, the separation between business units and the IT-department and the legacy burden are additional factors that increase the complexity of requirement management.ObjectiveThis paper presents results and experiences from three years long work with quality requirements, starting from ad-hoc handling of quality requirements in separate projects to systematic work across projects with reusable sets of requirements and processes.MethodWe present how quality requirements are captured and classified, as well as changes to the agile software development process as a consequence of increasing focus on product quality.ResultsThe ISO/IEC-25010:2011 standard is tailored for better context fit and is supported by concrete requirements and a methodology that covers the life cycle of software products in both greenfield and brownfield projects. In addition, the organization had to examine the current state of existing IT-capabilities in order to establish a quality baseline for future development, and develop shared vision and roadmaps for product quality.ConclusionsIn our experience, stakeholders prefer an iterative and lightweight approach in eliciting and refining quality requirements. The classification model and requirement lists are used as guidelines in requirement workshops. The developed terminology, updated templates and processes are reusable in projects and generalizable to different contexts, and are well adopted by the IT and business units."
"Research article - A historical, textual analysis approach to feature location","AbstractContextFeature location is the task of finding the source code that implements specific functionality in software systems. A common approach is to leverage textual information in source code against a query, using Information Retrieval (IR) techniques. To address the paucity of meaningful terms in source code, alternative, relevant source-code descriptions, like change-sets could be leveraged for these IR techniques. However, the extent to which these descriptions are useful has not been thoroughly studied.ObjectiveThis work rigorously characterizes the efficacy of source-code lexical annotation by change-sets (ACIR), in terms of its best-performing configuration.MethodA tool, implementing ACIR, was used to study different configurations of the approach and to compare them to a baseline approach (thus allowing comparison against other techniques going forward). This large-scale evaluation employs eight subject systems and 600 features.ResultsIt was found that, for ACIR: (1) method level granularity demands less search effort; (2) using more recent change-sets improves effectiveness; (3) aggregation of recent change-sets by change request, decreases effectiveness; (4) naive, text-classification-based filtering of “management” change-sets also decreases the effectiveness. In addition, a strongly pronounced dichotomy of subject systems emerged, where one set recorded better feature location using ACIR and the other recorded better feature location using the baseline approach. Finally, merging ACIR and the baseline approach significantly improved performance over both standalone approaches for all systems.ConclusionThe most fundamental finding is the importance of rigorously characterizing proposed feature location techniques, to identify their optimal configurations. The results also suggest it is important to characterize the software systems under study when selecting the appropriate feature location technique. In the past, configuration of the techniques and characterization of subject systems have not been considered first-class entities in research papers, whereas the results presented here suggests these factors can have a big impact."
Research article - An extension of the GQM+Strategies approach with formal causal reasoning,"AbstractContext: Successful organizations need to manage and synchronize their strategic objectives with daily operations and activities. In general, achieving that requires a continuous process of organizational alignment. GQM+Strategies is an approach that helps software organizations with documenting and aligning organizational goals and strategies, and developing measurement programs. Objective: In this paper, the GQM+Strategies approach is further evolved and extended to include capabilities to evaluate the relationships of organizational goals and strategies through causal analysis. Method: We used an analytical paradigm to develop a formal causal model over the GQM+Strategies structure. In addition, an empirical pre-experimental study was designed to test practitioners’ abilities to provide necessary input for the formal causal model. Results: A developed formal causal model over the GQM+Strategies structure allows the use of causal reasoning for the purpose of analyzing dependencies among chosen sets of goals. We illustrate this by showing how to analyze the impact of risky goals on other goals in the grid. The results of the empirical study showed that the practitioners had no difficulties providing their predictions, i.e. inputs into the causal model. Conclusion: The proposed solution extends the existing GQM+Strategies knowledge base by further elaborating and clarifying the process of creating grids by introducing causality theory. The use of causality theory allows experts to quantify their knowledge and beliefs regarding the effectiveness of organizational strategies. As a part of future work, formal causal models and causal reasoning can be implemented as a supporting software tool for the GQM+Strategies approach."
Research article - On code reuse from StackOverflow: An exploratory study on Android apps,"AbstractContext: Source code reuse has been widely accepted as a fundamental activity in software development. Recent studies showed that StackOverflow has emerged as one of the most popular resources for code reuse. Therefore, a plethora of work proposed ways to optimally ask questions, search for answers and find relevant code on StackOverflow. However, little work studies the impact of code reuse from StackOverflow.Objective: To better understand the impact of code reuse from StackOverflow, we perform an exploratory study focusing on code reuse from StackOverflow in the context of mobile apps. Specifically, we investigate how much, why, when, and who reuses code. Moreover, to understand the potential implications of code reuse, we examine the percentage of bugs in files that reuse StackOverflow code.Method: We perform our study on 22 open source Android apps. For each project, we mine their source code and use clone detection techniques to identify code that is reused from StackOverflow. We then apply different quantitative and qualitative methods to answer our research questions.Results: Our findings indicate that 1) the amount of reused StackOverflow code varies for different mobile apps, 2) feature additions and enhancements in apps are the main reasons for code reuse from StackOverflow, 3) mid-age and older apps reuse StackOverflow code mostly later on in their project lifetime and 4) that in smaller teams/apps, more experienced developers reuse code, whereas in larger teams/apps, the less experienced developers reuse code the most. Additionally, we found that the percentage of bugs is higher in files after reusing code from StackOverflow.Conclusion: Our results provide insights on the potential impact of code reuse from StackOverflow on mobile apps. Furthermore, these results can benefit the research community in developing new techniques and tools to facilitate and improve code reuse from StackOverflow."
