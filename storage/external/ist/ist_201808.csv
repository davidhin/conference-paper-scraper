title,abstract
Research article - The GRADE taxonomy for supporting decision-making of asset selection in software-intensive system development,"AbstractContextThe development of software-intensive systems includes many decisions involving various stakeholders with often conflicting interests and viewpoints.ObjectiveDecisions are rarely systematically documented and sporadically explored. This limits the opportunity for learning and improving on important decisions made in the development of software-intensive systems.MethodIn this work, we enable support for the systematic documentation of decisions, improve their traceability and contribute to potentially improved decision-making in strategic, tactical and operational contexts.ResultsWe constructed a taxonomy for documentation supporting decision-making, called GRADE. GRADE was developed in a research project that required composition of a common dedicated language to make feasible the identification of new opportunities for better decision support and evaluation of multiple decision alternatives. The use of the taxonomy has been validated through thirty three decision cases from industry.ConclusionThis paper occupies this important yet greatly unexplored research gap by developing the GRADE taxonomy that serves as a common vocabulary to describe and classify decision-making with respect to architectural assets."
Research article - Spectrum-based fault localization in software product lines,"AbstractContextSoftware Product Line (SPL) testing is challenging mainly due to the potentially huge number of products under test. Most of the research on this field focuses on making testing affordable by selecting a representative subset of products to be tested. However, once the tests are executed and some failures revealed, debugging is a cumbersome and time consuming task due to difficulty to localize and isolate the faulty features in the SPL.ObjectiveThis paper presents a debugging approach for the localization of bugs in SPLs.MethodThe proposed approach works in two steps. First, the features of the SPL are ranked according to their suspiciousness (i.e., likelihood of being faulty) using spectrum-based localization techniques. Then, a novel fault isolation approach is used to generate valid products of minimum size containing the most suspicious features, helping to isolate the cause of failures.ResultsFor the evaluation of our approach, we compared ten suspiciousness techniques on nine SPLs of different sizes. The results reveal that three of the techniques (Tarantula, Kulcynski2 and Ample2) stand out over the rest, showing a stable performance with different types of faults and product suite sizes. By using these metrics, faults were localized by examining between 0.1% and 14.4% of the feature sets.ConclusionOur results show that the proposed approach is effective at locating bugs in SPLs, serving as a helpful complement for the numerous approaches for testing SPLs."
Research article - Surgical teams on GitHub: Modeling performance of GitHub project development processes,"AbstractContext: Better methods of evaluating process performance of OSS projects can benefit decision makers who consider adoption of OSS software in a company. This article studies the closure of issues (bugs and features) in GitHub projects, which is an important measure of OSS development process performance and quality of support that project users receive from the developer team.Objective: The goal of this article is a better understanding of the factors that affect issue closure rates in OSS projects.Methodology: The GHTorrent repository is used to select a large sample of mature, active OSS projects. Using survival analysis, we calculate short-term, and long-term issue closure rates. We formulate several hypotheses regarding the impact of OSS project and team characteristics, such as measures of work centralization, measures that reflect internal project workflows, and developer social networks measures on issue closure rates. Based on the proposed features and several control features, a model is built that can predict issue closure rate. The model allows to test our hypotheses.Results: We find that large teams that have many project members have lower issue closure rates than smaller teams. Similarly, increased work centralization increases issue closure rates. While desirable social network characteristics have a positive impact on the amount of commits in a project, they do not have significant influence on issue closure.Conclusion: Overall, findings from empirical analysis support the classic notion of Brook’s – the “surgical team” – in the context of OSS project development process performance on GitHub. The model of issue closure rates proposed in this article is a first step towards an improved understanding and prediction of this important measure of OSS development process performance."
Research article - EVL+Strace: a novel bidirectional model transformation approach,"AbstractContext: Model transformation, as one of the cornerstones of Model-Driven Engineering (MDE) paradigm, produces target models from source models. In most of the practical cases, both source and target models are changed independently and it is essential to preserve the consistency between them. Bidirectional transformation (Bx) provides a mechanism to re-establish this inter-model consistency. Bx approaches suffer from several limitations, such as lack of a comprehensive implementation, low learnability, and mismanagement of update conflicts.Objective: To alleviate the aforementioned drawbacks, we propose a novel Bx approach, called EVL+Strace, which is built using the Epsilon Validation Language (EVL) on a domain-specific trace metamodel (Strace). Furthermore, an Eclipse-based toolkit, called MoDEBiTE, is developed to automatically produce the EVL+Strace artifacts including the specific trace metamodel and transformation code.Method: EVL+Strace exploits the ability of EVL to transform user updates on models from source to target and vice versa, simultaneously. The applied trace metamodel should be specific to the domains of source and target metamodels that prevents illegitimate trace elements. Additionally, it enables developers to specify the transformation concepts more precisely. A running example is applied to explain the components of EVL+Strace and application of MoDEBiTE.Result: EVL+Strace is the first practical interactive approach that can provide important bidirectional features, such as preservation and propagation. A feature model of Bx approaches is applied to compare EVL+Strace with the well-known Bx languages. To show the superiority of EVL+Strace and applicability of MoDEBiTE, a comprehensive evaluation on six case studies is performed.Conclusion: EVL+Strace provides an interactive transformation system to manage update conflicts. It uses the EVL language for defining Bx transformation that has an easy-to-learn syntax. It is developed based on Epsilon, which is a comprehensive and actively updated framework."
Research article - Efficient runtime aspect weaving for Java applications,"AbstractContextThe aspect-oriented paradigm is aimed at solving the code scattering and tangling problem, providing new mechanisms to support better separation of concerns. For specific scenarios where high runtime adaptability is an important requirement, dynamic Aspect-Oriented Programming (AOP) represents a useful tool. With dynamic AOP, components and aspects can be woven and unwoven at runtime, enabling applications greater responsiveness when dealing with different or changing requirements. However, this responsiveness typically incurs a cost in terms of runtime performance and memory consumption.ObjectiveBuild an efficient dynamic aspect weaver for Java that provides the best runtime performance compared to the existing approaches, minimum memory overhead consumption, and similar functionalities to the widespread runtime weavers.MethodWe design and implement weaveJ, a dynamic aspect weaver for Java. This dynamic weaver leverages the invokedynamic opcode introduced in Java 7, which allows dynamic relinkage of method and field access. We compare the functionalities of weaveJ with the existing dynamic weavers for Java, and evaluate their runtime performance and memory consumption.ResultsweaveJ shows the best runtime performance for all benchmarks and real applications executed. Method interception with invokedynamic is at least 142% faster than the techniques used by the existing runtime weavers. The average cost of dynamic weaving using invokedynamic is only 2.2% for short running programs, and 1.5% for long running applications. Moreover, the use of aspects in weaveJ does not imply additional memory consumption.ConclusionThe dynamic aspect weaver implemented demonstrates that invokedynamic is a suitable mechanism to provide efficient runtime aspect weaving for Java applications. Moreover, it supports concurrent and programmatic aspect (un)weaving at any point of execution, a wide set of join points, class and object weaving, and allow aspects to have their own state. Neither the Java language nor the virtual machine needs to be modified."
Research article - Cross project defect prediction using class distribution estimation and oversampling,"AbstractContextCross-project defect prediction (CPDP) which uses dataset from other projects to build predictors has been recently recommended as an effective approach for building prediction models that lack historical or sufficient local datasets. Class imbalance and distribution mismatch between the source and target datasets associated with real-world defect datasets are known to have a negative impact on prediction performance.ObjectiveTo alleviate the negative effects of class imbalance and distribution mismatch on performance of CPDP models by using Class Distribution Estimation and Synthetic Minority Oversampling Technique. A novel approach called Class Distribution Estimation with Synthetic Minority Oversampling Technique (CDE-SMOTE) is proposed to optimize and improve the CPDP performance and avoid excessive oversampling.MethodThe proposed CDE-SMOTE employs CDE to estimate the class distribution of the target project. SMOTE is then used to modify the class distribution of the training data until the distribution becomes the reverse of the approximated class distribution of the target project. Four comprehensive experiments are conducted on 14 open source software projects.ResultsThe proposed approach improves the overall performance of CPDP models when compared to the performance of other CPDP approaches. Significant improvements are observed in 63% of the test cases according to the Wilcoxon signed-rank tests with 16.421%, 29.687% and 20.259% improvements in terms of Balance, G-measure, and F-measure, respectively. Application of CDE-SMOTE on NN-filtered datasets significantly improved prediction performance.ConclusionsCDE-SMOTE mitigates the class imbalance and distribution mismatch problems and also helps prevents excessive oversampling that results in performance degradation of prediction models. This approach is thus recommended for CPDP studies in software engineering."
Research article - Learning from the past: A process recommendation system for video game projects using postmortems experiences,"AbstractContext: The video game industry is a billion dollar industry that faces problems in the way games are developed. One method to address these problems is using developer aid tools, such as Recommendation Systems. These tools assist developers by generating recommendations to help them perform their tasks.Objective: This article describes a systematic approach to recommend development processes for video game projects, using postmortem knowledge extraction and a model of the context of the new project, in which “postmortems” are articles written by video game developers at the end of projects, summarizing the experience of their game development team. This approach aims to provide reflections about development processes used in the game industry as well as guidance to developers to choose the most adequate process according to the contexts they’re in.Method: Our approach is divided in three separate phases: in the first phase, we manually extracted the processes from the postmortems analysis; in the second one, we created a video game context and algorithm rules for recommendation; and finally in the third phase, we evaluated the recommended processes by using quantitative and qualitative metrics, game developers feedback, and a case study by interviewing a video game development team.Contributions: This article brings three main contributions. The first describes a database of developers’ experiences extracted from postmortems in the form of development processes. The second defines the main attributes that a video game project contain, which it uses to define the contexts of the project. The third describes and evaluates a recommendation system for video game projects, which uses the contexts of the projects to identify similar projects and suggest a set of activities in the form of a process."
Research article - A Bayesian networks-based approach to assess and improve the teamwork quality of agile teams,"AbstractCONTEXT: According to the agile principles and values, as well as recent research articles, teamwork factors are critical to achieve success in agile projects. However, teamwork does not automatically arise. There are some existing instruments with the purpose of assessing the teamwork quality based on Structural Equation Modeling (i.e., empirically derived) and Radar Plots, but they may not be useful in a concrete situation because these techniques are not advised for prediction and diagnosis purposes. OBJECTIVE: Analytically derive a Bayesian network model based on a literature review and a practitioner’s knowledge; and to assess its practical utility through a case study. METHOD: To build the model, we executed a top-down approach using data collected through a literature review and a domain practitioner. We assessed the model with a case study executed in three Scrum teams. RESULTS: Given the context of the case study, the model assists agile teams on assessing teamwork quality and identifying improvement opportunities, is easy to learn, and the cost-benefit for using it with the proposed procedure is positive. CONCLUSION: We concluded that we achieved promising results with the presented solution. However, it needs more evaluation and validation to generalize the obtained results."
Research article - Supporting the evolution of event-driven service-oriented architectures using change patterns,"AbstractContextThe components of an event-driven service-oriented architecture (EDSOA) are composed in a highly decoupled way, facilitating high flexibility, scalability and concurrency in SOA systems. Evolving an EDSOA is challenging because the absence of explicit dependencies among constituent components makes understanding and analysing the overall system composition difficult. The evolution of EDSOAs typically happens by performing a series of primitive changes—which can be described formally as change primitives.ObjectiveIn this article, we present our change pattern based approach for managing the EDSOA evolution as a novel design method supporting EDSOA evolution. The change patterns operate on a higher abstraction level than change primitives.MethodTo evaluate our approach, we have compared both time and correctness of changes in a controlled experiment comparing the understanding and performing of changes in EDSOAs. The experiment has been conducted with 90 students of the Software Architecture course at the University of Vienna. We compare the efficiency of 3 sets of change operations for modifying a given system architecture to obtain a desired architecture: a minimal set of 3 change patterns, an extended set of 5 change patterns, and a minimal set of 4 change primitives.ResultsOur results show that change patterns based evolution requires significantly less time to capture a similar level of correctness as the evolution based on change primitives, presuming that a certain level of transformation complexity is required. Furthermore, we did not observe a significant difference in the correctness level nor in the time required to perform the changes using an extended pattern set compared to a minimal set of patterns.ConclusionsWe clearly show the feasibility of our approach by developing a design method and tool support using a model-driven tool chain consisting of 3 domain-specific languages and empirically evaluating the approach in a controlled experiment."
"Research article - SINIS: A GQM+Strategies-based approach for identifying goals, strategies and indicators for IT services","AbstractContextMeasurement is a key process to support organizations in managing and improving processes, products and services. The literature on IT (Information Technology) Service states that IT services should support critical business processes and should be measured in order to provide useful information for decision-making. However, there is a lack of clear guidance regarding what should be measured and which critical business processes should be considered.ObjectiveWe conducted this work aiming to answer the research question: How to support identification of IT service goals, strategies and indicators at different organizational levels and aligned to business goals?MethodWe defined SINIS, a method to identify Goals, Strategies and Indicators for IT Services, which has been developed to support IT service departments in identifying IT service goals, strategies and indicators to provide information for decision-making at different organizational levels and in alignment with business goals. SINIS supports defining strategies to achieve IT service goals, and identifying indicators to evaluate the strategies and goals achievement. SINIS is based on process improvement approaches (mainly GQM+Strategies) and approaches related to IT service management (mainly COBIT Goals Cascade)ResultsSINIS was used in a case study in the IT Infrastructure and IT Security departments of a large global company. Results showed that participants were able to build the GQM+Strategies Grid and discard useless indicators. In addition, team members became more devoted to measurement and strategies, and better understood relations between goals, strategies and indicators. Templates, examples and checklists useful to learn how to execute SINIS and to properly record the produced results were used by the study participants.ConclusionsInitial evidences show that SINIS supports building the GQM+Strategies Grid and helps IT service departments to define strategies and identify useful indicators, contributing to focus efforts on strategies aligned to IT service and business goals."
Research article - Modeling Security and Privacy Requirements: a Use Case-Driven Approach,"AbstractContext: Modern internet-based services, ranging from food-delivery to home-caring, leverage the availability of multiple programmable devices to provide handy services tailored to end-user needs. These services are delivered through an ecosystem of device-specific software components and interfaces (e.g., mobile and wearable device applications). Since they often handle private information (e.g., location and health status), their security and privacy requirements are of crucial importance. Defining and analyzing those requirements is a significant challenge due to the multiple types of software components and devices integrated into software ecosystems. Each software component presents peculiarities that often depend on the context and the devices the component interact with, and that must be considered when dealing with security and privacy requirements. Objective: In this paper, we propose, apply, and assess a modeling method that supports the specification of security and privacy requirements in a structured and analyzable form. Our motivation is that, in many contexts, use cases are common practice for the elicitation of functional requirements and should also be adapted for describing security requirements. Method: We integrate an existing approach for modeling security and privacy requirements in terms of security threats, their mitigations, and their relations to use cases in a misuse case diagram. We introduce new security-related templates, i.e., a mitigation template and a misuse case template for specifying mitigation schemes and misuse case specifications in a structured and analyzable manner. Natural language processing can then be used to automatically report inconsistencies among artifacts and between the templates and specifications. Results: We successfully applied our approach to an industrial healthcare project and report lessons learned and results from structured interviews with engineers. Conclusion: Since our approach supports the precise specification and analysis of security threats, threat scenarios and their mitigations, it also supports decision making and the analysis of compliance to standards."
Short communication - Towards a mutation analysis of IoT protocols,"AbstractContextMutation testing and analysis is concerned with the introduction of single faults (or errors) into a system’s design, specification, implementation or interface and then testing or analysing the effects caused by those faults or errors on the system’s properties and behaviour. Such faulty entities are called mutants.ObjectiveThis short paper sketches the idea that mutations can be used to identify whether protocol implementations may deviate from the standards defining those protocols.MethodsWe apply formal analysis techniques to analyse the harmful effects of mutations on IoT protocol specifications, most importantly, e.g. whether those mutations will violate the IoT protocol standard.ResultsWe discovered in our initial investigation one interesting case where a mutant protocol specification may lead to implementations that drop every message intended for publication to applications without breaking the standard of quality of message delivery in the protocol standard.ConclusionWe believe as a result, that there is some additional investigation needed in this direction that could be beneficial in implementing future more reliable protocols and also that the current standards need to be revised to take care of such scenarios."
