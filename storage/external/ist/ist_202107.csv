title,abstract
Short communication - Continuous Systems and Software Engineering for Industry 4.0: A disruptive view,"AbstractContext:Industry 4.0 has substantially changed the manufacturing processes, leading to smart factories with full digitalization, intelligence, and dynamic production. The need for rigorous and continuous development of highly networked software-intensive Industry 4.0 systems entails great challenges. Hence, Industry 4.0 requires new ways to develop, operate, and evolve these systems accordingly.Objective:We introduce the view of Continuous Systems and Software Engineering for Industry 4.0 (CSSE I4.0).Method:Based on our research and industrial projects, we propose this novel view and its core elements, including continuous twinning, which is also introduced first in this paper. We also discuss the existing industrial engagement and research that could leverage this view for practical application.Results:There are still several open issues, so we highlight the most urgent perspectives for future work.Conclusions:A disruptive view on how to engineer Industry 4.0 systems must be established to pave the way for the realization of the fourth industrial revolution."
Review article - Test case generation for agent-based models: A systematic literature review,"AbstractContext:Agent-based models play an important role in simulating complex emergent phenomena and supporting critical decisions. In this context, a software fault may result in poorly informed decisions that lead to disastrous consequences. The ability to rigorously test these models is therefore essential.Objective:Our objective is to summarise the state-of-the-art techniques for test case generation in agent-based models and identify future research directions.Method:We have conducted a systematic literature review in which we pose five research questions related to the key aspects of test case generation in agent-based models: What are the information artifacts used to generate tests? How are these tests generated? How is a verdict assigned to a generated test? How is the adequacy of a generated test suite measured? What level of abstraction of an agent-based model is targeted by a generated test?Results:Out of the 464 initial search results, we identified 24 primary publications. Based on these primary publications, we formed a taxonomy to summarise the state-of-the-art techniques for test case generation in agent-based models. Our results show that whilst the majority of techniques are effective for testing functional requirements at the agent and integration levels of abstraction, there are comparatively few techniques capable of testing society-level behaviour. Furthermore, the majority of techniques cannot test non-functional requirements or “soft goals”.Conclusions:This paper reports insights into the key developments and open challenges concerning test case generation in agent-based models that may be of interest to both researchers and practitioners. In particular, we identify the need for test case generation techniques that focus on societal and non-functional behaviour, and a more thorough evaluation using realistic case studies that feature challenging properties associated with a typical agent-based model."
Research article - On the generalizability of Neural Program Models with respect to semantic-preserving program transformations,"AbstractContext:With the prevalence of publicly available source code repositories to train deep neural network models, neural program models can do well in source code analysis tasks such as predicting method names in given programs that cannot be easily done by traditional program analysis techniques. Although such neural program models have been tested on various existing datasets, the extent to which they generalize to unforeseen source code is largely unknown.Objective:Since it is very challenging to test neural program models on all unforeseen programs, in this paper, we propose to evaluate the generalizability of neural program models with respect to semantic-preserving transformations: a generalizable neural program model should perform equally well on programs that are of the same semantics but of different lexical appearances and syntactical structures.Method:We compare the results of various neural program models for the method name prediction task on programs before and after automated semantic-preserving transformations. We use three Java datasets of different sizes and three state-of-the-art neural network models for code, namely code2vec, code2seq, and GGNN, to build nine such neural program models for evaluation.Results:Our results show that even with small semantically preserving changes to the programs, these neural program models often fail to generalize their performance. Our results also suggest that neural program models based on data and control dependencies in programs generalize better than neural program models based only on abstract syntax trees (ASTs). On the positive side, we observe that as the size of the training dataset grows and diversifies the generalizability of correct predictions produced by the neural program models can be improved too.Conclusion:Our results on the generalizability of neural program models provide insights to measure their limitations and provide a stepping stone for their improvement."
Research article - iMER: Iterative process of entity relationship and business process model extraction from the requirements,"AbstractContextExtracting conceptual models, e.g., entity relationship model or Business Process model, from software requirement document is an essential task in the software development life cycle. Business process model presents a clear picture of required system's functionality. Operations in business process model together with the data entity consumed, help the software developers to understand the database design and operations to be implemented. Researchers have been aiming at automatic extraction of these artefacts from the requirement document.ObjectiveIn this paper, we present an automated approach to extract the entity relationship and business process models from requirements, which are possibly in different formats such as general requirements, use case specification and user stories. Our approach is based on the efficient natural language processing techniques.MethodIt is an iterative approach of Models Extraction from the Requirements (iMER). iMER has multiple iterations where each iteration is to address a sub-problem. In the first iteration, iMER extracts the data entities and attributes. Second iteration is to find the relationships between data entities, while extracting cardinalities is in the third step. Business process model is generated in the fourth iteration, containing the external (actors’) and internal (system's) operations.EvaluationTo evaluate the performance and accuracy of iMER, experiments are conducted on various formats of the requirement documents. Additionally, we have also evaluated our approaches using the requirement documents which been modified by shuffling the sentences and by merging with other requirements. Comparative study is also performed. The preliminary results show a noticeable improvement.ConclusionThe iMER is an efficient automated iterative approach that is able to extract the conceptual models from the various formats of requirements."
Research article - Generating feasible protocol test sequences from EFSM models using Monte Carlo tree search,"AbstractContext:Feasible test sequences generation is a key step in protocol conformance testing based on the Extended Finite State Machine (EFSM) model. To guarantee the feasibility of generated test sequences, transition executability analysis (TEA) technique is widely applied in automatic test derivation. However, the TEA method often suffers from the famous state explosion problem, which has become a major obstacle to its efficient application.Objective:In order to mitigate this issue, this paper proposed a novel heuristic TEA method (MTEA) that uses Monte Carlo tree search (MCTS) to guide the TEA tree expansion for efficiently deriving feasible test sequences.Method:The approach first provides a framework to apply the MCTS algorithm based on multiple decision subtrees, in the context of test sequence generation for EFSM-specified systems, to more efficiently expanding the TEA tree with huge state space, and thus alleviating the problem of state explosion. To achieve this, we then design a reward function to calculate the fitness of nodes currently being expanded in the TEA tree and heuristically direct the search towards a near-optimal solution. Next, an adaptive reduction mechanism of search budget is also introduced to accelerate the convergence of the analysis. Finally, a MTEA-based algorithm for automatically generating feasible test sequences is presented under a specific transition coverage criterion.Results:A detailed case study on 6 popular EFSMs was carried out to evaluate the effectiveness and efficiency of our method. Experimental results show that the MTEA significantly outperforms Breadth-First-Search based TEA method (BTEA) and the standard MCTS-based method (SMCTS), regarding time and space performance. Compared with the BTEA, SMCTS and random TEA method (RTEA), the success rate of test generation of MTEA (98.14% on average) is approximately 2, 1.85 and 3 times higher, respectively. For successful test derivation, MTEA only needs to explore on average 9.95% of the nodes and consume on average 61.68% of the runtime of the BTEA method.Conclusion:The experiments illustrate the promise of our approach for alleviating the state explosion problem in test generation for EFSM-specified systems."
Research article - Augmenting commit classification by using fine-grained source code changes and a pre-trained deep neural language model,"AbstractContext:Analyzing software maintenance activities is very helpful in ensuring cost-effective evolution and development activities. The categorization of commits into maintenance tasks supports practitioners in making decisions about resource allocation and managing technical debt.Objective:In this paper, we propose to use a pre-trained language neural model, namely BERT (Bidirectional Encoder Representations from Transformers) for the classification of commits into three categories of maintenance tasks — corrective, perfective and adaptive. The proposed commit classification approach will help the classifier better understand the context of each word in the commit message.Methods:We built a balanced dataset of 1793 labeled commits that we collected from publicly available datasets. We used several popular code change distillers to extract fine-grained code changes that we have incorporated into our dataset as additional features to BERT’s word representation features. In our study, a deep neural network (DNN) classifier has been used as an additional layer to fine-tune the BERT model on the task of commit classification. Several models have been evaluated to come up with a deep analysis of the impact of code changes on the classification performance of each commit category.Results and conclusions:Experimental results have shown that the DNN model trained on BERT’s word representations and Fixminer code changes (DNN@BERT+Fix_cc) provided the best performance and achieved 79.66% accuracy and a macro-average f1 score of 0.8. Comparison with the state-of-the-art model that combines keywords and code changes (RF@KW+CD_cc) has shown that our model achieved approximately 8% improvement in accuracy. Results have also shown that a DNN model using only BERT’s word representation features achieved an improvement of 5% in accuracy compared to the RF@KW+CD_cc model."
Research article - MEGDroid: A model-driven event generation framework for dynamic android malware analysis,"AbstractContextThe tremendous growth of Android malware in recent years is a strong motivation for the vast endeavor in detection and analysis of malware apps. A prominent approach for this purpose is dynamic analysis in which providing complex interactions with the samples under analysis is a need. Event generation tools are almost used to provide such interactions, but they have deficiencies for effective malware analysis. For example, anti-static and anti-dynamic analysis techniques employed by the malware prevent event generators to extract sufficient information for generating appropriate events. As a result, they fail to trigger malicious payloads or obtain high code coverage in most cases.ObjectiveIn this paper, we aim to present a new framework to improve the event generation process for dynamic analysis of Android malware.MethodWe propose MEGDroid, a Model Driven Engineering (MDE) framework in which malware-related information is automatically extracted and represented as a domain-specific model. This model, then is used to generate appropriate events for malware analysis using model-to-model and model-to-code transformations. The proposed model-driven artifacts also provide required facilities to put the human in the loop for properly taking his/her knowledge into account.ResultsThe proposed framework has been realized as an Eclipse plugin and we performed extensive practical analysis on a set of malware samples selected from the AMD dataset. The experimental results showed that MEGDroid considerably increases the number of triggered malicious payloads as well as the execution code coverage compared with Monkey and DroidBot, as two state of the art general-purpose and malware specific event generators respectively.ConclusionThe proposed MDE approach, enhances the event generation process through both automatic event generation and analyzer user involvement who can efficiently direct the process to increase the effectiveness of the generated events considering small amount of information that is extractable from the malware code."
Research article - Multi-objective software performance optimisation at the architecture level using randomised search rules,"AbstractArchitecture-based software performance optimisation can help to find potential performance problems and mitigate their negative effects at an early stage. To automate this optimisation process, rule-based and metaheuristic-based performance optimisation methods have been proposed. However, existing rule-based methods explore a limited search space, potentially excluding optimal or near-optimal solutions. Most of current metaheuristic-based methods ignore existing practical knowledge of performance improvement, and lead to solutions that are not easily explicable to humans. To address these problems, we propose a novel approach for performance optimisation at the software architecture level named Multiobjective performance Optimisation based on Randomised search rulEs (MORE). First, we design randomised search rules (MORE-R) to provide explanation without parameters while benefiting from existing practical knowledge of performance improvement. Second, based on all possible composite applications of MORE-R, an explicable multi-objective optimisation problem (MORE-P) is defined to enlarge search space and enable solutions explicable to architectural stakeholder. Third, a multi-objective evolutionary algorithm (MORE-EA) with an introduced do-nothing rule, innovative encoding and repair mechanism is designed to effectively solve MORE-P. The experiments show that MORE is able to achieve more explicable and higher quality solutions than two state-of-the-art techniques. They also demonstrate the benefits of integrating search-based software engineering approaches with practical knowledge."
Research article - A practical algorithm for learning disjunctive abstraction heuristics in static program analysis,"AbstractContext:The precision and cost of static analysis are determined by abstraction heuristics (e.g., strategies for abstracting calling contexts, heap locations, etc.), but manually designing effective abstraction heuristics requires a huge amount of engineering effort and domain knowledge. Recently, data-driven static analysis has emerged to address this challenge by learning such heuristics automatically from a set of training programs.Objective:We present a practical algorithm for learning disjunctive abstraction heuristics in data-driven static analysis. We build on a recently proposed approach that can learn nontrivial program properties by disjunctive boolean functions. However, the existing approach is practically limited as it assumes that the most precise abstraction is cheap for the training programs; the algorithm is inapplicable if the most precise abstraction is not scalable. The objective of this paper is to mitigate this limitation.Method:Our algorithm overcomes the limitation with two new ideas. It systematically decomposes the learning problem into feasible subproblems, and it can search through the abstraction space from the coarse- to fine-grained abstractions. With this approach, our algorithm is able to learn heuristics when static analysis with the most precise abstraction is not scalable over the training programs.Results:We show our approach is effective and generally applicable. We applied our approach to a context-sensitive points-to analysis for Java and a flow-sensitive interval analysis for C. Experimental results show that our algorithm is efficient. For example, our algorithm can learn heuristics for 3-object-sensitive analysis for which the existing learning algorithm is too expensive to learn any useful heuristics.Conclusion:Our algorithm makes a state-of-the-art technique for data-driven static analysis more practical."
Research article - Analyzing the sensitivity of multi-objective software architecture refactoring to configuration characteristics,"AbstractContext:Software architecture refactoring can be induced by multiple reasons, such as satisfying new functional requirements or improving non-functional properties. Multi-objective optimization approaches have been widely used in the last few years to introduce automation in the refactoring process, and they have revealed their potential especially when quantifiable attributes are targeted. However, the effectiveness of such approaches can be heavily affected by configuration characteristics of the optimization algorithm, such as the composition of solutions.Objective:In this paper, we analyze the behavior of EASIER, which is an Evolutionary Approach for Software archItecturE Refactoring, while varying its configuration characteristics, with the objective of studying its potential to find near-optimal solutions under different configurations.Method:In particular, we use two different solution space inspection algorithms (i.e., NSGA−II and SPEA2) while varying the genome length and the solution composition.Results:We have conducted our experiments on a specific case study modeled in Æmilia ADL, on which we have shown the ability of EASIER to identify performance-critical elements in the software architecture where refactoring is worth to be applied. Beside this, from the comparison of multi-objective algorithms, NSGA−II has revealed to outperform SPEA2 in most of cases, although the latter one is able to induce more diversity in the proposed solutions.Conclusion:Our results show that the EASIER thoroughly automated process for software architecture refactoring allows to identify configuration contexts of the evolutionary algorithm in which multi-objective optimization more effectively finds near-optimal Pareto solutions."
