title,abstract
Research article - Evaluating subset selection methods for use case points estimation,"AbstractWhen the Use Case Points method is used for software effort estimation, users are faced with low model accuracy which impacts on its practical application. This study investigates the significance of using subset selection methods for the prediction accuracy of Multiple Linear Regression models, obtained by the stepwise approach. K-means, Spectral Clustering, the Gaussian Mixture Model and Moving Window are evaluated as appropriate subset selection techniques. The methods were evaluated according to several evaluation criteria and then statistically tested. Evaluation was performing on two independent datasets - which differ in project types and size. Both were cut by the hold-out method. If clustering were used, the training sets were clustered into 3 classes; and, for each of class, an independent regression model was created. These were later used for the prediction of testing sets. If Moving Window was used, then window of sizes 5, 10 and 15 were tested.The results show that clustering techniques decrease prediction errors significantly when compared to Use Case Points or moving windows methods. Spectral Clustering was selected as the best-performing solution, because it achieves a Sum of Squared Errors reduction of 32% for the first dataset, and 98% for the second dataset. The Mean Absolute Percentage Error is less than 1% for the second dataset for Spectral Clustering; 9% for moving window; and 27% for Use Case Points. When the first dataset is used, then prediction errors are significantly higher – 53% for Spectral Clustering, but Use Case Points produces a 165% result.It can be concluded that this study proves subset selection techniques as a significant method for improving the prediction ability of linear regression models - which are used for software development effort prediction. It can also be concluded that the clustering method performs better than the moving window method."
"Research article - Exploring the links between software development task type, team attitudes and task completion performance: Insights from the Jazz repository","AbstractContextIn seeking to better understand the impact of various human factors involved in software development, and how teams’ attitudes relate to their performance, increasing attention is being given to the study of team-related artefacts. In particular, researchers have conducted numerous studies on a range of team communication channels to explore links between developers’ language use and the incidence of software bugs in the products they delivered. Comparatively limited attention has been paid, however, to the full range of software tasks that are commonly performed during the development and delivery of software systems, in spite of compelling evidence pointing to the need to understand teams’ attitudes more widely.ObjectiveWe were therefore motivated to study the relationships between task type and team attitudes, and how attitudes expressed in teams’ communications might be related to their task completion performance when undertaking a range of activities.MethodOur investigation involved artefacts from 474 IBM Jazz practitioners assembled in 149 teams working on around 30,000 software development tasks over a three-year period. We applied linguistic analysis, standard statistical techniques and directed content analysis to address our research objective.ResultsOur evidence revealed that teams expressed different attitudes when working on various forms of software tasks, and they were particularly emotional when working to remedy defects. That said, teams’ expression of attitudes was not found to be a strong predictor of their task completion performance.ConclusionEfforts aimed at reducing bug incidence may positively limit teams’ emotional disposition when resolving bugs, thereby reducing the otherwise high demand for emotionally stable members. In addition, in environments where teams work closely together to develop software such as in Agile contexts, attitudes are likely to have a bearing on how they function as a group."
Research article - A theory of openness for software engineering tools in software organizations,"AbstractContextThe increased use of Open Source Software (OSS) affects how software-intensive product development organizations (SIPDO) innovate and compete, moving them towards Open Innovation (OI). Specifically, software engineering tools have the potential for OI, but require better understanding regarding what to develop internally and what to acquire from outside the organization, and how to cooperate with potential competitors.AimThis paper aims at synthesizing a theory of openness for software engineering tools in SIPDOs, that can be utilized by managers in defining more efficient strategies towards OSS communities.MethodWe synthesize empirical evidence from a systematic mapping study, a case study, and a survey, using a narrative method. The synthesis method entails four steps: (1) Developing a preliminary synthesis, (2) Exploring the relationship between studies, (3) Assessing the validity of the synthesis, and (4) Theory formation.ResultWe present a theory of openness for OSS tools in software engineering in relation to four constructs: (1) Strategy, (2) Triggers, (3) Outcomes, and (4) Level of openness.ConclusionThe theory reasons that openness provides opportunities to reduce the development cost and development time. Furthermore, OI positively impacts on the process and product innovation, but it requires investment by organizations in OSS communities. By betting on openness, organizations may be able to significantly increase their competitiveness."
Research article - A systematic approach to API usability: Taxonomy-derived criteria and a case study,"AbstractContextThe currently existing literature about Application Program Interface (API) usability is heterogeneous in terms of goals, scope, and audience; and its connection to accepted definitions of usability is rarely made explicit. The use of metrics to measure API usability is focused only on measurable characteristics excluding those usability aspects that are related to the subjectivity of human opinions.ObjectiveOur objective is to build a comprehensive set of heuristics and guidelines for API usability that is a structured synthesis of the existing literature on API usability but which also covers other aspects that have been neglected so far. This set is explicitly connected with a usability model, something that allows us to check if we are addressing actual usability problems.MethodOur approach is to follow a systematic approach based on a comprehensive model of usability and context-of-use. From this comprehensive model we derived the set of heuristics and guidelines that are used to carry out a heuristic evaluation with usability experts and a subjective analysis with users. The influence of the context of use, something that is normally ignored, is explicitly analyzed.ResultsOur heuristics and guidelines were integrated into a usability study of a sleep medicine API. In this study, we were able to identify several usability issues of the proposed API that are not explicitly addressed in the existing literature. The context of use helped us to identify those categories that were more relevant to consider in order to improve API usability.ConclusionThe literature on API usability is very technically-minded and tends to neglect the subjective component of usability. We contribute to a more global and comprehensive view of the usability of APIs that is not contradictory but complementary with metrics. Our criteria ease the always necessary usability evaluation with human evaluators and users."
Research article - Content and structure of laboratory packages for software engineering experiments,"AbstractContextExperiment replications play a central role in the scientific method. Although software engineering experimentation has matured a great deal, the number of experiment replications is still relatively small. Software engineering experiments are composed of complex concepts, procedures and artefacts. Laboratory packages are a means of transferring knowledge among researchers to facilitate experiment replications.ObjectiveThis paper investigates the experiment replication process to find out what information is needed to successfully replicate an experiment. Our objective is to propose the content and structure of laboratory packages for software engineering experiments.MethodWe evaluated seven replications of three different families of experiments. Each replication had a different experimenter who was, at the time, unfamiliar with the experiment. During the first iterations of the study, we identified experimental incidents and then proposed a laboratory package structure that addressed these incidents, including document usability improvements. We used the later iterations to validate and generalize the laboratory package structure for use in all software engineering experiments. We aimed to solve a specific problem, while at the same time looking at how to contribute to the body of knowledge on laboratory packages.ResultsWe generated a laboratory package for three different experiments. These packages eased the replication of the respective experiments. The evaluation that we conducted shows that the laboratory package proposal is acceptable and reduces the effort currently required to replicate experiments in software engineering.ConclusionWe think that the content and structure that we propose for laboratory packages can be useful for other software engineering experiments."
Short communication - Towards a model to transfer knowledge from software engineering research to practice,"AbstractContext: Many researchers argue that Software Engineering (SE) research lacks connection with practice.Objective: We propose a model aimed at supporting researchers to transfer knowledge to SE practice.Method: This model is built upon the foundation of Rapid Reviews and Evidence Briefings. These two key elements have been proven effective in other domains, such as medicine, and initial results suggest that they can play a prominent role in SE as well.Results: We discuss how to apply the model as well as possible challenges that might hinder its adoption.Conclusion: We believe that both SE practitioners and researchers could benefit from the proposed model. We expect replications and instantiations of the model in the future."
Research article - A design pattern-based approach for automatic choice of semi-partitioned and global scheduling algorithms,"AbstractContext: Because of the evergrowing complexity of Real-Time Embedded Systems (RTES) coupled with the variety of scheduling approaches and algorithms, the scheduling step has become more challenging mainly for new designers. In particular, the choice of the appropriate scheduling algorithm for a RTES is a hard step that requires vast knowledge and expertise of the scheduling field. Therefore, there is still a need for directives and guidelines to assist designers while choosing the appropriate scheduling algorithm to avoid system failures. In this respect, some approaches were proposed to deal with automatic scheduling. However, only the partitioned scheduling approach which prevents task migration was supported.Objective: Our work aims at supporting the automatic choice of scheduling approach and algorithm at a high-level of abstraction. A key feature of this proposal is that it supports semi-partitioned and global scheduling, which allow task migration.Method: With the above objective in mind, we propose a model-based approach which focuses on the use of the Model Driven Engineering (MDE) and design patterns to support the automatic scheduling at a high-level of abstraction. The proposed approach uses two design patterns previously published (Magdich et al., 2014, 2015) to model the semi-partitioned and global scheduling approaches. They allow checking the correctness of the studied system model and detecting automatically the appropriate scheduling approach and algorithm. A schedulability analysis step is, therefore, performed to check the temporal behavior of the studied system once the selected scheduling algorithm is applied.Results: The findings reveal the important impact of the use of high-level methodologies during the RTES scheduling. The automatic choice of the scheduling algorithm makes the scheduling step easier.Conclusions: Our proposal represents the first attempt to support the automatic scheduling regarding semi-partitioned and global scheduling. Thanks to the use of high-level techniques during the RTES design and scheduling, the designer’s effort is reduced."
Research article - Support vector regression for predicting software enhancement effort,"AbstractContextSoftware maintenance (SM) has to be planned, which involves SM effort prediction. One type of SM is enhancement, where new functionality is added or existing functionality changed or deleted.ObjectiveAnalyze the prediction accuracy of two types of support vector regression (ε-SVR and ʋ-SVR) when applied to predict software enhancement effort.MethodBoth types of support vector regression used linear, polynomial, radial basis function, and sigmoid kernels. Prediction accuracies for ε-SVR and ʋ-SVR were compared with those of statistical regressions, neural networks, association rules, and decision trees. The models were trained and tested with five data sets of enhancement projects from Release 11 of the International Software Benchmarking Standards Group (ISBSG). Each data set was selected on the basis of data quality, development platform, programming language generation, and levels of effort recording.ResultsThe polynomial kernel ε-SVR (PKε-SVR) was statistically better than statistical regression, neural networks, association rules and decision trees, with 95% confidence.ConclusionsA PKε-SVR could be used for predicting software enhancement effort in mainframe platforms and coded in a third-generation programming languages, and when enhancement effort recording includes the efforts of the development team, its support personnel, the computer operations involvement, and end users."
Research article - Searching for violation of safety and liveness properties using knowledge discovery in complex systems specified through graph transformations,"AbstractContextModel checking is an automatic and precise technique in verification and refutation of software and hardware systems. Despite its advantages, the state space explosion problem may occur in large and complex systems. Recent studies demonstrate that using meta-heuristic and evolutionary algorithms are a proper solution to handle the state space explosion problem. In systems which are specified formally through graph transformations, the state space is constructed by applying all enable rules on all generated states. In such systems, there is a dependency between rules in each sequence of applied rules in the state space.ObjectiveThis fact motivates us to use knowledge discovery techniques to intelligently explore only a portion of the state space instead of exhaustive exploration. We propose two different techniques to acquire such knowledge form the model state space. In this paper, we propose a data mining-based approach in which the required knowledge is obtained from exploring a slight portion of the model state space. Another approach is proposed in which a Bayesian network is used to capture this knowledge. After acquiring the required knowledge, it is employed to explore only a portion of the model state space intelligently, to refute a property.ResultsThe proposed approaches can be used to analyze the reachability, safety and liveness properties. To evaluate the proposed approaches, they are implemented in GROOVE, an open source toolset for designing and model checking of systems specified through graph transformations.ConclusionExperimental results on different set of benchmarks show that the proposed approaches are faster and more accurate in comparison with the existing meta-heuristic and evolutionary techniques in model checking of complex software systems specified through graph transformations."
Research article - How does the value provided by a software product and users’ psychological needs interact to impact user loyalty,"AbstractA multi-disciplinary review of literature shows that products can provide three types of value to the users – utilitarian, hedonic and social. Further, these values impact user outcomes such as their loyalty to the product. However, in this study we suggest that the relative impacts of these values on user loyalty to the product will vary with user needs. To test this contention we conducted a study with actual users of three software products – Producteev, Kerbal and Facebook. The results of the study confirm that user needs selectively moderate the impact of the various values provided by the software product to the users on their loyalty for the software product. These findings have implications for software product managers. They highlight the relevance of developing software products aligned with the profile of the targeted users to maximize their loyalty to the software product and the importance of the hitherto unexplored SV in the context of software products."
Research article - Age stereotypes in distributed software development: The impact of culture on age-related performance expectations,"AbstractContextDue to demographic changes in most developed countries, distributed software development (DSD) teams might suffer new barriers above and beyond the well-known cultural and distance-based challenges. Remarkably, six out of the twelve most important barriers for DSD are related to typical problems induced by both cultural and age diversity. Age stereotypes can hinder communication, trust, knowledge exchange and coordination in software development. They have been studied based on individual level whereas context-related factors such as culture have been less in focus yet.ObjectiveWe examine the effects of national and organizational culture on age stereotypes. Therein we explore the conditions and processes that might increase age stereotypes.MethodWe conducted a quantitative study with 457 employees in two software development companies in China, Germany, Poland and Bulgaria.ResultsResults show a significant bias in performance expectations favoring middle-aged employees over younger and older employees across national cultures. Stereotypes toward older employees are more negative in Eastern Europe and China than in Germany, while stereotypes toward younger employees are more negative in Germany than in China and Eastern Europe. Lower average team age and lower contact frequency foster stereotypes in China and Eastern Europe. Negative stereotypes can be buffered by an organizational culture which values team achievement and trust over individual performance and control.ConclusionsThe study advances the literature by integrating value- and schema-based approaches when examining cultural influences, extending the stereotype content model and the situated dynamics framework. Moreover, it may help finding new solutions for human-related problems in DSD based on intangible barriers that hinder development processes. Companies that use DSD might consider reducing age stereotypes in China and Eastern Europe by intensively increasing contact to older workers, including age stereotype aspects into cultural training or by increasing values of team achievement within their organizational culture."
Research article - Systematic guidance on usability methods in user-centered software development,"AbstractContextIn order to ensure usability, it is necessary to schedule activities and methods to be applied throughout different stages of the development process. There exists a substantial number of usability methods to be applied in user-centered software development. However, the application of each usability method largely depends on specific constraints that should be closely considered. Even so, these constraints are not always known beforehand, remaining unidentified or under uncertainty at early stages of the project.ObjectiveThis paper presents an approach to automatically recommend 43 usability methods depending on the project's stage and constraints. Our approach deals with uncertainty to recommend usability methods regardless of the completeness of the information available, which makes it suitable for enhancing initial scheduling. Besides, a supporting tool intended to schedule and guide on usability methods is presented in order to systematize the recommendation mechanism.MethodTo validate our approach, we present two application scenarios demonstrating the suitability of the mechanism, including also an expert analysis to observe the recommendation appropriateness in terms of recommendation gap. Also, a user testing was accomplished to evaluate the usability of the approach with key users.ResultsA low recommendation gap was observed (<2.5%) and, according to the results obtained in the user testing, high percentage values for usefulness (82.38%) and satisfaction (87.89%) were obtained. The user evaluation also reported high values concerning other dimensions such as ease of use (89.00%) and ease of learning (92.38%).ConclusionsResults obtained helped answer main research questions, demonstrating that it is possible to create a mechanism to recommend usability methods according to a software project's constraints, even under uncertainty, and also affirm that it is possible to systemize the recommendations with a scheduling tool being satisfactory for key stakeholders, denoting acceptable levels of recommendation appropriateness, usefulness, and overall usability."
Short communication - Regulated software meets DevOps,"AbstractContextRegulatory authorities require proofs from critical systems manufacturers that the software in their products is developed in accordance to prescribed development practices before accepting the product to the markets. This is challenging when using DevOps, where continuous integration and deployment are the default practices, which are not a good match with the regulatory software development standards.ObjectiveWe aim to bring DevOps and regulated software development closer to each other. First, we want to make it easier for developers to develop regulated software with tools and practices they are familiar with. Second, we want to allow regulatory authorities to build confidence on solutions provided by manufacturers by defining a mapping between DevOps and regulatory software development.MethodWe performed a literature survey and created research suggestions using exploratory research.ResultsTighter integration between development tools, requirements management, version control and deployment pipeline would simplify the creation of regulatory compliant development practices.ConclusionsRegulations could be improved for more agile and incremental method in quality approval, the final step before the actual deployment of the software. Improved development practices and tool integration, created in cooperation by tool vendors, system providers, and regulatory authorities, could support developers who are not comfortable with fixed, and rigid practices of regulated software development."
Research article - IFPUG Function Points to COSMIC Function Points convertibility: A fine-grained statistical approach,"AbstractBackgroundFunctional size measurement is widely used in software organizations because it supports the estimation of software development effort. Function Point Analysis was the first functional size measurement method and became quite popular. The COSMIC method is considered a second-generation method, due to its novel design, and has also gained wide acceptance. Since the proposal of the COSMIC method, the measure convertibility issue arose. Many studies have investigated this issue: several conversion techniques have been proposed and their accuracy has been evaluated through empirical studies.ObjectiveThe goal of the paper is to explore statistic conversion criteria that leverage the similarity between the Base Functional Components of the considered functional measurement methods, especially concerning elementary processes and functional processes.MethodStatistical models of the relationship between the considered measures were built, using Least Median of Squares linear regression. The models use measures of Function Point Analysis Base Functional Components and COSMIC Base Functional Components as independent and dependent variables, respectively. Accuracy of conversion was assessed via leave-one-out cross validation.ResultsThe proposed method was tested on three datasets, and was compared with other conversion methods. The proposed method achieved results that are never less accurate – and sometimes much more accurate – than alternative methods’.ConclusionsThe proposed method requires that when traditional Function Points are measured, information concerning Base Functional Components are recorded. If such information is available, the proposed approach is – according to the collected evidence – preferable to other conversion methods, with respect to both the effort required to obtain the results and their accuracy."
