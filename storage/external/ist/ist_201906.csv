title,abstract
Research article - Detecting terminological ambiguity in user stories: Tool and experimentation,"AbstractContext. Defects such as ambiguity and incompleteness are pervasive in software requirements, often due to the limited time that practitioners devote to writing good requirements. Objective.We study whether a synergy between humans’ analytic capabilities and natural language processing is an effective approach for quickly identifying near-synonyms, a possible source of terminological ambiguity. Method.We propose a tool-supported approach that blends information visualization with two natural language processing techniques: conceptual model extraction and semantic similarity. We evaluate the precision and recall of our approach compared to a pen-and-paper manual inspection session through a controlled quasi-experiment that involves 57 participants organized into 28 groups, each group working on one real-world requirements data set. Results.The experimental results indicate that manual inspection delivers higher recall (statistically significant with p ≤ 0.01) and non-significantly higher precision. Based on qualitative observations, we analyze the quantitative results and suggest interpretations that explain the advantages and disadvantages of each approach. Conclusions.Our experiment confirms conventional wisdom in requirements engineering: identifying terminological ambiguities is time consuming, even when with tool support; and it is hard to determine whether a near-synonym may challenge the correct development of a software system. The results suggest that the most effective approach may be a combination of manual inspection with an improved version of our tool."
Research article - GuideGen: An approach for keeping requirements and acceptance tests aligned via automatically generated guidance,"AbstractContextWhen software-based systems evolve, their requirements change. The changes in requirements affect the associated acceptance tests, which should be adapted accordingly. In practice, however, requirements and their acceptance tests are not always kept up-to-date nor aligned. Such inconsistencies may introduce software quality problems, unintended costs and project delays.ObjectiveIn order to keep evolving requirements and their acceptance tests aligned, we are developing an approach called GuideGen. GuideGen automatically generates guidance in natural language about how to adapt the impacted acceptance tests when their requirements change.MethodWe have implemented GuideGen as a prototype tool and evaluated it in two studies: first, by assessing the correctness, completeness, understandability and relevance of the generated guidance using three data sets from industry and second, by assessing the applicability and usefulness of the approach and the tool with 23 practitioners from ten companies.When a requirement having more than one associated acceptance test is changed, GuideGen currently generates guidance for all of them together. As a first step towards overcoming this limitation, we assessed how well existing methods for change impact analysis can identify the tests actually impacted by the changes in a requirement.ResultsIn the first study, we found that GuideGen produced correct guidance in about 67 to 89 percent of all changes. Our approach performed better for agile requirements than for traditional ones. The results of the second study show that GuideGen is perceived to be useful, but that the practitioners would prefer a GuideGen plug-in for commercial tools instead of a standalone tool. Further, in our experiment we could correctly identify the affected acceptance tests for 63% to 91% of the changes in the requirements.ConclusionOur approach facilitates the alignment of acceptance tests with the actual requirements and can improve the communication between requirements engineers and testers."
Research article - Quality requirements challenges in the context of large-scale distributed agile: An empirical study,"AbstractContextEngineering quality requirements in agile projects does not fit organically with agile methods. Despite the agile community acknowledges this, little empirical evidence has been published on this topic.ObjectiveThis exploratory qualitative interview-based study explicates the challenging situations experienced by practitioners in engineering the quality requirements in the context of large-scale distributed agile projects. Moreover, this study describes the practices that agile distributed teams currently use which could contribute by dealing with the identified challenges.MethodThe challenging situations and possible mitigation practices were studied from the perspective of 17 practitioners from large distributed agile project teams in six organizations in The Netherlands. Qualitative data were collected using semi-structured, open-ended interviews. Qualitative coding techniques were used for data analysis, to identify the challenges of engineering quality requirements, the mechanisms behind the challenges and the practices used that could mitigate the impact of those challenges. Further, by using dialog mapping technique for qualitative data structuring, we have mapped the identified mechanisms and practices to the challenges.ResultsFrom the perspective of the participating practitioners, our exploratory study revealed 15 challenges classified in five categories: (1) team coordination and communication, (2) quality assurance, (3) quality requirements elicitation, (4) conceptual challenges, and (5) software architecture. The study has also disclosed 13 mechanisms behind the challenges and 9 practices that could mitigate the impact of those challenges.ConclusionsThe main contributions of the paper are: (1) the explication of the challenges from practitioners’ perspective and the comparison of our findings with previously published results, (2) the description of the mechanisms behind the challenges, and (3) the identification of the practices currently used by agile teams that could mitigate the impact of the challenges. The findings of this study provide useful input into the process of designing possible solution approaches to overcome the challenges."
Research article - Investigation on test effort estimation of mobile applications: Systematic literature review and survey,"AbstractContextIn the last few years, the exigency of mobile devices has proliferated to prodigious heights. The process of developing the mobile software/application proceeds amidst testing phase to verify the correctness of the mobile app. The estimation of testing plays a vital role in the effective completion of testing.ObjectiveTo identify how estimation of test effort for mobile applications is distinct from other software via published literature and from mobile software organizations. Second is to recognize different issues in adapting traditional test estimation methods to the mobile domain and if suggestions from survey results could be helpful in providing an improved test estimation model for mobile applications.MethodA systematic literature review is conducted followed by a survey through an online questionnaire filled from experienced mobile application developers and testers.ResultsThe results from SLR cover identification of mobile app specific characteristics and reports test effort estimation techniques in the mobile domain. Findings from survey corroborate that a) Function Point/Test Point Analysis is highly adapted traditional test estimation technique to mobile domain; b) Challenges like uncertain requirements, no tool support for test estimation, complexity in testing, client miscommunication etc. are reported; c)Suggestions to improve test estimation process include proper test planning, adoption of agile methodology, healthier communication among client, developer, and tester etc.; d) On the basis of responses, Analytical Hierarchical Process (AHP) identifies “Diverse Devices and OS” along with “Type of App” as highly influential mobile app characteristic on the test estimation process.ConclusionResults conclude that the importance of identified mobile app characteristics from SLR cannot be ignored in the estimation process of mobile software testing. There might be a possibility to improve existing test estimation techniques for mobile apps by giving weight to mobile app specific characteristics and by considering suggestions from experienced developers and testers."
Research article - Towards functional change decision support based on COSMIC FSM method,"AbstractContext: Managing requirements change is a central issue in the software development industry. In fact, inappropriate decisions about a change request may jeopardize the project development progress by going over budget/time or delivering a software with functional requirements that do not fully meet the user’s needs. Hence, a change decision support is required for the success of the software development.Objective: This paper has a three-fold objective: (i) explore the applicability of the ISO standard COSMIC FSM method to evaluate a change request; (ii) investigate the use of estimation models to predict the effort required to handle a functional change and its impact on the initially estimated software development effort; and (iii) propose a decision support method that offers the appropriate information for the change advisory board members to decide whether to accept, deny or defer a functional change request.Method: To guide the decision on a change request, the method proposed in this paper accounts for the most important factors when evaluating a change request, namely the functional change status, the preference of the change requester, and the effort required to handle the change. The functional change status is identified based on the sensitivity of the changed functionality and the functional size of the functional change. The functional change effort can be estimated using several ways including the COCOMO II model, the Simple Linear Regression Model and expert judgment. Furthermore, this paper proposes a prototype to determine automatically the functional change status and offers pertinent information that the change advisory board can use to determine how to handle a change request. The use of the decision support method and tool is illustrated through three case studies.Results: A decision support method to help decision-makers respond to a functional change request is provided. This method takes into account the functional change status, the preference of the change requester and the functional change effort. The empirical evaluation of the proposed method is illustrated through three case studies. The role of experiments here is primarily to provide a proof-of-concept rather than an exhaustive evaluation.Conclusion: Using COSMIC FSM method, it is possible to identify functional changes leading to a potential impact on the software development progress. Based on the evaluation of the functional change, the change advisory board members can make judicious decisions about whether to accept, defer or deny a functional change request."
Research article - CaMeLOT: An educational framework for conceptual data modelling,"AbstractContextTeaching conceptual data modelling (CDM) remains a challenging task for educators. Despite the fact that CDM is an integral part of software engineering curricula, there is no generally accepted educational framework for the subject. Moreover, the existing educational literature shows significant gaps when it comes to pursued learning outcomes and their assessment.ObjectiveIn this paper, we propose an educational framework for conceptual data modelling, based on the revised Bloom's taxonomy of educational objectives, and provide necessary examples of systemized learning outcomes.MethodWe utilized the revised Bloom's taxonomy to develop an adapted framework specifically for learning outcomes related to CDM. We validated the framework by mapping learning outcomes distilled from the existing course material to the framework, by presenting the framework for feedback to the experts in the field and further elaborating and refining it based on the feedback and experiences from these validation activities.ResultsCaMeLOT is an adaptation of the Bloom's taxonomy specifically for learning outcomes related to CDM. We identified different content areas and indicated the necessary scaffolding. Based on the framework, we worked out 17 example tables of learning outcomes related to content areas at different levels of scaffolding, exemplifying the different knowledge and cognitive levels. We clarify the differences in learning outcomes related to different knowledge and cognitive levels and thereby provide a domain specific clarification of the classification guidelines.ConclusionCaMeLOT gives educators an opportunity to enhance the CDM part of software engineering curricula with a systemized set of learning outcomes to be pursued, and open the path for creating more complete, useful and effective assessment packages. The adoption of our educational framework may reduce the time spent on designing educational material and, at the same time, improve its quality."
Research article - Why is my code change abandoned?,"AbstractContext: Software developers contribute numerous changes every day to the code review systems. However, not all submitted changes are merged into a codebase because they might not pass the code review process. Some changes would be abandoned or be asked for resubmission after improvement, which results in more workload for developers and reviewers, and more delays to deliverables.Objective: To understand the underlying reasons why changes are abandoned, we conduct an empirical study on the code review of four open source projects (Eclipse, LibreOffice, OpenStack, and Qt).Method: First, we manually analyzed 1459 abandoned changes. Second, we leveraged the open card sorting method to label these changes with reasons why they were abandoned, and we identified 12 categories of reasons. Next, we further investigated the frequency distribution of the categories across projects. Finally, we studied the relationship between the categories and time-to-abandonment.Results: Our findings include the following: (1) Duplicate changes are the majority of the abandoned changes; (2) the frequency distribution of abandoned changes across the 12 categories is similar for the four open source projects; (3) 98.39% of the changes are abandoned within a year.Conclusion: Our study concluded the root causes of abandoned changes, which will help developers submit high-quality code changes."
Research article - FineLocator: A novel approach to method-level fine-grained bug localization by query expansion,"AbstractContextBug localization, namely, to locate suspicious snippets from source code files for developers to fix the bug, is crucial for software quality assurance and software maintenance. Effective bug localization technique is desirable for software developers to reduce the effort involved in bug resolution. State-of-the-art bug localization techniques concentrate on file-level coarse-grained localization by lexical matching bug reports and source code files. However, this would bring about a heavy burden for developers to locate feasible code snippets to make change with the goal of fixing the bug.ObjectiveThis paper proposes a novel approach called FineLocator to method-level fine-grained bug localization by using semantic similarity, temporal proximity and call dependency for method expansion.MethodFirstly, the bug reports and the methods of source code are represented by numeric vectors using word embedding (word2vec) and the TF-IDF method. Secondly, we propose three query expansion scores as semantic similarity score, temporal proximity score and call dependency score to address the representation sparseness problem caused by the short lengths of methods in the source code. Then, the representation of a method with short length is augmented by elements of its neighboring methods with query expansion. Thirdly, when a new bug report is incoming, FineLocator will retrieve the methods in source code by similarity ranking on the bug report and the augmented methods for bug localization.ResultsWe collect bug repositories of ArgoUML, Maven, Kylin, Ant and AspectJ projects to investigate the performance of the proposed FineLocator approach. Experimental results demonstrate that the proposed FineLocator approach can improve the performances of method-level bug localization at average by 20%, 21% and 17% measured by Top-N indicator, MAP and MRR respectively, in comparison with state-of-the-art techniques.ConclusionThis is the first paper to demonstrate how to make use of method expansion to address the representation sparseness problem for method-level fine-grained bug localization."
Short communication - Revisiting the refactoring mechanics,"AbstractContextRefactoring is a key practice in agile methodologies used by a number of developers, and available in popular IDEs. However, it is unclear whether the refactoring mechanics have the same meaning for developers.ObjectiveIn this article, we revisit the refactoring mechanics.MethodWe conduct a survey with 107 developers of popular Java projects on GitHub. We asked them about the output of seven refactoring types applied to small programs.ResultsDevelopers do not expect the same outputs in all questions. The refactoring mechanics is based on developers’ experience for a number of them (71.02%). Some developers (75.70%) use IDEs to apply refactorings. However, the output yielded by the preferred IDE is different from what they want.ConclusionDevelopers and IDE developers use different mechanics for most refactoring types considered in our survey, and this may impact developers’ communication."
Research article - Images don’t lie: Duplicate crowdtesting reports detection with screenshot information,"AbstractContext: Crowdtesting is effective especially when it comes to the feedback on GUI systems, or subjective opinions about features. Despite of this, we find crowdtesting reports are highly duplicated, i.e., 82% of them are duplicates of others. Most of the existing approaches mainly adopted textual information for duplicate detection, and suffered from low accuracy because of the lexical gap. Our observation on real industrial crowdtesting data found that when dealing with crowdtesting reports of GUI systems, the reports would be accompanied with images, i.e., the screenshots of the tested app. We assume the screenshot to be valuable for duplicate crowdtesting report detection because it reflects the real context of the bug and is not affected by the variety of natural languages.Objective: We aim at automatically detecting duplicate crowdtesting reports that could help reduce triaging effort.Method: In this work, we propose SETU which combines information from the ScrEenshots and the TextUal descriptions to detect duplicate crowdtesting reports. We extract four types of features to characterize the screenshots (i.e., image structure feature and image color feature) and the textual descriptions (i.e., TF-IDF feature and word embedding feature), and design a hierarchical algorithm to detect duplicates based on the four similarity scores derived from the four features respectively.Results: We investigate the effectiveness of SETU on 12 projects with 3,689 reports from one of the Chinese largest crowdtesting platforms. Results show that recall@1 achieved by SETU is 0.44 to 0.79, recall@5 is 0.66 to 0.92, and MAP is 0.21 to 0.58 across all experimental projects. Furthermore, SETU can outperform existing state-of-the-art approaches significantly and substantially.Conclusion: Through combining the screenshots and textual descriptions, our proposed SETU can improve the duplicate crowdtesting reports detection performance."
Review article - Reusability in goal modeling: A systematic literature review,"AbstractContext: Goal modeling is an important instrument for the elicitation, specification, analysis, and validation of early requirements. Goal models capture hierarchical representations of stakeholder objectives, requirements, possible solutions, and their relationships to help requirements engineers understand stakeholder goals and explore solutions based on their impact on these goals. To reuse a goal model and benefit from the strengths of goal modeling, we argue that it is necessary (i) to make sure that analysis and validation of goal models is possible through reuse hierarchies, (ii) to provide the means to delay decision making to a later point in the reuse hierarchy, (iii) to take constraints imposed by other modeling notations into account during analysis, (iv) to allow context dependent information to be modeled so that the goal model can be used in various reuse contexts, and (v) to provide an interface for reuse.Objective: In this two-part systematic literature review, we (i) evaluate how well existing goal modeling approaches support reusability with our five desired characteristics of contextual and reusable goal models, (ii) categorize these approaches based on language constructs for context modeling and connection to other modeling formalisms, and then (iii) draw our conclusions on future research themes.Method: Following guidelines by Kitchenham, the review is conducted on seven major academic search engines. Research questions, inclusion criteria, and categorization criteria are specified, and threats to validity are discussed. A final list of 146 publications and 34 comparisons/assessments of goal modeling approaches is discussed in more detail.Results: Five major research themes are derived to realize reusable goal models with context dependent information.Conclusion: The results indicate that existing goal modeling approaches do not fully address the required capabilities for reusability in different contexts and that further research is needed to fill this gap in the landscape of goal modeling approaches."
Research article - Reference Coupling: An exploration of inter-project technical dependencies and their characteristics within large software ecosystems,"AbstractContextSoftware projects often depend on other projects or are developed in tandem with other projects. Within such software ecosystems, knowledge of cross-project technical dependencies is important for (1) practitioners understanding of the impact of their code change and coordination needs within the ecosystem and (2) researchers in exploring properties of software ecosystems based on these technical dependencies. However, identifying technical dependencies at the ecosystem level can be challenging.ObjectiveIn this paper, we describe Reference Coupling, a new method that uses solely the information in developers online interactions to detect technical dependencies between projects. The method establishes dependencies through user-specified cross-references between projects. We then use the output of this method to explore the properties of large software ecosystems.MethodWe validate our method on two datasets — one from open-source projects hosted on GitHub and one commercial dataset of IBM projects. We manually analyze the identified dependencies, categorize them, and compare them to dependencies specified by the development team. We examine the types of projects involved in the identified ecosystems, the structure of the identified ecosystems, and how the ecosystems structure compares with the social behavior of project contributors and owners.ResultsWe find that our Reference Coupling method often identifies technical dependencies between projects that are untracked by developers. We describe empirical insights about the characteristics of large software ecosystems. We find that most ecosystems are centered around one project and are interconnected with other ecosystems. By exploring the socio-technical alignment within the GitHub ecosystems, we also found that the project owners social behavior aligns well with the technical dependencies within the ecosystem, but the project contributors social behavior does not align with these dependencies.ConclusionsWe conclude with a discussion on future research that is enabled by our Reference Coupling method."
