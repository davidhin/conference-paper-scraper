title,abstract
Research article - A large-scale empirical study on the lifecycle of code smell co-occurrences,"AbstractContextCode smells are suboptimal design or implementation choices made by programmers during the development of a software system that possibly lead to low code maintainability and higher maintenance costs.ObjectivePrevious research mainly studied the characteristics of code smell instances affecting a source code file, while only few studies analyzed the magnitude and effects of smell co-occurrence, i.e., the co-occurrence of different types of smells on the same code component. This paper aims at studying in details this phenomenon.MethodWe analyzed 13 code smell types detected in 395 releases of 30 software systems to firstly assess the extent to which code smells co-occur, and then we analyze (i) which code smells co-occur together, and (ii) how and why they are introduced and removed by developers.Results59% of smelly classes are affected by more than one smell, and in particular there are six pairs of smell types (e.g., Message Chains and Spaghetti Code) that frequently co-occur. Furthermore, we observed that method-level code smells may be the root cause for the introduction of class-level smells. Finally, code smell co-occurrences are generally removed together as a consequence of other maintenance activities causing the deletion of the affected code components (with a consequent removal of the code smell instances) as well as the result of a major restructuring or scheduled refactoring actions.ConclusionsBased on our findings, we argue that more research aimed at designing co-occurrence-aware code smell detectors and refactoring approaches is needed."
Research article - Non-technical individual skills are weakly connected to the maturity of agile practices,"AbstractContext: Existing knowledge in agile software development suggests that individual competency (e.g. skills) is a critical success factor for agile projects. While assuming that technical skills are important for every kind of software development project, many researchers suggest that non-technical individual skills are especially important in agile software development.Objective: In this paper, we investigate whether non-technical individual skills can predict the use of agile practices.Method: Through creating a set of multiple linear regression models using a total of 113 participants from agile teams in six software development organizations from The Netherlands and Brazil, we analyzed the predictive power of non-technical individual skills in relation to agile practices.Results: The results show that there is surprisingly low power in using non-technical individual skills to predict (i.e. explain variance in) the mature use of agile practices in software development.Conclusions: Therefore, we conclude that looking at non-technical individual skills is not the optimal level of analysis when trying to understand, and explain, the mature use of agile practices in the software development context. We argue that it is more important to focus on the non-technical skills as a team-level capacity instead of assuring that all individuals possess such skills when understanding the use of the agile practices."
Research article - Effort estimation in large-scale software development: An industrial case study,"AbstractContext: Software projects frequently incur schedule and budget overruns. Planning and estimation are particularly challenging in large and globally distributed agile projects. While software engineering researchers have been investigating effort estimation for many years to help practitioners to improve their estimation processes, there is little empirical research about effort estimation in large-scale distributed projects involving agile teams.Objective: The objective of this paper is three-fold: i) To identify how effort estimation is carried out in large-scale distributed agile projects; ii) to analyze the accuracy of the effort estimation processes in large-scale distributed agile projects; and iii) to identify and investigate the factors that impact the accuracy of effort estimates in large-scale distributed agile projects.Method: We performed an exploratory longitudinal case study. The data collection was operationalized through archival research and semi-structured interviews.Results: The main findings of the studied case are: 1) A two-stage estimation process, with re-estimation at the analysis stage, improves the accuracy of the effort estimates; 2) underestimation is the dominant trend; 3) less mature teams incur larger effort overruns; 4) requirements with larger size/scope incur larger effort overruns; 5) requirements developed in multi-site settings incur larger effort overruns as compared to requirements developed in a co-located setting; 6) requirements priorities impact the accuracy of the effort estimates.Conclusion: A two-stage effort estimation process can improve effort estimation accuracy and seems to address some of the challenges in large-scale agile software development. To improve effort estimates one needs to consider team maturity, distribution as well as requirements size and priorities."
Research article - We’re doing it live: A multi-method empirical study on continuous experimentation,"AbstractContextContinuous experimentation guides development activities based on data collected on a subset of online users on a new experimental version of the software. It includes practices such as canary releases, gradual rollouts, dark launches, or A/B testing.ObjectiveUnfortunately, our knowledge of continuous experimentation is currently primarily based on well-known and outspoken industrial leaders. To assess the actual state of practice in continuous experimentation, we conducted a mixed-method empirical study.MethodIn our empirical study consisting of four steps, we interviewed 31 developers or release engineers, and performed a survey that attracted 187 complete responses. We analyzed the resulting data using statistical analysis and open coding.ResultsOur results lead to several conclusions: (1) from a software architecture perspective, continuous experimentation is especially enabled by architectures that foster independently deployable services, such as microservices-based architectures; (2) from a developer perspective, experiments require extensive monitoring and analytics to discover runtime problems, consequently leading to developer on call policies and influencing the role and skill sets required by developers; and (3) from a process perspective, many organizations conduct experiments based on intuition rather than clear guidelines and robust statistics.ConclusionOur findings show that more principled and structured approaches for release decision making are needed, striving for highly automated, systematic, and data- and hypothesis-driven deployment and experimentation."
Short communication - Machine translation-based bug localization technique for bridging lexical gap,"AbstractContextThe challenge of locating bugs in mostly large-scale software systems has led to the development of bug localization techniques. However, the lexical mismatch between bug reports and source codes degrades the performances of existing information retrieval or machine learning-based approaches.ObjectiveTo bridge the lexical gap and improve the effectiveness of localizing buggy files by leveraging the extracted semantic information from bug reports and source code.MethodWe present BugTranslator, a novel deep learning-based machine translation technique composed of an attention-based recurrent neural network (RNN) Encoder-Decoder with long short-term memory cells. One RNN encodes bug reports into several context vectors that are decoded by another RNN into code tokens of buggy files. The technique studies and adopts the relevance between the extracted semantic information from bug reports and source files.ResultsThe experimental results show that BugTranslator outperforms a current state-of-the-art word embedding technique on three open-source projects with higher MAP and MRR. The results show that BugTranslator can rank actual buggy files at the second or third places on average.ConclusionBugTranslator distinguishes bug reports and source code into different symbolic classes and then extracts deep semantic similarity and relevance between bug reports and the corresponding buggy files to bridge the lexical gap at its source, thereby further improving the performance of bug localization."
Research article - SPIRITuS: a SimPle Information Retrieval regressIon Test Selection approach,"AbstractContext:Regression Test case Selection (RTS) approaches aim at selecting only those test cases of a test suite that exercise changed parts of the System Under Test (SUT) or parts affected by changes.Objective:We present SPIRITuS (SimPle Information Retrieval regressIon Test Selection approach). It uses method code coverage information and a Vector Space Model to select test cases to be run. In a nutshell, the extent of a lexical modification to a method is used to decide if a test case has to be selected. The main design goals of SPIRITuS are to be: (i) easy to adapt to different programming languages and (ii) tunable via an easy to understand threshold.Method:To assess SPIRITuS, we conducted a large experiment on 389 faulty versions of 14 open-source programs implemented in Java. We were mainly interested in investigating the tradeoff between the number of selected test cases from the original test suite and fault detection effectiveness. We also compared SPIRITuS against well-known RTS approaches.Results:SPIRITuS selects a number of test cases significantly smaller than the number of test cases the other approaches select at the price of a slight reduction in fault detection capability.Conclusions:SPIRITuS can be considered a viable competitor of existing test case selection approaches especially when the average number of test cases covering a modified method increases (such information can be easily derived before test case selection takes place)."
Research article - Fixing class design inconsistencies using self regulating particle swarm optimization,"AbstractContextThe practice of using Unified Modeling Language models during software development and the chances of occurrence of model inconsistencies during software design are increasing. Hence detection of intra-model design inconsistencies is significant in the development of quality software.ObjectiveThe existing approaches of detecting class attribute inconsistencies rely on human decision making. Manual detection of inconsistencies is exhaustive, time consuming and sometimes incomplete. Therefore, we propose an automated and novel approach to perform consistency check of class attributes using artificial intelligence.MethodInconsistency in attribute definition and specification is detected and fixed with self regulating particle swarm optimization (SRPSO) algorithm that uses a fitness function to optimize the consistency of attributes in class diagram and activity diagrams. SRPSO is preferred since the best particle is not influenced by its or others experience and uses its direction as the best direction and the remaining particles use self and social knowledge to update their velocity and position.ResultThe use of artificial intelligence technique for detection and fixing of inconsistencies during the software design phase ensures design completeness through generation of models with consistent attribute definitions and a significant improvement in software quality prediction, accurate code generation, meeting time deadlines, and software production and maintenance cost is achieved.ConclusionEnsuring consistency and completeness of models is an inevitable aspect in software design and development. The proposed approach automates the process of inconsistency detection and correction in class attribute definition and specification using SRPSO algorithm during the design phase of software development."
Short communication - Not all bug reopens are negative: A case study on eclipse bug reports,"AbstractContextWe observed a special type of bug reopen that has no direct impact on the user experience or the normal operation of the system being developed. We refer to these as non-negative bug reopens.ObjectiveNon-negative bug reopens are novel and somewhat contradictory to popular conceptions. Therefore, we thoroughly explored these phenomena in this study.MethodWe begin with a novel approach that preliminarily characterizes non-negative bug reopens. Based on bug reports extracted from Eclipse Bugzilla, we then examined a case study to compare non-negative and regular bug reopens using the Wilcoxon-Mann-Whitney test.ResultsThe results show that non-negative bug reopens are statistically significantly different than regular bug reopens, based on their survival times and the number of developers involved in the entire debugging process.ConclusionTaking into account the significant differences, we suggest that the effects of non-negative bug reopens should be considered in future research in related areas, such as bug triage and reopened bug prediction."
Research article - Combinatorial-based event sequence testing of Android applications,"AbstractContext: Mobile applications are Event Driven Systems (EDS) that take Graphical User Interface (GUI) event sequences as input and respond by changing their state. EDS are often tested with event sequences that exercise system functionality. Much of prior work focuses on testing random event sequences. Combinatorial-based techniques are often used to systematically generate event combinations and may be extended to test behavior that occurs only when events are executed in a particular order. We expand upon the state-of-the-art by using combinatorial-based techniques to systematically test Android applications with automatically generated GUI event sequences.Objective: This paper describes a combinatorial-based technique for automatic construction of Android application test suites. The goal is to minimize redundant execution of events, maximize coverage of event combinations, and increase the likelihood of testing behavior that occurs when GUI events are executed in a particular order.Method: A greedy online algorithm selects and executes GUI events that maximize coverage of n-way event combinations, where n is a specified event combination strength. We compare our combinatorial-based technique to random and frequency-based techniques. We use a two-hour time budget to generate test suites for ten Android applications and empirically evaluate the test suites in terms of code and event coverage.Results: Our 2-way and 3-way combinatorial-based test suites achieve better code and event coverage compared to random and frequency-based test suites in the majority of our subject applications. The results show that there is no significant difference in code or event coverage between 2-way and 3-way combinatorial-based test suites.Conclusion: Given the time budget, the combinatorial-based technique is more effective than random and frequency-based techniques, but its effectiveness may vary depending on specific characteristics of the application under test."
Research article - The role and value of replication in empirical software engineering results,"AbstractContextConcerns have been raised from many quarters regarding the reliability of empirical research findings and this includes software engineering. Replication has been proposed as an important means of increasing confidence.ObjectiveWe aim to better understand the value of replication studies, the level of confirmation between replication and original studies, what confirmation means in a statistical sense and what factors modify this relationship.MethodWe perform a systematic review to identify relevant replication experimental studies in the areas of (i) software project effort prediction and (ii) pair programming. Where sufficient details are provided we compute prediction intervals.ResultsOur review locates 28 unique articles that describe replications of 35 original studies that address 75 research questions. Of these 10 are external, 15 internal and 3 internal-same-article replications. The odds ratio of internal to external (conducted by independent researchers) replications of obtaining a ‘confirmatory’ result is 8.64. We also found incomplete reporting hampered our ability to extract estimates of effect sizes. Where we are able to compute replication prediction intervals these were surprisingly large.ConclusionWe show that there is substantial evidence to suggest that current approaches to empirical replications are highly problematic. There is a consensus that replications are important, but there is a need for better reporting of both original and replicated studies. Given the low power and incomplete reporting of many original studies, it can be unclear the extent to which a replication is confirmatory and to what extent it yields additional knowledge to the software engineering community. We recommend attention is switched from replication research to meta-analysis."
Research article - Reliability of search in systematic reviews: Towards a quality assessment framework for the automated-search strategy,"AbstractContextThe trust in systematic literature reviews (SLRs) to provide credible recommendations is critical for establishing evidence-based software engineering (EBSE) practice. The reliability of SLR as a method is not a given and largely depends on the rigor of the attempt to identify, appraise and aggregate evidence. Previous research, by comparing SLRs on the same topic, has identified search as one of the reasons for discrepancies in the included primary studies. This affects the reliability of an SLR, as the papers identified and included in it are likely to influence its conclusions.ObjectiveWe aim to propose a comprehensive evaluation checklist to assess the reliability of an automated-search strategy used in an SLR.MethodUsing a literature review, we identified guidelines for designing and reporting automated-search as a primary search strategy. Using the aggregated design, reporting and evaluation guidelines, we formulated a comprehensive evaluation checklist. The value of this checklist was demonstrated by assessing the reliability of search in 27 recent SLRs.ResultsUsing the proposed evaluation checklist, several additional issues (not captured by the current evaluation checklist) related to the reliability of search in recent SLRs were identified. These issues severely limit the coverage of literature by the search and also the possibility to replicate it.ConclusionInstead of solely relying on expensive replications to assess the reliability of SLRs, this work provides means to objectively assess the likely reliability of a search-strategy used in an SLR. It highlights the often-assumed aspect of repeatability of search when using automated-search. Furthermore, by explicitly considering repeatability and consistency as sub-characteristics of a reliable search, it provides a more comprehensive evaluation checklist than the ones currently used in EBSE."
Review article - Reproducibility and replicability of software defect prediction studies,"AbstractContext: Replications are an important part of scientific disciplines. Replications test the credibility of original studies and can separate true results from those that are unreliable.Objective: In this paper we investigate the replication of defect prediction studies and identify the characteristics of replicated studies. We further assess how defect prediction replications are performed and the consistency of replication findings.Method: Our analysis is based on tracking the replication of 208 defect prediction studies identified by a highly cited Systematic Literature Review (SLR) [1]. We identify how often each of these 208 studies has been replicated and determine the type of replication carried out. We identify quality, citation counts, publication venue, impact factor, and data availability from all 208 SLR defect prediction papers to see if any of these factors are associated with the frequency with which they are replicated.Results: Only 13 (6%) of the 208 studies are replicated. Replication seems related to original papers appearing in the Transactions of Software Engineering (TSE) journal. The number of citations an original paper had was also an indicator of replications. In addition, studies conducted using closed source data seems to have more replications than those based on open source data. Where a paper has been replicated, 11 (38%) out of 29 studies revealed different results to the original study.Conclusion: Very few defect prediction studies are replicated. The lack of replication means that it remains unclear how reliable defect prediction is. We provide practical steps for improving the state of replication."
Review article - Reproducibility and credibility in empirical software engineering: A case study based on a systematic literature review of the use of the SZZ algorithm,"AbstractContextReproducibility of Empirical Software Engineering (ESE) studies is an essential part for improving their credibility, as it offers the opportunity to the research community to verify, evaluate and improve their research outcomes.ObjectiveWe aim to study reproducibility and credibility in ESE with a case study, by investigating how they have been addressed in studies where SZZ, a widely-used algorithm by Śliwerski, Zimmermann and Zeller to detect the origin of a bug, has been applied.MethodologyWe have performed a systematic literature review to evaluate publications that use SZZ. In total, 187 papers have been analyzed for reproducibility, reporting of limitations and use of improved versions of the algorithm.ResultsWe have found a situation with a lot of room for improvement in ESE as reproducibility is not commonly found; factors that undermine the credibility of results are common. We offer some lessons learned and guidelines for researchers and reviewers to address this problem.ConclusionReproducibility and other related aspects that ensure a high quality scientific process should be taken more into consideration by the ESE community in order to increase the credibility of the research results."
