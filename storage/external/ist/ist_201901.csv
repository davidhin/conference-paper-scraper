title,abstract
Research article - What can violations of good practices tell about the relationship between GoF patterns and run-time quality attributes?,"AbstractContextGoF patterns have been extensively studied with respect to the benefit they provide as problem-solving, communication and quality improvement mechanisms. The latter has been mostly investigated through empirical studies, but some aspects of quality (esp. run-time ones) are still under-investigated.ObjectiveIn this paper, we study if the presence of patterns enforces the conformance to good coding practices. To achieve this goal, we explore the relationship between the presence of GoF design patterns and violations of good practices related to source code correctness, performance and security, via static analysis.MethodSpecifically, we exploit static analysis so as to investigate whether the number of violations of good coding practices identified on classes is related to: (a) their participation in pattern occurrences, (b) the pattern category, (c) the pattern in which they participate, and (d) their role within the pattern occurrence. To answer these questions, we performed a case study on approximately 13,000 classes retrieved from five open-source projects.ResultsThe obtained results suggest that classes not participating in patterns are more probable to violate good coding practices for correctness, performance and security. In a more fine-grained level of analysis, by focusing on specific patterns, we observed that patterns with more complex structure (e.g., Decorator) and pattern roles that are more change-prone (e.g., Subclasses) are more likely to be associated with a higher number of violations (up to 50 times more violations).ConclusionThis finding implies that investing in a well-thought architecture based on best practices, such as patterns, is often accompanied with cleaner code with fewer violations."
Research article - Improving bug localization with word embedding and enhanced convolutional neural networks,"AbstractContext: Automatic localization of buggy files can speed up the process of bug fixing to improve the efficiency and productivity of software quality assurance teams. Useful semantic information is available in bug reports and source code, but it is usually underutilized by existing bug localization approaches.Objective: To improve the performance of bug localization, we propose DeepLoc, a novel deep learning-based model that makes full use of semantic information.Method: DeepLoc is composed of an enhanced convolutional neural network (CNN) that considers bug-fixing recency and frequency, together with word-embedding and feature-detecting techniques. DeepLoc uses word embeddings to represent the words in bug reports and source files that retain their semantic information, and different CNNs to detect features from them. DeepLoc is evaluated on over 18,500 bug reports extracted from AspectJ, Eclipse, JDT, SWT, and Tomcat projects.Results: The experimental results show that DeepLoc achieves 10.87%–13.4% higher MAP (mean average precision) than conventional CNN. DeepLoc outperforms four current state-of-the-art approaches (DeepLocator, HyLoc, LR+WE, and BugLocator) in terms of Accuracy@k (the percentage of bug reports for which at least one real buggy file is located within the top k rank), MAP, and MRR (mean reciprocal rank) using less computation time.Conclusion: DeepLoc is capable of automatically connecting bug reports to the corresponding buggy files and achieves better performance than four state-of-the-art approaches based on a deep understanding of semantics in bug reports and source code."
Research article - An extensible framework for software configuration optimization on heterogeneous computing systems: Time and energy case study,"AbstractContext: Application of component based software engineering methods to heterogeneous computing (HC) enables different software configurations to realize the same function with different non–functional properties (NFP). Finding the best software configuration with respect to multiple NFPs is a non–trivial task.Objective: We propose a Software Component Allocation Framework (SCAF) with the goal to acquire a (sub–) optimal software configuration with respect to multiple NFPs, thus providing performance prediction of a software configuration in its early design phase. We focus on the software configuration optimization for the average energy consumption and average execution time.Method: We validated SCAF through its instantiation on a real–world demonstrator and a simulation. Firstly, we verified the correctness of our model through comparing the performance prediction of six software configurations to the actual performance, obtained through extensive measurements with a confidence interval of 95%. Secondly, to demonstrate how SCAF scales up, we performed software configuration optimization on 55 generated use–cases (with solution spaces ranging from 1030 to 3070) and benchmark the results against best performing random configurations.Results: The performance of a configuration as predicted by our framework matched the configuration implemented and measured on a real–world platform. Furthermore, by applying the genetic algorithm and simulated annealing to the weight function given in SCAF, we obtain sub–optimal software configurations differing in performance at most 7% and 13% from the optimal configuration (respectfully).Conclusion: SCAF is capable of correctly describing a HC platform and reliably predict the performance of software configuration in the early design phase. Automated in the form of an Eclipse plugin, SCAF allows software architects to model architectural constraints and preferences, acting as a multi–criterion software architecture decision support system. In addition to said, we also point out several interesting research directions, to further investigate and improve our approach."
Research article - On the impact of code smells on the energy consumption of mobile applications,"AbstractContext. The demand for green software design is steadily growing higher especially in the context of mobile devices, where the computation is often limited by battery life. Previous studies found how wrong programming solutions have a strong impact on the energy consumption. Objective. Despite the efforts spent so far, only a little knowledge on the influence of code smells, i.e.,symptoms of poor design or implementation choices, on the energy consumption of mobile applications is available. Method. To provide a wider overview on the relationship between smells and energy efficiency, in this paper we conducted a large-scale empirical study on the influence of 9 Android-specific code smells on the energy consumption of 60 Android apps. In particular, we focus our attention on the design flaws that are theoretically supposed to be related to non-functional attributes of source code, such as performance and energy consumption. Results. The results of the study highlight that methods affected by four code smell types, i.e.,Internal Setter, Leaking Thread, Member Ignoring Method, and Slow Loop, consume up to 87 times more than methods affected by other code smells. Moreover, we found that refactoring these code smells reduces energy consumption in all of the situations. Conclusions. Based on our findings, we argue that more research aimed at designing automatic refactoring approaches and tools for mobile apps is needed."
Research article - Insights into startup ecosystems through exploration of multi-vocal literature,"AbstractContext: Successful startup firms have the ability to create jobs and contribute to economic welfare. A suitable ecosystem developed around startups is important to form and support these firms. In this regard, it is crucial to understand the startup ecosystem, particularly from researchers’ and practitioners’ perspectives. However, a systematic literature research on the startup ecosystem is limited. Objective: In this study, our objective was to conduct a multi-vocal literature review and rigorously find existing studies on the startup ecosystem in order to organize and analyze them, know the definitions and major elements of this ecosystem, and determine the roles of such elements in startups’ product development. Method: We conducted a multi-vocal literature review to analyze relevant articles, which are published technical articles, white papers, and Internet articles that focused on the startup ecosystem. Our search generated 18,310 articles, of which 63 were considered primary candidates focusing on the startup ecosystem. Results: From our analysis of primary articles, we found four definitions of a startup ecosystem. These definitions used common terms, such as stakeholders, supporting organization, infrastructure, network, and region. Out of 63 articles, 34 belonged to the opinion type, with contributions in the form of reports, whereas over 50% had full relevance to the startup ecosystem. We identified eight major elements (finance, demography, market, education, human capital, technology, entrepreneur, and support factors) of a startup ecosystem, which directly or indirectly affected startups. Conclusions: This study aims to provide the state of the art on the startup ecosystem through a multi-vocal literature review. The results indicate that current knowledge on the startup ecosystem is mainly shared by non-peer-reviewed literature, thus signifying the need for more systematic and empirical literature on the topic. Our study also provides some recommendations for future work."
Research article - An exploratory study of waste in software development organizations using agile or lean approaches: A multiple case study at 14 organizations,"AbstractContextThe principal focus of lean is the identification and elimination of waste from the process with respect to maximizing customer value. Similarly, the purpose of agile is to maximize customer value and minimize unnecessary work and time delays. In both cases the concept of waste is important. Through an empirical study, we explore how waste is approached in agile software development organizations.ObjectiveThis paper explores the concept of waste in agile/lean software development organizations and how it is defined, used, prioritized, reduced, or eliminated in practiceMethodThe data were collected using semi-structured open-interviews. 23 practitioners from 14 embedded software development organizations were interviewed representing two core roles in each organization.ResultsVarious wastes, categorized in 10 different categories, were identified by the respondents. From the mentioned wastes, not all were necessarily waste per se but could be symptoms caused by wastes. From the seven wastes of lean, Task-switching was ranked as the most important, and Extra-features, as the least important wastes according to the respondents’ opinion. However, most companies do not have their own or use an established definition of waste, more importantly, very few actively identify or try to eliminate waste in their organizations beyond local initiatives on project level.ConclusionIn order to identify, recognize and eliminate waste, a common understanding, and a joint and holistic view of the concept is needed. It is also important to optimize the whole organization and the whole product, as waste on one level can be important on another, thus sub-optimization should be avoided. Furthermore, to achieve a sustainable and effective waste handling, both the short-term and the long-term perspectives need to be considered."
Research article - Combining Automated GUI Exploration of Android apps with Capture and Replay through Machine Learning,"AbstractContextAutomated GUI Exploration Techniques have been widely adopted in the context of mobile apps for supporting critical engineering tasks such as reverse engineering, testing, and network traffic signature generation. Although several techniques have been proposed in the literature, most of them fail to guarantee the exploration of relevant parts of the applications when GUIs require to be exercised with particular and complex input event sequences. We refer to these GUIs as Gate GUIs and to the sequences required to effectively exercise them as Unlocking GUI Input Event Sequences.ObjectiveIn this paper, we aim at proposing a GUI exploration approach that exploits the human involvement in the automated process to solve the limitations introduced by Gate GUIs, without requiring the preliminary configuration of the technique or the user involvement for the entire duration of the exploration process.MethodWe propose juGULAR, a Hybrid GUI Exploration Technique combining Automated GUI Exploration with Capture and Replay. Our approach is able to automatically detect Gate GUIs during the app exploration by exploiting a Machine Learning approach and to unlock them by leveraging input event sequences provided by the user. We implement juGULAR in a modular software architecture that targets the Android mobile platform. We evaluate the performance of juGULAR by an experiment involving 14 real Android apps.ResultsThe experiment shows that the hybridization introduced by juGULAR allows to improve the exploration capabilities in terms of Covered Activities, Covered Lines of Code, and generated Network Traffic Bytes at a reasonable manual intervention cost. The experimental results also prove that juGULAR is able to outperform the state-of-the-practice tool Monkey.ConclusionWe conclude that the combination of Automated GUI Exploration approaches with Capture and Replay techniques is promising to achieve a thorough app exploration. Machine Learning approaches aid to pragmatically integrate these two techniques."
Research article - CERSE - Catalog for empirical research in software engineering: A Systematic mapping study,"AbstractContext Empirical research in software engineering contributes towards developing scientific knowledge in this field, which in turn is relevant to inform decision-making in industry. A number of empirical studies have been carried out to date in software engineering, and the need for guidelines for conducting and evaluating such research has been stressed.Objective: The main goal of this mapping study is to identify and summarize the body of knowledge on research guidelines, assessment instruments and knowledge organization systems on how to conduct and evaluate empirical research in software engineering.Method: A systematic mapping study employing manual search and snowballing techniques was carried out to identify the suitable papers. To build up the catalog, we extracted and categorized information provided by the identified papers.Results: The mapping study comprises a list of 341 methodological papers, classified according to research methods, research phases covered, and type of instrument provided. Later, we derived a brief explanatory review of the instruments provided for each of the research methods.Conclusion: We provide: an aggregated body of knowledge on the state of the art relating to guidelines, assessment instruments and knowledge organization systems for carrying out empirical software engineering research; an exemplary usage scenario that can be used to guide those carrying out such studies is also provided. Finally, we discuss the catalog’s implications for research practice and the needs for further research."
Research article - A first look at unfollowing behavior on GitHub,"AbstractContextMany open source software projects rely on contributors to fix bugs and contribute new features. On GitHub, developers often broadcast their activities to followers, which may entice followers to be project contributors. It is important to understand unfollowing behavior, maintain current followers, and attract some followers to become contributors in OSS projects.ObjectiveOur objective in this paper is to provide a comprehensive analysis of unfollowing behavior on GitHub.MethodTo the best of our knowledge, we present a first look at unfollowing behavior on GitHub. We collect a dataset containing 701,364 developers and their 4,602,440 following relationships in March 2016. We also crawl their following relationships in May 2013, August 2015 and November 2015. We conduct surveys, define potential impact factors, and analyze the correlation of factors with the likelihood of unfollowing behavior.ResultsOur main observations are: (1) Between May 2013 and August 2015, 19.8% of active developers ever unfollowed some users. (2) Developers are more likely to unfollow those who have fewer activities, lower programming language similarity, and asymmetric relationships.ConclusionOur results give suggestions for developers to reduce the likelihood of being unfollowed by their followers, and attract researchers’ attention on relationship dissolution."
Review article - Adaptive monitoring: A systematic mapping,"AbstractContextAdaptive monitoring is a method used in a variety of domains for responding to changing conditions. It has been applied in different ways, from monitoring systems’ customization to re-composition, in different application domains. However, to the best of our knowledge, there are no studies analyzing how adaptive monitoring differs or resembles among the existing approaches.ObjectiveTo characterize the current state of the art on adaptive monitoring, specifically to: (a) identify the main concepts in the adaptive monitoring topic; (b) determine the demographic characteristics of the studies published in this topic; (c) identify how adaptive monitoring is conducted and evaluated by the different approaches; (d) identify patterns in the approaches supporting adaptive monitoring.MethodWe have conducted a systematic mapping study of adaptive monitoring approaches following recommended practices. We have applied automatic search and snowballing sampling on different sources and used rigorous selection criteria to retrieve the final set of papers. Moreover, we have used an existing qualitative analysis method for extracting relevant data from studies. Finally, we have applied data mining techniques for identifying patterns in the solutions.ResultsWe have evaluated 110 studies organized in 81 approaches that support adaptive monitoring. By analyzing them, we have: (1) surveyed related terms and definitions of adaptive monitoring and proposed a generic one; (2) visualized studies’ demographic data and arranged the studies into approaches; (3) characterized the main approaches’ contributions; (4) determined how approaches conduct the adaptation process and evaluate their solutions.ConclusionsThis cross-domain overview of the current state of the art on adaptive monitoring may be a solid and comprehensive baseline for researchers and practitioners in the field. Especially, it may help in identifying opportunities of research; for instance, the need of proposing generic and flexible software engineering solutions for supporting adaptive monitoring in a variety of systems."
Review article - Software product line evolution: A systematic literature review,"AbstractContext: Software Product Lines (SPL) evolve when there are changes in the requirements, product structure or the technology being used. Different approaches have been proposed for managing SPL assets and some also address how evolution affects these assets. Existing mapping studies have focused on specific aspects of SPL evolution, but there is no cohesive body of work that gives an overview of the area as a whole.Objective: The goals of this work are to review the characteristics of the approaches reported as supporting SPL evolution, and to synthesize the evidence provided by primary studies about the nature of their processes, as well as how they are reported and validated.Method: We conducted a systematic literature review, considering six research questions formulated to evaluate evolution approaches for SPL. We considered journal, conference and workshop papers published up until March 2017 in leading digital libraries for computer science.Results: After a thorough analysis of the papers retrieved from the digital libraries, we ended up with a set of 60 primary studies. Feature models are widely used to represent SPLs, so feature evolution is frequently addressed. Other assets are less frequently addressed. The area has matured over time: papers presenting more rigorous work are becoming more common. The processes used to support SPL evolution are systematic, but with a low level of automation.Conclusions: Our research shows that there is no consensus about SPL formalization, what assets can evolve, nor how and when these evolve. Case studies are quite popular, but few industrial-sized case studies are publicly available. Also, few of the proposed techniques offer tool support. We believe that the SPL community needs to work together to improve the state of the art, creating methods and tools that support SPL evolution in a more comparable manner."
Review article - Integration of feature models: A systematic mapping study,"AbstractContextThe integration of feature models has been widely investigated in the last decades, given its pivotal role for supporting the evolution of software product lines. Unfortunately, academia and industry have overlooked the production of a thematic analysis of the current literature. Hence, a thorough understanding of the state-of-the-art works remains still limited.ObjectiveThis study seeks to create a panoramic view of the current literature to pinpoint gaps and supply insights of this research field.MethodA systematic mapping study was performed based on well-established empirical guidelines for answering six research questions. In total, 47 primary studies were selected by applying a filtering process from a sample of 2874 studies.ResultsThe main results obtained are: (1) most studies use a generic notation (68.09%, 32/47) for representing feature models; (2) only one study (2%, 1/47) compares feature models based on their syntactic and semantics; (3) there is no preponderant use of a particular integration technique in the selected studies; (4) most studies (70%, 33/47) provide a product-based strategy to evaluate the integrated feature models; (5) majority (70%, 33/47) automates the integration process; and (6) most studies (90%, 42/47) propose techniques, rather than focusing on producing practical knowledge derived from empirical studies.ConclusionThe results were encouraging and suggest that integration of feature models is still an evolving research area. This study provides insightful information for the definition of a more ambitious research agenda. Lastly, empirical studies exploring the required effort to apply the current integration techniques in real-world settings are highly recommended in future work."
Review article - Empirical research on concurrent software testing: A systematic mapping study,"AbstractBackground: Concurrent software testing is a costly and difficult task, especially due to the exponential increase in the test sequences caused by non-determinism. Such an issue has motivated researchers to develop testing techniques that select a subset of the input domain that has a high probability of revealing faults. Academics and industrial practitioners rarely use most concurrent software testing techniques because of the lack of data about their applicability. Empirical evidence can provide an important scientific basis for the strengths and weaknesses of each technique to help researchers and practitioners choose concurrent testing techniques appropriate for their environments.Aim: This paper gathers and synthesizes empirical research on concurrent software testing to characterize the field and the types of empirical studies performed.Method: We performed a systematic mapping study to identify and analyze empirical research on concurrent software testing techniques. We provide a detailed analysis of the studies and their design choices.Results: The primary findings are: (1) there is a general lack of empirical validation of concurrent software testing techniques, (2) the type of evaluation method varies with the type of technique, (3) there are some key challenges to empirical study design in concurrent software testing, and (4) there is a dearth of controlled experiments in concurrent software testing.Conclusions: There is little empirical evidence available about some specific concurrent testing techniques like model-based testing and formal testing. Overall, researchers need to perform more empirical work, especially real-world case studies and controlled experiments, to validate properties of concurrent software testing techniques. In addition, researchers need to perform more analyses and synthesis of the existing evidence. This paper is a first step in that direction."
Short communication - A new algorithm for software clustering considering the knowledge of dependency between artifacts in the source code,"AbstractContext: Software systems evolve over time to meet the new requirements of users. These new requirements, usually, are not reflected in the original documents of these software systems. Therefore, the new version of a software system deviates from the original and documented architecture. This way, it will be more difficult to understand it after a while and it will be difficult to make new changes conveniently. Clustering techniques are used to extract the architecture of a software system in order to understand it. An artifact dependency graph (ADG) is often used for clustering, which is extracted from a source code. In the literature, some hierarchical and search-based clustering methods have been presented to extract the software architecture. Hierarchical algorithms have reasonable search time; however, they are not able to find a good architecture. In contrast, search-based algorithms are often better in this regard; however, their time and space limitations make them useless in practice for large-scale software systems. Both hierarchical and search-based clustering methods overlook the existing knowledge in an ADG for clustering.Objective: To overcome the limitations of the existing clustering methods, this paper presents a new deterministic clustering algorithm named Neighborhood tree algorithm.Method: The new algorithm creates a neighborhood tree using available knowledge in an ADG and uses this tree for clustering.Results: Our initial results indicate that the algorithm is better able to extract an acceptable architecture in a reasonable time, compared with hierarchical and search-based algorithms.Conclusions: The proposed clustering algorithm is expected to greatly assist software engineers in extracting meaningful and understandable subsystems from a source code."
