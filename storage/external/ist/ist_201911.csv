title,abstract
Short communication - PrioriTTVs: A process aimed at supporting researchers to prioritize threats to validity and their mitigation actions when planning controlled experiments in SE,"AbstractContextResearchers argue that a critical component of any empirical study in Software Engineering (SE) is to identify, analyze, and mitigate threats to validity.ObjectiveWe propose PrioriTTVs, a process to support researchers in identifying and prioritizing threats to validity and their corresponding mitigation actions when planning controlled experiments in SE. We also introduce a tool to support the entire process.MethodEmpirical studies were conducted with six experts and 20 postgraduate students to evaluate the ease of use, learning, and perceptions of satisfaction regarding PrioriTTVs.ResultsSo far, participants have considered PrioriTTVs to be useful (83%), significantly contributing to learning (90%), and satisfaction (75%).ConclusionsWe believe both novice and expert users can benefit from the process we propose for addressing threats to validity when conducting SE experiments. We also intend to extend our approach to manage threats specific to different SE experiment contexts."
Short communication - Evaluating probabilistic software development effort estimates: Maximizing informativeness subject to calibration,"AbstractContextProbabilistic effort estimates inform about the uncertainty and may give useful input to plans, budgets and investment analyses.Objective & methodThis paper introduces, motivates and illustrates two principles on how to evaluate the accuracy and other performance criteria of probabilistic effort estimates in software development contexts.ResultsThe first principle emphasizes a consistency between the estimation error measure and the loss function of the chosen type of probabilistic single point effort estimates. The second principle points at the importance of not just measuring calibration, but also informativeness of estimated prediction intervals and distributions. The relevance of the evaluation principles is illustrated by a performance evaluation of estimates from twenty-eight software professionals using two different uncertainty assessment methods to estimate the effort of the same thirty software maintenance tasks."
Review article - Taking the emotional pulse of software engineering — A systematic literature review of empirical studies,"AbstractContextOver the past 50 years of Software Engineering, numerous studies have acknowledged the importance of human factors. However, software developers’ emotions are still an area under investigation and debate that is gaining relevance in the software industry.ObjectiveIn this study, a systematic literature review (SLR) was carried out to identify, evaluate, and synthesize research published concerning software developers’ emotions as well as the measures used to assess its existence.MethodBy searching five major bibliographic databases, authors identified 7172 articles related to emotions in Software Engineering. We selected 66 of these papers as primary studies. Then, they were analyzed in order to find empirical evidence of the intersection of emotions and software engineering.ResultsStudies report a total of 40 discrete emotions but the most frequent were: anger, fear, disgust, sadness, joy, love, and happiness. There are also 2 different dimensional approaches and 10 datasets related to this topic which are publicly available on the Web. The findings also showed that self-reported mood instruments (e.g., SAM, PANAS), physiological measures (e.g., heart rate, perspiration) or behavioral measures (e.g., keyboard use) are the least reported tools, although, there is a recognized intrinsic problem with the accuracy of current state of the art sentiment analysis tools. Moreover, most of the studies used software practitioners and/or datasets from industrial context as subjects.ConclusionsThe study of emotions has received a growing attention from the research community in the recent years, but the management of emotions has always been challenging in practice. Although it can be said that this field is not mature enough yet, our results provide a holistic view that will benefit researchers by providing the latest trends in this area and identifying the corresponding research gaps."
Review article - Bug report severity level prediction in open source software: A survey and research opportunities,"AbstractContext: The severity level attribute of a bug report is considered one of the most critical variables for planning evolution and maintenance in Free/Libre Open Source Software. This variable measures the impact the bug has on the successful execution of the software system and how soon a bug needs to be addressed by the development team. Both business and academic community have made an extensive investigation towards the proposal methods to automate the bug report severity prediction.Objective: This paper aims to provide a comprehensive mapping study review of recent research efforts on automatically bug report severity prediction. To the best of our knowledge, this is the first review to categorize quantitatively more than ten aspects of the experiments reported in several papers on bug report severity prediction.Method: The mapping study review was performed by searching four electronic databases. Studies published until December 2017 were considered. The initial resulting comprised of 54 papers. From this set, a total of 18 papers were selected. After performing snowballing, more nine papers were selected.Results: From the mapping study, we identified 27 studies addressing bug report severity prediction on Free/Libre Open Source Software. The gathered data confirm the relevance of this topic, reflects the scientific maturity of the research area, as well as, identify gaps, which can motivate new research initiatives.Conclusion: The message drawn from this review is that unstructured text features along with traditional machine learning algorithms and text mining methods have been playing a central role in the most proposed methods in literature to predict bug severity level. This scenario suggests that there is room for improving prediction results using state-of-the-art machine learning and text mining algorithms and techniques."
Short communication - Multi-reviewing pull-requests: An exploratory study on GitHub OSS projects,"AbstractContext:GitHub has enabled developers to easily contribute their review comments on multiple pull-requests and switch their review focus between different pull-requests, i.e., multi-reviewing. Reviewing multiple pull-requests simultaneously may enhance work efficiency. However, multi-reviewing also relies on developers’ rationally allocating their focus, which may bring a different influence to the resolution of pull-requests.Objective: In this paper, we present an ongoing study of the impact of multi-reviewing on pull-request resolution in GitHub open source projects.Method: We collected and analyzed 1,836,280 pull-requests from 760 GitHub projects to explore how multi-reviewing affects the resolution of a pull-request.Results: We find that multi-reviewing is a common behavior in GitHub. However, more multi-reviewing behaviors tend to bring longer pull-request resolution latency.Conclusion: Multi-reviewing is a complex behavior of developers, and has an important impact on the efficiency of pull-request resolution. Our study motivates the need for more research on multi-reviewing."
Research article - Using cognitive dimensions to evaluate the usability of security APIs: An empirical investigation,"AbstractContextUsability issues of security Application Programming Interfaces (APIs) are a main factor for mistakes programmers make that could result in introducing security vulnerabilities into applications they develop. This has become a common problem as there is no methodology to evaluate the usability of security APIs. A usability evaluation methodology for security APIs would allow API developers to identify usability issues of security APIs and fix them. A Cognitive Dimensions Framework (CDF) based usability evaluation methodology has been proposed in previous research to empirically evaluate the usability of security APIs.ObjectiveIn this research, we evaluated the proposed CDF based methodology through four security APIs (Google Authentication API, Bouncy Castle light weight Crypto API, Java Secure Socket Extension API, OWASP Enterprise Security API).MethodWe conducted four experiments where in each experiment we recruited programmers and they completed a programming task using one of the four security APIs. Participants’ feedback on each cognitive dimension of the particular API was collected using the cognitive dimensions questionnaire. Usability issues of each API was identified based on this feedback.ResultsResults of the four experiments revealed that over 83% of the usability issues in a security API could be identified by this methodology with a considerably good validity and reliability.ConclusionThe proposed CDF based usability evaluation methodology provides a good platform to conduct usability evaluation for security APIs."
Research article - Automatic recall of software lessons learned for software project managers,"AbstractContextLessons learned (LL) records constitute the software organization memory of successes and failures. LL are recorded within the organization repository for future reference to optimize planning, gain experience, and elevate market competitiveness. However, manually searching this repository is a daunting task, so it is often disregarded. This can lead to the repetition of previous mistakes or even missing potential opportunities. This, in turn, can negatively affect the organization's profitability and competitiveness.ObjectiveWe aim to present a novel solution that provides an automatic process to recall relevant LL and to push those LL to project managers. This will dramatically save the time and effort of manually searching the unstructured LL repositories and thus encourage the LL exploitation.MethodWe exploit existing project artifacts to build the LL search queries on-the-fly in order to bypass the tedious manual searching. An empirical case study is conducted to build the automatic LL recall solution and evaluate its effectiveness. The study employs three of the most popular information retrieval models to construct the solution. Furthermore, a real-world dataset of 212 LL records from 30 different software projects is used for validation. Top-k and MAP well-known accuracy metrics are used as well.ResultsOur case study results confirm the effectiveness of the automatic LL recall solution. Also, the results prove the success of using existing project artifacts to dynamically build the search query string. This is supported by a discerning accuracy of about 70% achieved in the case of top-k.ConclusionThe automatic LL recall solution is valid with high accuracy. It will eliminate the effort needed to manually search the LL repository. Therefore, this will positively encourage project managers to reuse the available LL knowledge – which will avoid old pitfalls and unleash hidden business opportunities."
Research article - The usefulness of software metric thresholds for detection of bad smells and fault prediction,"AbstractContextSoftware metrics may be an effective tool to assess the quality of software, but to guide their use it is important to define their thresholds. Bad smells and fault also impact the quality of software. Extracting metrics from software systems is relatively low cost since there are tools widely used for this purpose, which makes feasible applying software metrics to identify bad smells and to predict faults.ObjectiveTo inspect whether thresholds of object-oriented metrics may be used to aid bad smells detection and fault predictions.MethodTo direct this research, we have defined three research questions (RQ), two related to identification of bad smells, and one for identifying fault in software systems. To answer these RQs, we have proposed detection strategies for the bad smells: Large Class, Long Method, Data Class, Feature Envy, and Refused Bequest, based on metrics and their thresholds. To assess the quality of the derived thresholds, we have made two studies. The first one was conducted to evaluate their efficacy on detecting these bad smells on 12 systems. A second study was conducted to investigate for each of the class level software metrics: DIT, LCOM, NOF, NOM, NORM, NSC, NSF, NSM, SIX, and WMC, if the ranges of values determined by thresholds are useful to identify fault in software systems.ResultsBoth studies confirm that metric thresholds may support the prediction of faults in software and are significantly and effective in the detection of bad smells.ConclusionThe results of this work suggest practical applications of metric thresholds to identify bad smells and predict faults and hence, support software quality assurance activities.Their use may help developers to focus their efforts on classes that tend to fail, thereby minimizing the occurrence of future problems."
Research article - Scaling-up domain-specific modelling languages through modularity services,"AbstractContextModel-driven engineering (MDE) promotes the active use of models in all phases of software development. Even though models are at a high level of abstraction, large or complex systems still require building monolithic models that prove to be too big for their processing by existing tools, and too difficult to comprehend by users. While modularization techniques are well-known in programming languages, they are not the norm in MDE.ObjectiveOur goal is to ease the modularization of models to allow their efficient processing by tools and facilitate their management by users.MethodWe propose five patterns that can be used to extend a modelling language with services related to modularization and scalability. Specifically, the patterns allow defining model fragmentation strategies, scoping and visibility rules, model indexing services, and scoped constraints. Once the patterns have been applied to the meta-model of a modelling language, we synthesize a customized modelling environment enriched with the defined services, which become applicable to both existing monolithic legacy models and new models.ResultsOur proposal is supported by a tool called EMF-Splitter, combined with the Hawk model indexer. Our experiments show that this tool improves the validation performance of large models. Moreover, the analysis of 224 meta-models from OMG standards, and a public repository with more than 300 meta-models, demonstrates the applicability of our patterns in practice.ConclusionsModularity mechanisms typically employed in programming IDEs can be successfully transferred to MDE, leading to more scalable and structured domain-specific modelling languages and environments."
Research article - Test case selection-prioritization approach based on memoization dynamic programming algorithm,"AbstractContextIn the software industry, selection and prioritization techniques become a necessity in the regression and validation testing phases because a lot of test cases are available for reuse, yet time and project specific constraints must be respected.ObjectiveIn this paper we propose a dynamic programming approach in solving test case selection-prioritization problems. We focus on low memory consumption in pseudo-polynomial time complexity applicable in both selection and selection-prioritization problems over sets of test cases or test suites. In dynamic programming optimization solutions, huge amounts of memory are required and unfortunately the memory is limited. Therefore, lower memory consumption leads to a higher number of test cases to be involved in the selection process.MethodOur approach is suited for medium to large projects where the required memory space is not higher than the order of tens of GBytes. We employed both objective methods as the dynamic programming algorithm and subjective and empiric human decision as defining the prioritization criteria. Furthermore, we propose a method of employing multiple project specific criteria in evaluating the importance of a test case in the project context.ResultsTo evaluate the proposed solution relative to the classical dynamic programming knapsack solution, we developed a suite of comparative case studies based on 1000 generated scenarios as close as possible to real project scenarios. The results of the comparative study reported the proposed algorithm requires up to 400 times less memory in the best-case scenarios and about 40 times less memory in average.ConclusionThe solution delivers optimal results in pseudo-polynomial time complexity, is effective for amounts of test cases up to the order of millions and compared with the classical dynamic programming methods leads to higher number of test cases to be involved in the selection process due to reduced memory consumption."
Research article - Simsax: A measure of project similarity based on symbolic approximation method and software defect inflow,"AbstractBackgroundProfiling software development projects, in order to compare them, find similar sub-projects or sets of activities, helps to monitor changes in software processes. Since we lack objective measures for profiling or hashing, researchers often fall back on manual assessments.ObjectiveThe goal of our study is to define an objective and intuitive measure of similarity between software development projects based on software defect-inflow profiles.MethodWe defined a measure of project similarity called SimSAX which is based on segmentation of defect-inflow profiles, coding them into strings (sequences of symbols) and comparing these strings to find so-called motifs. We use simulations to find and calibrate the parameters of the measure. The objects in the simulations are two different large industry projects for which we know the similarity a priori, based on the input from industry experts. Finally, we apply the measure to find similarities between five industrial and six open source projects.ResultsOur results show that the measure provides the most accurate simulated results when the compared motifs are long (32 or more weeks) and we use an alphabet of 5 or more symbols. The measure provides the possibility to calibrate for each industrial case, thus allowing to optimize the method for finding specific patterns in project similarity.ConclusionsWe conclude that our proposed measure provides a good approximation for project similarity. The industrial evaluation showed that it can provide a good starting point for finding similar periods in software development projects."
