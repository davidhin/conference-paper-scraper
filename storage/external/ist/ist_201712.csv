title,abstract
Research article - Automated change-prone class prediction on unlabeled dataset using unsupervised method,"AbstractContextSoftware change-prone class prediction can enhance software decision making activities during software maintenance (e.g., resource allocating). Researchers have proposed many change-prone class prediction approaches and most are effective on labeled datasets (projects with historical labeled data). These approaches usually build a supervised model by learning from historical labeled data. However, a major challenge is that this typical change-prone prediction setting cannot be used for unlabeled datasets (e.g., new projects or projects with limited historical data). Although the cross-project prediction is a solution on unlabeled dataset, it needs the prior labeled data from other projects and how to select the appropriate training project is a difficult task.ObjectiveWe aim to build a change-prone class prediction model on unlabeled datasets without the need of prior labeled data.MethodWe propose to tackle this task by adopting a state-of-art unsupervised method, namely CLAMI. In addition, we propose a novel unsupervised approach CLAMI+ by extending CLAMI. The key idea is to enable change-prone class prediction on unlabeled dataset by learning from itself.ResultsThe experiments among 14 open source projects show that the unsupervised methods achieve comparable results to the typical supervised within-project and cross-project prediction baselines in average and the proposed CLAMI+ slightly improves the CLAMI method in average.ConclusionOur method discovers that it is effective for building change-prone class prediction model by using unsupervised method. It is convenient for practical usage in industry, since it does not need prior labeled data."
Research article - Which type of metrics are useful to deal with class imbalance in software defect prediction?,"AbstractContextThere are various ways to cope with class imbalance problem which is one of the main issues of software defect prediction. Sampling algorithms are implemented on both industrial and open-source software defect prediction data sets by practitioners to wipe out imbalanced data points. Sampling algorithms, up-to-date, have been employed either static or process code metrics.ObjectiveIn this study, sampling algorithms including Virtual, SMOTE, and HSDD (hybrid sampling for defect data sets) are explored using static code and quality metrics together. Our goal is not only to lead practitioners to decide the type of the metrics in defect prediction but also provide useful information for developers to design less defective software projects.MethodWe ran sampling experiments with three sampling algorithms on ten data sets (from GitHub). Feature selection is applied on large features of the data sets. Using five classifiers, the performance of the data sets after sampling is compared with initial data sets. Regression analyzes are implemented on quality metrics to find the most influential metrics for detecting defect proneness.ResultsRegardless of the type of the sampling, prediction performances are similar. Quality metrics surpassed static code metrics with respect to training times and prediction accuracies.ConclusionUsing quality metrics yields better prediction results rather than static code metrics in imbalanced data sets. As the count of project cloning increases, the number of defects decreases. Thus, approaches, related to the class imbalance, should be evaluated not only in terms of static code metrics but also for quality metrics."
Research article - Developing software systems to Big Data platform based on MapReduce model: An approach based on Model Driven Engineering,"AbstractContext: The need to analyze a large volume and variety of data for the purpose of extracting information has been promoting investments in Big Data, e.g., for storage, analysis and, more recently, methodologies and approaches for software system development for Big Data platforms. The application of software engineering for Big Data is recent and emerging, so in the literature we find a number of challenges and opportunities related to Big Data, but few practical approaches.ObjectiveIn this paper, we propose a practical approach based on MDE (Model Driven Engineering) to support the semi-automated development of software systems for Big Data platform that use MapReduce model.MethodThe proposed approach consists of framework, process, metamodels, visual Alf, transformation definitions written in ATL and Eclipse IDE plug-in. The proposed framework uses concepts of MDE, Weaving and software development based on Y. Our proposed process guides the use of our approach. A graphical notation and extended metamodel for Alf (i.e. visual Alf) assign executable behavior for UML or DSLs. An Eclipse IDE plug-in implements our approach.ResultsWe show the applicability of the proposed approach through an illustrative example.ConclusionOur approach brings a contribution because the development of software systems is assisted by models which preserves the business logic and adds Big Data features throughout the development process."
Research article - Reusable and generic design decisions for developing UML-based domain-specific languages,"AbstractContext: In recent years, UML-based domain-specific model languages (DSMLs) have become a popular option in model-driven development projects. However, making informed design decisions for such DSMLs involves a large number of non-trivial and inter-related options. These options concern the language-model specification, UML extension techniques, concrete-syntax language design, and modeling-tool support.Objective: In order to make the corresponding knowledge on design decisions reusable, proven design rationale from existing DSML projects must be collected, systematized, and documented using an agreed upon documentation format.Method: We applied a sequential multi-method approach to identify and to document reusable design decisions for UML-based DSMLs. The approach included a Web-based survey with 80 participants. Moreover, 80 DSML projects1, which have been identified through a prior systematic literature review, were analyzed in detail in order to identify reusable design decisions for such DSMLs.Results: We present insights on the current state of practice in documenting UML-based DSMLs (e.g., perceived barriers, documentation techniques, reuse potential) and a publicly available collection of reusable design decisions, including 35 decision options on different DSML development concerns (especially concerning the language model, concrete-syntax language design, and modeling tools). The reusable design decisions are documented using a structured documentation format (decision record).Conclusion: Our results are both, scientifically relevant (e.g. for design-space analyses or for creating classification schemas for further research on UML-based DSML development) and important for actual software engineering projects (e.g. by providing best-practice guidelines and pointers to common pitfalls)."
Research article - Modeling and measuring attributes influencing DevOps implementation in an enterprise using structural equation modeling,"AbstractContextDevOps refer to set of principles that advocate a tight integration between development and operation to achieve higher quality with faster turnaround. It is paramount to assess and measure the DevOps attributes in an enterprise. The literature provides references to these attributes but the detail assessment of these attributes and determination of the maturity of DevOps implementation is still a challenge.ObjectiveThis paper provides important insights for practitioners to assess and measure the DevOps attributes using statistical analysis and Two-way assessment. The proposed framework facilitates the detailed assessment of eighteen attributes to identify key independent attributes and measure them to determine the maturity of DevOps implementation in an enterprise.MethodThe relationship between eighteen attributes was examined; a structural model was established using Exploratory and Confirmatory Factor Analysis, the model was validated using Structural Equation Modelling. Key independent attributes were identified which influences other attributes and overall DevOps implementation. Using Two-way assessment, key independent attributes were measured and the maturity of the DevOps implementation was determined in an enterprise.ResultsUsing Exploratory and Confirmatory Factor Analysis, 18 attributes were categorized under 4 latent variables namely Automation, Source Control, Cohesive Teams and Continuous Delivery. Using Structural Equation Modelling, 10 key independent attributes were determined, that influenced other attributes and overall DevOps implementation. Two-way assessment was applied to measure the key independent attributes and it was found that 4 of these attributes were performing below threshold level. Corrective actions were taken by the management team, and the revised measurement of these attributes demonstrated 40% improvement in the maturity level of DevOps implementation.ConclusionThe proposed framework contributes significantly to the field of DevOps by enabling practitioners to conduct the detailed assessment and measurement of DevOps attributes to determine the maturity of DevOps implementation to achieve higher quality."
Research article - Experimental comparison of approaches for checking completeness of test suites from finite state machines,"AbstractContextMany approaches have been proposed for checking test suite completeness for Finite State Machines (FSMs). Some approaches provide sufficient conditions whereas others give necessary and sufficient conditions for test suite completeness. One method, called the CONF method, is based on sufficient conditions, and relies on a search for confirmed sets when checking completeness. If a confirmed set cannot be found, then the outcome is inconclusive. Another method, the SIM method, is based on the notion of simulation relations, and relies on necessary and sufficient conditions when checking test suite completeness. The SIM method always returns conclusive verdicts about suite completeness.ObjectiveIn this work, we describe experimental results comparing these two methods. We also investigate when both methods can be combined for checking completeness of test suites.MethodWe evaluate both strategies according to different parameters of the FSMs, such as the number of states and the number of transitions in the FSM models, the size of input and output alphabets of the FSM models, as well as the size of the test suites. We also report on the relative rates of conclusive and inconclusive verdicts when using both methods.ResultsWe see that these methods are complementary, which allows for a combined strategy: the CONF method is the fastest in terms of processing time, while the SIM method is not as scalable in terms of the size of the specifications.ConclusionThe experimental results indicated a substantial difference for the rate of positive verdicts obtained by the SIM method when compared with the number of positive answers returned by the CONF method."
Research article - Predicting move method refactoring opportunities in object-oriented code,"AbstractContextRefactoring is the maintenance process of restructuring software source code to improve its quality without changing its external behavior. Move Method Refactoring (MMR) refers to moving a method from one class to the class in which the method is used the most often. Manually inspecting and analyzing the source code of the system under consideration to determine the methods in need of MMR is a costly and time-consuming process. Existing techniques for identifying MMR opportunities have several limitations, such as scalability problems and being inapplicable in early development stages. Most of these techniques do not consider semantic relationships.ObjectiveWe introduce a measure and a corresponding model to precisely predict whether a class includes methods in need of MMR. The measure is applicable once a class has entered the early development stages without waiting for other classes to be developed.MethodThe proposed measure considers both the cohesion and coupling aspects of methods. In addition, the measure uses structural and semantic data available within the class of interest. A statistical technique is applied to construct prediction models for classes that include methods in need of MMR. The models are applied on seven object-oriented systems to empirically evaluate their abilities to predict MMR opportunities.ResultsThe results show both that the prediction models based on the proposed measure had outstanding prediction abilities and that the measure was able to correctly detect more than 90% of the methods in need of MMR within the predicted classes.ConclusionsThe proposed measure and corresponding prediction models are expected to greatly assist software engineers both in locating classes that include methods in need of MMR and in identifying these methods within the predicted classes."
Research article - Formal verification of ECML hybrid models with spaceex,"AbstractContextECML is a modeling language for hybrid systems, proposed by ETRI in Korea. ECML extended the basic formalism, DEV&DESS, with uses in modeling and simulation, whereas algorithmic verification on the ECML models continues to be an on-going research task.ObjectiveThis paper proposes a verification technique to verify ECML models with SpaceEx, a verification platform for hybrid systems. It includes translation rules from ECML into the SpaceEx model.MethodAs SpaceEx reads linear hybrid automata, we developed translation rules from ECML models to linear hybrid automata and implemented an automatic translator ECMLtoSpaceEx. We also developed a rule checker ECML Checker to check whether an ECML model complies with assumptions and restrictions to overcome the semantic gap between the two formal languages. We performed a case study with an extension of the widely used example ‘barrel-filler system’ to demonstrate the effectiveness of our verification technique.ResultsThe verification result shows that our verification technique can translate ECML models into SpaceEx models, and we also perform formal verification on ECML models with SpaceEx.ConclusionsThe proposed technique can verify ECML with support fromSpaceEx. We expect that the proposed translation rules can be used with minor modifications to translate ECML models into different notations, and thus allow for the use of verification tools other than SpaceEx."
Research article - Software effort estimation based on open source projects: Case study of Github,"AbstractContextManagers usually want to pre-estimate the effort of a new project for reasonably dividing their limited resources. In reality, it is common practice to train a prediction model based on effort datasets to predict the effort required by a project. Sufficient data is the basis for training a good estimator, yet most of the data owners are unwilling to share their closed source project (CSP) effort data due to the privacy concerns, which means that we can only obtain a small number of effort data. Effort estimator built on the limited data usually cannot satisfy the practical requirement.ObjectiveWe aim to provide a method which can be used to collect sufficient data for solving the problem of lack of training data when building an effort estimation model.MethodWe propose to mine GitHub to collect sufficient and diverse real-life effort data for effort estimation. Specifically, we first demonstrate the feasibility of our cost metrics (including functional point analysis and personnel factors). In particular, we design a quantitative method for evaluating the personnel metrics based on GitHub data. Then we design a samples incremental approach based on AdaBoost and Classification And Regression Tree (ABCART) to make the collected dataset owns dynamic expansion capability.ResultsExperimental results on the collected dataset show that: (1) the personnel factor is helpful for improving the performance of the effort estimation. (2) the proposed ABCART algorithm can increase the samples of the collected dataset online. (3) the estimators built on the collected data can achieve comparable performance with those of the estimators which built on existing effort datasets.ConclusionsEffort estimation based on Open Source Project (OSP) is an effective way for getting the effort required by a new project, especially for the case of lacking training data."
Research article - A formal approach to derive an aspect oriented programming-based implementation of a secure access control filter,"AbstractContext: Nowadays, Information Systems (IS) are at the heart of most companies and constitute then a critical element that needs an adequate attention regarding security issues of sensitive data it manages.Objective: This paper presents a formal approach for the development of a filter to secure access to sensitive resources of information systems.Method: The proposed approach consists of three complementary steps. Designers start by modeling the functionalities of the system and its security requirements using dedicated UML diagrams. These diagrams are then automatically translated into a formal B specification suitable not only for reasoning about data integrity checking but also for the derivation of a trustworthy implementation. Indeed, a formal refinement process is applied on the generated B specification to obtain a relational-like B implementation which is then translated into an AspectJ implementation, connected to a SQL Server (release 2014) relational database system. Such a generation is performed following the aspect oriented programming paradigm which permits a separation of concerns by making a clear distinction between functional and security aspects.Results: A systematic formal approach to derive a secure filter that regulates access to the sensitive data of an information system. The filter considers both static and dynamic access rules. A tool that supports the proposed approach is also provided.Conclusion: The approach has been applied on several case studies that demonstrate that the development of a tool permits to free the developers from tedious and error-prone tasks since they have just to push a button to generate the AspectJ code of an application."
Research article - LoCo CoCo: Automatically constructing coordination and communication networks from model-based systems engineering data,"AbstractContext: Communication and coordination are essential ingredients to successful requirements and software engineering. However, especially in large organisations, it is difficult to establish and maintain communication channels.Objective: In order to facilitate communication, we investigate automatic construction of social network models from existing requirements and systems engineering models.Method: We conducted a design science research study in three iterative cycles at a large automotive company, and evaluated the outcome based on 15 interviews with practitioners and a survey with 12 participants.Results: The resulting approach, denoted LoCo CoCo, automatically creates and visualises social networks based on selected systems engineering components of real-life, productive systems engineering models. Our results indicate that automatic construction and visualisation of social network models could be feasible and useful to overcome existing communication challenges.Conclusion: Despite a lack of quality in existing social data at the case company, practitioners found LoCo CoCo potentially helpful to overcome existing communication challenges. Additionally, the visualisation could trigger practitioners to keep their social data up to date."
Review article - Contextual attributes impacting the effectiveness of requirements elicitation Techniques: Mapping theoretical and empirical research,"AbstractBackground: Software engineers can utilise a myriad of elicitation techniques to capture relevant information in order to specify requirements. The effectiveness of these techniques varies depending on the context in which the elicitation takes place. So, it is important to identify the attributes that represent this context. Objective: This paper aims to match theoretical to empirical research on contextual attributes that influence elicitation technique effectiveness. Method: We conduct a systematic mapping study to identify proposed attributes (by theoretical works) and attributes studied empirically. Then we map empirical results with theoretical proposals. Results: 60% of theoretically proposed attributes have been studied empirically. There seems to be some degree of coordination between theory and empiricism. However, there is empirical confirmation of the impact of only a third of the theoretically proposed attributes. Conclusions: These results call for more empirical research in order to evaluate beliefs with respect to elicitation techniques."
Research article - How developers perceive smells in source code: A replicated study,"AbstractContext. In recent years, smells, also referred to as bad smells, have gained popularity among developers. However, it is still not clear how harmful they are perceived from the developers’ point of view. Many developers talk about them, but only few know what they really are, and even fewer really take care of them in their source code.Objective. The goal of this work is to understand the perceived criticality of code smells both in theory, when reading their description, and in practice.Method. We executed an empirical study as a differentiated external replication of two previous studies. The studies were conducted as surveys involving only highly experienced developers (63 in the first study and 41 in the second one). First the perceived criticality was analyzed by proposing the description of the smells, then different pieces of code infected by the smells were proposed, and finally their ability to identify the smells in the analyzed code was tested.Results. According to our knowledge, this is the largest study so far investigating the perception of code smells with professional software developers. The results show that developers are very concerned about code smells in theory, nearly always considering them as harmful or very harmful (17 out of 23 smells). However, when they were asked to analyze an infected piece of code, only few infected classes were considered harmful and even fewer were considered harmful because of the smell.Conclusions. The results confirm our initial hypotheses that code smells are perceived as more critical in theory but not as critical in practice."
"Research article - A graphical user interface for presenting integrated development environment command recommendations: Design, evaluation, and implementation","AbstractContextA set of algorithms exist to generate integrated development environment (IDE) command recommendations. The recommendations are aimed at improving software developer’s interaction with an IDE. Even though the interface is a critical element of every recommender system, we are not aware of any existing graphical user interface to present such recommendations.ObjectiveThis paper describes and evaluates a novel design of a graphical user interface to recommend commands within an IDE. The interface contains a description of the suggested command, an explanation of why the command is recommended, and a command usage example.MethodThe proposed design is based on the analysis of guidelines identified in the literature. Its acceptance and usability were evaluated through a user study with 36 software developers and semi-structured interviews with 11 software developers.ResultsThe results indicate that the suggested interface is well accepted, but it can be further improved. Through the interviews and the implementation of the interface, we identified a series of requirements important for the development of future IDE command recommender systems.ConclusionsThis paper shows that a convenient graphical user interface is critical to achieve high acceptance of IDE command recommendations. Our work also illustrates steps useful for undertaking user studies related to IDE command recommendations in a practical setting without human intervention. A future step is to evaluate the interface within the business environment, where recommendations are generated and presented in an IDE used by practicing software developers as part of their normal workday."
