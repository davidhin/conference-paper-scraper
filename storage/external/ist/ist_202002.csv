title,abstract
Research article - Architecting systems of systems: A tertiary study,"AbstractContext: The term System of Systems (SoS) has increasingly been used in a wide variety of domains to describe those systems composed of independent constituent systems that collaborate towards a mission that they could not accomplish on their own. There is a significant volume of research by the software architecture community that aims to overcome the challenges involved in architecting SoS, as evidenced by the number of secondary studies in the field published so far. However, the boundaries of such research do not seem to be well defined, at least partially, due to the emergence of SoS-adjacent areas of interest like the Internet of Things.Objective: This paper aims to investigate the current state of research on SoS architecting by synthesizing the demographic data, assessing the quality and the coverage of architecting activities and software quality attributes by the research, and distilling a concept map that reflects a community-wide understanding of the concept of SoS. Method: We conduct what is, to the best of our understanding, the first tertiary study on SoS architecting. Such tertiary study was based on five research questions, and was performed by following the guidelines of Kitchenham et al. In all, 19 secondary studies were evaluated, which is comparable to other tertiary studies. Results: The study illustrates a state of disconnection in the research community, with research gaps in the coverage of particular phases and quality attributes. Furthermore, a more effective approach in classifying systems as SoS is required, as the means of resolving conceptual and terminological overlaps with the related domains. Conclusions: Despite the amount of research in the area of SoS architecting, more coordinated and systematic targeted efforts are required in order to address the identified issues with the current state of research."
Research article - Assisting engineers extracting requirements on components from domain documents,"AbstractContext: When entering an unfamiliar domain, organizations usually have to invest significant time and effort performing domain analysis with the purpose of acquiring system requirements. This process usually involves collecting domain documents extensively, retrieving and reviewing the related ones carefully, searching for the requirements knowledge, then extracting and specifying system requirements. Furthermore, the task must often be performed repeatedly throughout the early phases of projects. Depending on the nature of the domain and the availability of documentation, this process is extremely time-consuming and may require non-trivial human effort.Objective: In order to assist engineers identifying requirements knowledge from a collect of domain documents, previously we proposed an approach MaRK in the Conference RE’16 which ranks the domain documents by their relevance to components and highlights the content that are likely to contain component-related information. Experiments showed MaRK can almost identify the top and bottom documents in the reference list. However, it tends to underestimate the relevance of the domain documents that have a number of sections with medium knowledge density.Method: We improve the ranking algorithm in MaRK and propose MaRK-II. In addition, to assist engineers locating the relevant information in lengthy documents, we preserve the highlighting work in MaRK and strengthen MaRK-II by extracting the summary of component-related text. MaRK-II is evaluated with the documents in three domains.Results: We found that MaRK-II significantly outperforms MaRK and VSM on ranking the documents by their relevance. And a user study showed that MaRK-II is indeed helpful for engineers to extract requirements on components.Conclusions: Our approach provides three mechanisms including documents ranking, pertinent content highlighting and summarizing to help engineers obtaining requirements from a collection of domain documents."
Research article - Toward recursion aware complexity metrics,"AbstractContext: Software developers spend a significant amount of time on reading, comprehending, and debugging of source code. Numerous software metrics can give us awareness of incomprehensible functions or of flaws in their collaboration. Invocation chains, especially recursive ones, affect solution complexity, readability, and understandability. Even though decomposed and recursive solutions are characterized as short and clear in comparison with iterative ones, they hide the complexity of the observed problem and solution. As the collaboration between functions can strongly depend on context, difficulties are usually detected in debugging, testing or by static analysis, while metrics support is still very weak.Objective: We introduce a new complexity metric, called Overall Path Complexity (OPC), which is aware of (recursive) call chains in the observed source code. As invocations are basic collaboration mechanism and recursions are broadly accepted, the OPC metric is intended to be applicable independently on programming language and paradigm.Method: We propose four different versions of the OPC calculation algorithm and explore and discuss their suitability. We have validated proposed metrics based on a Framework specially designed for evaluation and validation of software complexity metrics and accordingly performed theoretical, empirical and practical validation. Practical validation was performed on toy examples and industrial cases (47012 LOCs, 2899 functions, and 758 recursive paths) written in Erlang.Result: Based on our analysis we selected the most suitable (of 4 proposed) OPC calculation formula, and showed that the new metric expresses advanced properties of the software in comparison with other available metrics that was confirmed by low correlation.Conclusion: We introduced the OPC metric calculated on the Overall Control Flow Graph as an extension of Cyclomatic Complexity by adding awareness of (recursive) invocations. The values of the new metric can lead us to find the problematic fragments of the code or of the execution paths."
Research article - A generic methodology for early identification of non-maintainable source code components through analysis of software releases,"AbstractContextContemporary development approaches consider that time-to-market is of utmost importance and assume that software projects are constantly evolving, driven by the continuously changing requirements of end-users. This practically requires an iterative process where software is changing by introducing new or updating existing software/user features, while at the same time continuing to support the stable ones. In order to ensure efficient software evolution, the need to produce maintainable software is evident.ObjectiveIn this work, we argue that non-maintainable software is not the outcome of a single change, but the consequence of a series of changes throughout the development lifecycle. To that end, we define a maintainability evaluation methodology across releases and employ various information residing in software repositories, so as to decide on the maintainability of software.MethodUpon using the dropping of packages as a non-maintainability indicator (accompanied by a series of quality-related criteria), the proposed methodology involves using one-class-classification techniques for evaluating maintainability at a package level, on four different axes each targeting a primary source code property: complexity, cohesion, coupling, and inheritance.ResultsGiven the qualitative and quantitative evaluation of our methodology, we argue that apart from providing accurate and interpretable maintainability evaluation at package level, we can also identify non-maintainable components at an early stage. This early stage is in many cases around 50% of the software package lifecycle.ConclusionBased on our findings, we conclude that modeling the trending behavior of certain static analysis metrics enables the effective identification of non-maintainable software components and thus can be a valuable tool for the software engineers."
Research article - Practical detection of CMS plugin conflicts in large plugin sets,"AbstractContextContent Management Systems (CMS), such as WordPress, are a very popular category of software for creating web sites and blogs. These systems typically build on top of plugin architectures. Unfortunately, it is not uncommon that the combined activation of multiple plugins in a CMS web site will produce unexpected behavior. Conflict-detection techniques exist but they do not scale.ObjectiveThis paper proposes Pena, a technique to detect conflicts in large sets of plugins as those present in plugin market places.MethodPena takes on input a configuration, consisting of a potentially large set of plugins, and reports on output the offending plugin combinations. Pena uses an iterative divide-and-conquer search to explore the large space of plugin combinations and a staged filtering process to eliminate false alarms.ResultsWe evaluated Pena with plugins selected from the WordPress official repository and compared its efficiency and accuracy against the technique that checks conflicts in all pairs of plugins. Results show that Pena is 12.4x to 19.6x more efficient than the comparison baseline and can find as many conflicts as it."
Research article - Energy efficient adaptation engines for android applications,"AbstractContext The energy consumption of mobile devices is increasing due to the improvement in their components (e.g., better processors, larger screens). Although the hardware consumes the energy, the software is responsible for managing hardware resources such as the camera software and its functionality, and therefore, affects the energy consumption. Energy consumption not only depends on the installed code, but also on the execution context (environment, devices status) and how the user interacts with the application.Objective In order to reduce the energy consumption based on user behavior, it is necessary to dynamically adapt the application. However, the adaptation mechanism also consumes a certain amount of energy in itself, which may lead to an important increase in the energy expenditure of the application in comparison with the benefits of the adaptation. Therefore, this footprint must be measured and compared with the benefit obtained.Method In this paper, we (1) determine the benefits, in terms of energy consumption, of dynamically adapting mobile applications, based on user behavior; and (2) advocate the most energy-efficient adaptation mechanism. We provide four different implementations of a proposed adaptation model and measure their energy consumption.Results The proposed adaptation engines do not increase the energy consumption when compared to the benefits of the adaptation, which can reduce the energy consumption by up to 20%.Conclusion The adaptation engines proposed in this paper can decrease the energy consumption of the mobile devices based on user behavior. The overhead introduced by the adaptation engines is negligible in comparison with the benefits obtained by the adaptation."
Research article - A focus area maturity model for software ecosystem governance,"AbstractContextIncreasingly, software companies are realizing that they can no longer compete through product excellence alone. The ecosystems that surround platforms, such as operating systems, enterprise applications, and even social networks are undeniably responsible for a large part of a platform’s success. With this realization, software producing organizations need to devise tools and strategies to improve their ecosystems and reinvent tools that others have invented many times before.ObjectiveIn this article, the software ecosystem governance maturity model (SEG-M2) is presented, which has been designed along the principles of a focus area maturity model. The SEG-M2 has been designed for software producing organizations to assess their ecosystem governance practices, set a goal for improvement, and execute an improvement plan.MethodThe model has been created following an established focus area maturity model design method. The model has been evaluated in six evaluating case studies with practitioners, first by applying the model to their organizations and secondly by evaluating with the practitioners whether the evaluation and improvement advice from the model is valid, useful, and effective.ResultThe model is extensively described and illustrated using six desk studies and six case studies.ConclusionsThe model is evaluated by both researchers and practitioners as a useful collection of practices that enable decision making about software ecosystem governance. We find that maturity models are an effective tool in disseminating a large collection of knowledge, but that research and creation tooling for maturity models is limited."
Research article - Energy aware simulation and testing of smart-spaces,"AbstractContextA smart-space SS typically consists of many rooms, with temperature and humidity environment attributes, devices, and software components that communicate with each other to satisfy certain test purposes that need to be checked over various realistic exterior environment weather conditions.ObjectiveWe present a novel energy-aware approach for the validation of smart-spaces while minimizing the energy consumption encountered during testing.MethodA framework for deriving minimal (energy) cost tests is provided. It includes SS, a controlled environment Env that depicts the exterior conditions, and a Tester that can control SS and Env, derive and runs tests, and observe relevant SS attributes in order to release a success verdict whenever a test purpose is met. A simulator is proposed for deriving tests by appropriately exploring part of the SS behavior employing several cost functions for computing the estimated cost and duration of test events.ResultsThe framework is deployed in a real SS environment which is used to assess the actual energy consumption of derived tests in practice. Experiments show that the actual power consumption of the derived tests is close to the ones estimated by the simulator. A case study that assesses the gains in using energy aware tests in comparison to non energy-aware alternatives is also provided.ConclusionsThe obtained results highlight the importance of considering power consumption in the development and testing of smart-spaces."
