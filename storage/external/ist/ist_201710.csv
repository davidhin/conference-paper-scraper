title,abstract
Research article - A systematic literature review on methods that handle multiple quality attributes in architecture-based self-adaptive systems,"AbstractContextHandling multiple quality attributes (QAs) in the domain of self-adaptive systems is an understudied research area. One well-known approach to engineer adaptive software systems and fulfill QAs of the system is architecture-based self-adaptation. In order to develop models that capture the required knowledge of the QAs of interest, and to investigate how these models can be employed at runtime to handle multiple quality attributes, we need to first examine current architecture-based self-adaptive methods.ObjectiveIn this paper we review the state-of-the-art of architecture-based methods for handling multiple QAs in self-adaptive systems. We also provide a descriptive analysis of the collected data from the literature.MethodWe conducted a systematic literature review by performing an automatic search on 28 selected venues and books in the domain of self-adaptive systems. As a result, we selected 54 primary studies which we used for data extraction and analysis.ResultsPerformance and cost are the most frequently addressed set of QAs. Current self-adaptive systems dealing with multiple QAs mostly belong to the domain of robotics and web-based systems paradigm. The most widely used mechanisms/models to measure and quantify QAs sets are QA data variables. After QA data variables, utility functions and Markov chain models are the most common models which are also used for decision making process and selection of the best solution in presence of many alternatives. The most widely used tools to deal with multiple QAs are PRISM and IBM's autonomic computing toolkit. KLAPER is the only language that has been specifically developed to deal with quality properties analysis.ConclusionsOur results help researchers to understand the current state of research regarding architecture-based methods for handling multiple QAs in self-adaptive systems, and to identity areas for improvement in the future. To summarize, further research is required to improve existing methods performing tradeoff analysis and preemption, and in particular, new methods may be proposed to make use of models to handle multiple QAs and to enhance and facilitate the tradeoffs analysis and decision making mechanism at runtime."
Research article - Characterizing malicious Android apps by mining topic-specific data flow signatures,"AbstractContext: State-of-the-art works on automated detection of Android malware have leveraged app descriptions to spot anomalies w.r.t the functionality implemented, or have used data flow information as a feature to discriminate malicious from benign apps. Although these works have yielded promising performance, we hypothesize that these performances can be improved by a better understanding of malicious behavior.Objective: To characterize malicious apps, we take into account both information on app descriptions, which are indicative of apps’ topics, and information on sensitive data flow, which can be relevant to discriminate malware from benign apps.Method: In this paper, we propose a topic-specific approach to malware comprehension based on app descriptions and data-flow information. First, we use an advanced topic model, adaptive LDA with GA, to cluster apps according to their descriptions. Then, we use information gain ratio of sensitive data flow information to build so-called “topic-specific data flow signatures”.Results: We conduct an empirical study on 3691 benign and 1612 malicious apps. We group them into 118 topics and generate topic-specific data flow signature. We verify the effectiveness of the topic-specific data flow signatures by comparing them with the overall data flow signature. In addition, we perform a deeper analysis on 25 representative topic-specific signatures and yield several implications.Conclusion: Topic-specific data flow signatures are efficient in highlighting the malicious behavior, and thus can help in characterizing malware."
Research article - Domain-aware Mashup service clustering based on LDA topic model from multiple data sources,"AbstractContextMashup is emerging as a promising software development method for allowing software developers to compose existing Web APIs to create new or value-added composite Web services. However, the rapid growth in the number of available Mashup services makes it difficult for software developers to select a suitable Mashup service to satisfy their requirements. Even though clustering based Mashup discovery technique shows a promise of improving the quality of Mashup service discovery, Mashup service clustering with high accuracy and good efficiency is still a challenge problem.ObjectiveThis paper proposes a novel domain-aware Mashup service clustering method with high accuracy and good efficiency by exploiting LDA topic model built from multiple data sources, to improve the quality of Mashup service discovery.MethodThe proposed method firstly designs a domain-aware Mashup service feature selection and reduction process by refining characterization of their domains to consolidate domain relevance. Then, it presents an extended LDA topic model built from multiple data sources (include Mashup description text, Web APIs and tags) to infer topic probability distribution of Mashup services, which serves as a basis of Mashup service similarity computation. Finally, K-means and Agnes algorithm are used to perform Mashup service clustering in terms of their similarities.ResultsCompared with other existing Mashup service clustering methods, experimental results show that the proposed method achieves a significant improvement in terms of precision, recall, F-measure, purity and entropy.ConclusionThe results of the proposed method help software developers to improve the quality of Mashup service discovery and Mashup-based software development. In the future, there will be a need to extend the method by considering heterogeneous network information among Mashup, Web APIs, tags, users, and applying it to Mashup discovery for software developers."
Review article - Incorporating user preferences in search-based software engineering: A systematic mapping study,"AbstractContextSearch-based algorithms have been successfully applied to solve software engineering problems in the field known as Search-based Software Engineering (SBSE). However, in practice, the user may reject the obtained solutions, since many characteristics of the problem cannot be mathematically modeled. To cope with this situation, preference-based algorithms have been investigated and raised interest in the SBSE field.ObjectiveTo identify the quantity and type of research on SBSE preference-based approaches and to contribute to this new research subject, named here Preference and Search-Based Software Engineering (PSBSE),MethodWe conducted a systematic mapping, following a research plan to locate, assess, extract and group the outcomes from relevant studies.ResultsFew software engineering activities have been addressed. The most used algorithms are evolutionary and single-objective. In most studies the preferences are provided interactively and, in many cases, the user preferences are incorporated in the fitness functions. We observe a lack of evaluation measures and works comparing existing approaches.ConclusionsThe use of preference-based algorithms in SBSE is an underexplored subject, and many research opportunities exist."
Short communication - The relation between technical debt and corrective maintenance in PHP web applications,"AbstractContextTechnical Debt Management (TDM) refers to activities that are performed to prevent the accumulation of Technical Debt (TD) in software. The state-of-research on TDM lacks empirical evidence on the relationship between the amount of TD in a software module and the interest that it accumulates. Considering the fact that in the last years, a large portion of software applications are deployed in the web, we focus this study on PHP applications.ObjectiveAlthough the relation between debt amount and interest is well-defined in traditional economics (i.e., interest is proportional to the amount of debt), this relation has not yet been explored in the context of TD. To this end, the aim of this study is to investigate the relation between the amount of TD and the interest that has to be paid during corrective maintenance.MethodTo explore this relation, we performed a case study on 10 open source PHP projects. The obtained data have been analyzed to assess the relation between the amount of TD and two aspects of interest: (a) corrective maintenance (i.e., bug fixing) frequency, which translates to interest probability and (b) corrective maintenance effort which is related to interest amount.ResultsBoth interest probability and interest amount are positively related with the amount of TD accumulated in a specific module. Moreover, the amount of TD is able to discriminate modules that are in need of heavy corrective maintenance.ConclusionsThe results of the study confirm the cornerstone of TD research, which suggests that modules with a higher level of incurred TD, are costlier in maintenance activities. In particular, such modules prove to be more defect-prone and consequently require more (corrective) maintenance effort."
Research article - A software reference architecture for semantic-aware Big Data systems,"AbstractContext: Big Data systems are a class of software systems that ingest, store, process and serve massive amounts of heterogeneous data, from multiple sources. Despite their undisputed impact in current society, their engineering is still in its infancy and companies find it difficult to adopt them due to their inherent complexity. Existing attempts to provide architectural guidelines for their engineering fail to take into account important Big Data characteristics, such as the management, evolution and quality of the data.Objective: In this paper, we follow software engineering principles to refine the λ-architecture, a reference model for Big Data systems, and use it as seed to create Bolster, a software reference architecture (SRA) for semantic-aware Big Data systems.Method: By including a new layer into the λ-architecture, the Semantic Layer, Bolster is capable of handling the most representative Big Data characteristics (i.e., Volume, Velocity, Variety, Variability and Veracity).Results: We present the successful implementation of Bolster in three industrial projects, involving five organizations. The validation results show high level of agreement among practitioners from all organizations with respect to standard quality factors.Conclusion: As an SRA, Bolster allows organizations to design concrete architectures tailored to their specific needs. A distinguishing feature is that it provides semantic-awareness in Big Data Systems. These are Big Data system implementations that have components to simplify data definition and exploitation. In particular, they leverage metadata (i.e., data describing data) to enable (partial) automation of data exploitation and to aid the user in their decision making processes. This simplification supports the differentiation of responsibilities into cohesive roles enhancing data governance."
