title,abstract
Review article - Quality Assessment in Systematic Literature Reviews: A Software Engineering Perspective,"AbstractContext: Quality Assessment (QA) of reviewed literature is paramount to a Systematic Literature Review (SLR) as the quality of conclusions completely depends on the quality of selected literature. A number of researchers in Software Engineering (SE) have developed a variety of QA instruments and also reported their challenges. We previously conducted a tertiary study on SLRs with QA from 2004 to 2013, and reported the findings in 2015.Objective: With the widespread use of SLRs in SE and the increasing adoption of QA in these SLRs in recent years, it is necessary to empirically investigate whether the previous conclusions are still valid and whether there are new insights to the subject in question using a larger and a more up-to-date SLR set. More importantly, we aim to depict a clear picture of QA used in SLRs in SE by aggregating and distilling good practices, including the commonly used QA instruments as well as the major roles and aspects of QA in research.Method: An extended tertiary study was conducted with the newly collected SLRs from 2014 to 2018 and the original SLRs from 2004 to 2013 to systematically review the QA used by SLRs in SE during the 15-year period from 2004 to 2018. In addition, this extended study also compared and contrasted the findings of the previous study conducted in 2015.Results: A total of 241 SLRs between 2004 and 2018 were included, from which we identified a number of QA instruments. These instruments are generally designed to focus on the rationality of study design, the rigor of study execution and analysis, and the credibility and contribution of study findings and conclusions, with the emphasis largely placed on its rigor. The quality data is mainly used for literature selection or as evidence to support conclusions.Conclusions: QA has received much attention in SE in more recent years and the improvement is evident since the last study in 2015. New findings show that the aims are more concise, the instruments are more diverse and rigorous, and the criteria are more thoughtful."
Research article - An empirical study of performance using Clone & Own and Software Product Lines in an industrial context,"AbstractContext:Clone and Own (CaO) is a widespread approach to generate new software products from existing software products by adding small changes. The Software Product Line (SPL) approach addresses the development of families of products with similar features, moving away from the production of isolated products. Despite the popularity of both approaches, no experiment has yet compared them directly.Objective:The goal of this paper is to know the different performances of software engineers in the software products development process using two different approaches (SPL and CaO).Method:We conducted an experiment in the induction hobs software environment with software engineers. This experiment is a single factor experiment where the factor is the approach that is used to develop software products, with two treatments: (SPL or CaO). We compared the results obtained by the software engineers when they develop software products related to effectiveness, efficiency, and satisfaction.Results:The findings show that: (1) the SPL approach is more efficient even though the number of checking actions required by this approach is greater than the number required by the CaO approach; (2) the SPL approach offers more possibilities than software engineers need to perform their daily tasks; and (3) software engineers require better search capabilities in the CaO approach. The possible explanations for these results are presented in the paper.Conclusions:The results show that there are significant differences in effectiveness, efficiency, and satisfaction, with the SPL approach yielding the best results."
Research article - Boundary sampling to boost mutation testing for deep learning models,"AbstractContext: The prevalent application of Deep Learning (DL) models has raised concerns about their reliability. Due to the data-driven programming paradigm, the quality of test datasets is extremely important to gain accurate assessment of DL models. Recently, researchers have introduced mutation testing into DL testing, which applies mutation operators to generate mutants from DL models, and observes whether the test data can identify mutants to check the quality of test dataset. However, there still exist many factors (e.g., huge labeling efforts and high running cost) hindering the implementation of mutation testing for DL models.Objective: We desire for an approach to selecting a smaller, sensitive, representative and efficient subset of the whole test dataset to promote the current mutation testing (e.g., reduce labeling and running cost) for DL Models.Method: We propose boundary sample selection (BSS), which employs the distance of samples to decision boundary of DL models as the indicator to construct the appropriate subset. To evaluate the performance of BSS, we conduct an extensive empirical study with two widely-used datasets, three popular DL models, and 14 up-to-date DL mutation operators. Results: We observe that (1) The sizes of our subsets generated by BSS are much smaller (about 3%-20% of the whole test set). (2) Under most mutation operators, our subsets are superior (about 9.94-21.63) than the whole test sets in observing mutation effects. (3) Our subsets could replace the whole test sets to a very high degree (higher than 97%) when considering mutation score. (4) The MRR values of our proposed subsets are clearly better (about 2.28-13.19 times higher) than that of the whole test sets.Conclusions: The result shows that BSS can help testers save labelling cost, run mutation testing quickly and identify killed mutants early."
Research article - Laprob: A Label propagation-Based software bug localization method,"AbstractContextBug localization, which locates suspicious snippets related to the bugs mentioned in the bug reports, is time-consuming and laborious. Many automatic bug localization methods have been proposed to speed up the process of bug fixing and reduce the burden on developers. However, these methods have not fully utilized the intra-relations and inter-relations among the bug reports and the source files (i.e., call relationships between the source files).ObjectiveIn this paper, we propose a novel method LaProb (a label propagation-based software bug localization method) that makes full use of the intra-relations and inter-relations among the bug reports and the source files.MethodLaProb transforms the problem of bug localization into a multi-label distribution learning problem. LaProb first constructs a BHG (Biparty Hybrid Graph) by analyzing the structures and contents of bug reports and source files, and calculates the intra-relations between pairs of bug reports and source files, as well as the inter-relations between bug reports and source files. Based on BHG, LaProb then predicts the label distribution on source files by using the label propagation algorithm for the target bug report. Finally, LaProb finishes the bug localization task by sorting the results of label propagation.ResultsThe experimental results on nine open-source software projects (i.e., SWT, AspectJ, Eclipse, ZXing, SEC, HIVE, HBASE, WFLY and ROO) show that compared with several state-of-the-art methods (including BugLocator, BRTracer, BLUiR, AmaLgam, Locus and BLIZZARD), LaProb performs the best in terms of all five metrics on average. For MAP performance measure, LaProb achieves an improvement of 30.9%, 36.6%, 28.0%, 22.2%, 20.1% and 53.5%, respectively.ConclusionLaProb is capable of making full use of the intra-relations and inter-relations among the bug reports and the source files and achieves better performance than seven state-of-the-art methods."
Research article - Community detection in software ecosystem by comprehensively evaluating developer cooperation intensity,"AbstractContext: As soon as the concept of software ecosystem was proposed, it has aroused great interest in both academia and industry. Software ecosystem can be described as a special complex network. Community structures are critical towards understanding not only the network topology but also how the network functions. Traditional community detection algorithms in complex networks mainly utilize the network topology to measure the similarities between nodes. Because of the complexity of information interaction in software ecosystem, only considering the topology structure will lead to unreasonable division of communities.Objective: For solving community detection in software ecosystem more reasonably, we present a method of community detection by comprehensively evaluating developer cooperation intensity in software ecosystems.Method: First, we combine network topology information and developer interaction information to calculate the developer cooperation intensity, so as to deeply explore the relationship between developers from both topological and semantic properties. Then a community detection algorithm ABDCI is proposed based on the cooperation intensity of developers by referring to the hierarchical clustering idea of Louvain algorithm. Finally, this method is applied to many different types of developer networks in the software ecosystem through GitHub hosting platform.Results: Comparing with three classical community detection algorithms, we find that the proposed method can identify a clearer community structure for the developer collaboration network in the software ecosystem.Conclusion: Our approach provides an effective and extensible technique for solving the community detection problem of real developer collaboration network in software ecosystem. According to our findings, we conclude that community detection algorithms based on comprehensive topological properties and semantic properties are more suitable for real communities in software ecosystems than traditional single-property algorithms."
Research article - Test data generation using genetic programming,"AbstractContext:Typically, search-based test data generation methods search on a population of program input values. Program input values can be regarded as solutions to underlying path constraints over program input parameters. One way to discover these path constraints is to use the symbolic execution method. Search-based methods attempt to find input values which are solutions to these path constraints, without knowing the actual constraints.Objective:In this paper, we show that we can search for the underlying path constraints using search-based methods, without resorting to symbolic execution. Trying to discover the exact or a good enough approximation of the underlying constraints may lead to a more targeted search, compared to directly searching for program input values. Besides, the construction of approximate constraints by searching may help to avoid some problems of symbolic execution.Method:The proposed method uses genetic programming for learning constraints on program input parameters.Results:To evaluate the performance of the proposed approach, a series of experiments have been conducted on a number of different benchmark programs. For 91.8% of benchmark programs, the proposed method achieved the best efficiency among the competitive algorithms.Conclusion:The results show that, if constraint solving can be provided for some or all parameter types of the methods of programs under test, our approach can improve the efficiency and effectiveness of search-based test data generation."
Review article - Social network analysis of open source software: A review and categorisation,"AbstractContext: As companies have become large users of Open Source Software, it is important that they feel comfortable in their Open Source strategies. One of the critical differences between Open Source and Proprietary Software is the communication networks.Objective: This paper tries to set a base for understanding how open source teams are structured and how they change. This is vital to understanding Open Source Software Communities.Method: The paper looks into previous research on Social Network Analysis of Open Source Software, using a systematic literature review. Papers were gathered from Scopus, IEEEXplore and ACM Digital Library, and used or discarded based on predetermined inclusion and exclusion criteria. Research which focuses on the success factors of Open Source Software through Network Analysis is also examined.Results: A subjective categorisation is established for the papers: Structure, Lifecycle and Communication. It was found that the structure of a project has a large bearing on project success, with developers having previously worked together being indicative of project success. Other structure indicators of success are having a small but structured hierarchy, a diverse user and developer base, and project prominence. However, it was found that information on how these structures appear and evolve over time is lacking, and future research into temporal data models to determine project success information is suggested.Conclusions: A categorisation of existing research on Social Network Analysis is provided as a basis for further research. Further work into the lifecycle of OSS projects through Social Network Analysis of temporal project information is suggested."
Research article - Towards a unified criteria model for usability evaluation in the context of open source software based on a fuzzy Delphi method,"AbstractContextA plethora of models are available for open-source software (OSS) usability evaluation. However, these models lack consensus between scholars as well as standard bodies on a specific set of usability evaluation criteria. Retaining irrelevant criteria and omitting essential ones will mislead the direction of the usability evaluation.ObjectiveThis study introduces a three-step method to develop a usability evaluation model in the context of OSS.MethodThe fuzzy Delphi method has been employed to unify the usability evaluation criteria in the context of OSS. The first step in the method is the usability criteria analysis, which involves redefining and restructuring all collected usability criteria reported in the literature. The second step is fuzzy Delphi analysis, which includes the design and validates the fuzzy Delphi instrument and the utilisation of the fuzzy Delphi method to analyse the fuzziness consensus of experts' opinions on the usability evaluation criteria. The third step is the proposal of the OSS usability evaluation model.ResultsA total of 124 usability criteria were identified, redefined, and restructured by creating groups of related meaning criteria. The result of the groupings generated 11 main criteria; the findings of the fuzzy Delphi narrowed down the criteria to only seven. The final set of criteria was sent back to the panellists for reconsideration of their responses. The panellists verified that these criteria are suitable in the evaluation of the usability of OSS.DiscussionThe empirical analysis confirmed that the proposed evaluation model is acceptable in assessing the usability of OSS. Therefore, this model can be used as a reference metric for OSS usability evaluation which will have a practical benefit for the community in public and private organisations in helping the decision-maker to select the best OSS software package amongst the alternatives."
Research article - Two-level clustering of UML class diagrams based on semantics and structure,"AbstractContextThe reuse of software design has been an important issue of software reuse. UML class diagrams are widely applied in software design and has become DE factor standard. As a result, the reuse of UML class diagrams has received more attention. With the increasing number of class diagrams stored in reuse repository, their retrieval becomes a time-consuming job. The clustering can narrow down retrieval range and improve the retrieval efficiency. But few efforts have been done in clustering UML class diagrams. This paper tries to propose a clustering approach for UML class diagrams.ObjectiveThis paper proposes a two-level clustering of UML class diagrams, namely, semantic clustering and structural clustering. The UML class diagrams stored in reuse repository are clustered into a few domains based on semantics in the first level and a few categories based on structure in the second level.MethodWe propose a clustering algorithm named CUFS, in which the idea of partitioning and hierarchical clustering is combined and feature similarity is proposed for the similarity measure between two clusters in order to merge clusters. A better feature representation of a cluster, namely, feature class diagram, is proposed in this paper. In order to form each sub-cluster, the semantic and structural similarities between UML class diagrams are defined, respectively.ResultsA series of experimental results show that, the proposed feature similarity measure not only speeds up the clustering process, but also expresses the closeness degree between clusters for merging clusters. The proposed algorithm shows a good clustering quality and efficiency under the condition of different size and distribution of UML class diagrams.ConclusionIt is concluded that the proposed two-level clustering method considers both semantics and structure contained in a class diagram, which can flexibly adapt to different clustering requirements. Also, the proposed clustering algorithm performs better than other related algorithms, regardless of in semantic, structural and hybrid clustering."
Research article - Revisiting heterogeneous defect prediction methods: How far are we?,"AbstractContext: Cross-project defect prediction applies to the scenarios that the target projects are new projects. Most of the previous studies tried to utilize the training data from other projects (i.e., the source projects). However, metrics used by practitioners to measure the extracted program modules from different projects may not be the same, and performing heterogeneous defect prediction (HDP) is challenging.Objective: Researchers have proposed many novel HDP methods with promising performance until now. Recently, unsupervised defect prediction (UDP) methods have received more attention and show competitive performance. However, to our best knowledge, whether HDP methods can perform significantly better than UDP methods has not yet been thoroughly investigated.Method: In this article, we perform a comparative study to have a holistic look at this issue. Specifically, we compare five HDP methods with four UDP methods on 34 projects in five groups under the same experimental setup from three different perspectives: non-effort-aware performance indicators (NPIs), effort-aware performance indicators (EPIs) and diversity analysis on identifying defective modules.Result: We have the following findings: (1) HDP methods do not perform significantly better than some of UDP methods in terms of two NPIs and four EPIs. (2) According to two satisfactory criteria recommended by previous studies, the satisfactory ratio of existing HDP methods is pessimistic. (3) The diversity of prediction for defective modules across HDP vs. UDP methods is more than that within HDP methods or UDP methods.Conclusion: The above findings implicate there is still a long way for the HDP issue to go. Given this, we present some observations about the road ahead for HDP."
Research article - Large-scale intent analysis for identifying large-review-effort code changes,"AbstractContext: Code changes to software occur due to various reasons such as bug fixing, new feature addition, and code refactoring. Change intents have been studied for years to help developers understand the rationale behind code commits. However, in most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis.Objective: In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (LRE) changes—changes with large review effort.Method: Specifically, we first propose a feedback-driven and heuristics-based approach to identify change intents of code changes. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying LRE changes. We conduct our study on four large-scale projects, one from Microsoft and three are open source projects, i.e., Qt, Android, and OpenStack.Results: Our results show that, (i) code changes with some intents (i.e., Feature and Refactor) are more likely to be LRE changes, (ii) machine learning based prediction models are applicable for identifying LRE changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average.Conclusion: The change intent analysis and its application on LRE identification proposed in this study has already been used in Microsoft to provide the review effort and intent information of changes for reviewers to accelerate the review process. To show how to deploy our approaches in real-world practice, we report a case study of developing and deploying the intent analysis system in Microsoft. Moreover, we also evaluate the usefulness of our approaches by using a questionnaire survey. The feedback from developers demonstrate its practical value."
Research article - RSTrace+: Reviewer suggestion using software artifact traceability graphs,"AbstractContext:Various types of artifacts (requirements, source code, test cases, documents, etc.) are produced throughout the lifecycle of a software. These artifacts are connected with each other via traceability links that are stored in modern application lifecycle management repositories. Throughout the lifecycle of a software, various types of changes can arise in any one of these artifacts. It is important to review such changes to minimize their potential negative impacts. To make sure the review is conducted properly, the reviewer(s) should be chosen appropriately.Objective:We previously introduced a novel approach, named RSTrace, to automatically recommend reviewers that are best suited based on their familiarity with a given artifact. In this study, we introduce an advanced version of RSTrace, named RSTrace+ that accounts for recency information of traceability links including practical tool support for GitHub.Methods:In this study, we conducted a series of experiments on finding the appropriate code reviewer(s) using RSTrace+ and provided a comparison with the other code reviewer recommendation approaches.Results:We had initially tested RSTrace+ on an open source project (Qt 3D Studio) and achieved a top-3 accuracy of 0.89 with an MRR (mean reciprocal ranking) of 0.81. In a further empirical evaluation of 40 open source projects, we compared RSTrace+ with Naive-Bayes, RevFinder and Profile based approach, and observed higher accuracies on the average.Conclusion:We confirmed that the proposed reviewer recommendation approach yields promising top-k and MRR scores on the average compared to the existing reviewer recommendation approaches. Unlike other code reviewer recommendation approaches, RSTrace+ is not limited to recommending reviewers for source code artifacts and can potentially be used for recommending reviewers for other types of artifacts. Our approach can also visualize the affected artifacts and help the developer to make assessments of the potential impacts of change to the reviewed artifact."
Research article - Performance analysis of out-of-distribution detection on trained neural networks,"AbstractContextDeep Neural Networks (DNN) have shown great promise in various domains, for example to support pattern recognition in medical imagery. However, DNNs need to be tested for robustness before being deployed in safety critical applications. One common challenge occurs when the model is exposed to data samples outside of the training data domain, which can yield to outputs with high confidence despite no prior knowledge of the given input.ObjectiveThe aim of this paper is to investigate how the performance of detecting out-of-distribution (OOD) samples changes for outlier detection methods (e.g., supervisors) when DNNs become better on training samples.MethodSupervisors are components aiming at detecting out-of-distribution samples for a DNN. The experimental setup in this work compares the performance of supervisors using metrics and datasets that reflect the most common setups in related works. Four different DNNs with three different supervisors are compared during different stages of training, to detect at what point during training the performance of the supervisors begins to deteriorate.ResultsFound that the outlier detection performance of the supervisors increased as the accuracy of the underlying DNN improved. However, all supervisors showed a large variation in performance, even for variations of network parameters that marginally changed the model accuracy. The results showed that understanding the relationship between training results and supervisor performance is crucial to improve a model’s robustness.ConclusionAnalyzing DNNs for robustness is a challenging task. Results showed that variations in model parameters that have small variations on model predictions can have a large impact on the out-of-distribution detection performance. This kind of behavior needs to be addressed when DNNs are part of a safety critical application and hence, the necessary safety argumentation for such systems need be structured accordingly."
Editorial - Software engineering and advanced applications conference 2019 – selected papers,"AbstractSoftware Engineering and Advanced Applications (SEAA) is a long-standing international forum for researchers, practitioners, and students to present and discuss the latest innovations, trends, experiences, and concerns in the field of Software Engineering and Advanced Applications in information technology for software-intensive systems. In this special issue, we present a selection of papers which show the current trends in software engineering – improved systematic reviews, deep learning and cloud computing."
Research article - A comprehensive empirical evaluation of generating test suites for mobile applications with diversity,"AbstractContext: In search-based software engineering we often use popular heuristics with default configurations, which typically lead to suboptimal results, or we perform experiments to identify configurations on a trial-and-error basis, which may lead to better results for a specific problem. We consider the problem of generating test suites for mobile applications (apps) and rely on Sapienz, a state-of-the-art approach to this problem that uses a popular heuristic (NSGA-II) with a default configuration. Objective: We want to achieve better results in generating test suites with Sapienz while avoiding trial-and-error experiments to identify a more suitable configuration of Sapienz. Method: We conducted a fitness landscape analysis of Sapienz to analytically understand the search problem, which allowed us to make informed decisions about the heuristic and configuration of Sapienz when developing Sapienzdiv. We comprehensively evaluated Sapienzdiv in a head-to-head comparison with Sapienz on 34 apps. Results: Analyzing the fitness landscape of Sapienz, we observed a lack of diversity of the evolved test suites and a stagnation of the search after 25 generations. Sapienzdiv realizes mechanisms that preserve the diversity of the test suites being evolved. The evaluation showed that Sapienzdiv achieves better or at least similar test results than Sapienz concerning coverage and the number of revealed faults. However, Sapienzdiv typically produces longer test sequences and requires more execution time than Sapienz. Conclusions: The understanding of the search problem obtained by the fitness landscape analysis helped us to find a more suitable configuration of Sapienz without trial-and-error experiments. By promoting diversity of test suites during the search, improved or at least similar test results in terms of faults and coverage can be achieved."
Research article - A Systematic Comparison of search-Based approaches for LDA hyperparameter tuning,"AbstractContext:Latent Dirichlet Allocation (LDA) has been successfully used in the literature to extract topics from software documents and support developers in various software engineering tasks. While LDA has been mostly used with default settings, previous studies showed that default hyperparameter values generate sub-optimal topics from software documents.Objective: Recent studies applied meta-heuristic search (mostly evolutionary algorithms) to configure LDA in an unsupervised and automated fashion. However, previous work advocated for different meta-heuristics and surrogate metrics to optimize. The objective of this paper is to shed light on the influence of these two factors when tuning LDA for SE tasks.Method:We empirically evaluated and compared seven state-of-the-art meta-heuristics and three alternative surrogate metrics (i.e., fitness functions) to solve the problem of identifying duplicate bug reports with LDA. The benchmark consists of ten real-world and open-source projects from the Bench4BL dataset.Results:Our results indicate that (1) meta-heuristics are mostly comparable to one another (except for random search and CMA-ES), and (2) the choice of the surrogate metric impacts the quality of the generated topics and the tuning overhead. Furthermore, calibrating LDA helps identify twice as many duplicates than untuned LDA when inspecting the top five past similar reports.Conclusion:No meta-heuristic and/or fitness function outperforms all the others, as advocated in prior studies. However, we can make recommendations for some combinations of meta-heuristics and fitness functions over others for practical use. Future work should focus on improving the surrogate metrics used to calibrate/tune LDA in an unsupervised fashion."
