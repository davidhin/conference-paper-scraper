title,abstract
Review article - Enactment of adaptation in data stream processing with latency implications—A systematic literature review,"AbstractContextStream processing is a popular paradigm to continuously process huge amounts of data. Runtime adaptation plays a significant role in supporting the optimization of data processing tasks. In recent years runtime adaptation has received significant interest in scientific literature. However, so far no categorization of the enactment approaches for runtime adaptation in stream processing has been established.ObjectiveThis paper identifies and characterizes different approaches towards the enactment of runtime adaptation in stream processing with a main focus on latency as quality dimension.MethodWe performed a systematic literature review (SLR) targeting five main research questions. An automated search, resulting in 244 papers, was conducted. 75 papers published between 2006 and 2018 were finally included. From the selected papers, we extracted data like processing problems, adaptation goals, enactment approaches of adaptation, enactment techniques, evaluation metrics as well as evaluation parameters used to trigger the enactment of adaptation in their evaluation.ResultsWe identified 17 different enactment approaches and categorized them into a taxonomy. For each, we extracted the underlying technique used to implement this enactment approach. Further, we identified 9 categories of processing problems, 6 adaptation goals, 9 evaluation metrics and 12 evaluation parameters according to the extracted data properties.ConclusionWe observed that the research interest on enactment approaches to the adaptation of stream processing has significantly increased in recent years. The most commonly applied enactment approaches are parameter adaptation to tune parameters or settings of the processing, load balancing used to re-distribute workloads, and processing scaling to dynamically scale up and down the processing. In addition to latency, most adaptations also address resource fluctuation / bottleneck problems. For presenting a dynamic environment to evaluate enactment approaches, researchers often change input rates or processing workloads."
Research article - Search-based test case implantation for testing untested configurations,"AbstractContextModern large-scale software systems are highly configurable, and thus require a large number of test cases to be implemented and revised for testing a variety of system configurations. This makes testing highly configurable systems very expensive and time-consuming.ObjectiveDriven by our industrial collaboration with a video conferencing company, we aim to automatically analyze and implant existing test cases (i.e., an original test suite) to test the untested configurations.MethodWe propose a search-based test case implantation approach (named as SBI) consisting of two key components: 1) Test case analyzer that statically analyzes each test case in the original test suite to obtain the program dependence graph for test case statements and 2) Test case implanter that uses multi-objective search to select suitable test cases for implantation using three operators, i.e., selection, crossover, and mutation (at the test suite level) and implants the selected test cases using a mutation operator at the test case level including three operations (i.e., addition, modification, and deletion).ResultsWe empirically evaluated SBI with an industrial case study and an open source case study by comparing the implanted test suites produced by three variants of SBI with the original test suite using evaluation metrics such as statement coverage (SC), branch coverage (BC), and mutation score (MS). Results show that for both the case studies, the test suites implanted by the three variants of SBI performed significantly better than the original test suites. The best variant of SBI achieved on average 19.3% higher coverage of configuration variable values for both the case studies. Moreover, for the open source case study, the best variant of SBI managed to improve SC, BC, and MS with 5.0%, 7.9%, and 3.2%, respectively.ConclusionSBI can be applied to automatically implant a test suite with the aim of testing untested configurations and thus achieving higher configuration coverage."
Research article - Bootstrapping cookbooks for APIs from crowd knowledge on Stack Overflow,"AbstractContextWell established libraries typically have API documentation. However, they frequently lack examples and explanations, possibly making difficult their effective reuse. Stack Overflow is a question-and-answer website oriented to issues related to software development. Despite the increasing adoption of Stack Overflow, the information related to a particular topic (e.g., an API) is spread across the website. Thus, Stack Overflow still lacks organization of the crowd knowledge available on it.ObjectiveOur target goal is to address the problem of the poor quality documentation for APIs by providing an alternative artifact to document them based on the crowd knowledge available on Stack Overflow, called crowd cookbook. A cookbook is a recipe-oriented book, and we refer to our cookbook as crowd cookbook since it contains content generated by a crowd. The cookbooks are meant to be used through an exploration process, i.e. browsing.MethodIn this paper, we present a semi-automatic approach that organizes the crowd knowledge available on Stack Overflow to build cookbooks for APIs. We have generated cookbooks for three APIs widely used by the software development community: SWT, LINQ and QT. We have also defined desired properties that crowd cookbooks must meet, and we conducted an evaluation of the cookbooks against these properties with human subjects.ResultsThe results showed that the cookbooks built using our approach, in general, meet those properties. As a highlight, most of the recipes were considered appropriate to be in the cookbooks and have self-contained information.ConclusionWe concluded that our approach is capable to produce adequate cookbooks automatically, which can be as useful as manually produced cookbooks. This opens an opportunity for API designers to enrich existent cookbooks with the different points of view from the crowd, or even to generate initial versions of new cookbooks."
Review article - The relationship between personality and decision-making: A Systematic literature review,"AbstractContextFrom a point of view, software development is a set of decisions that need to be made while the software is developed. Many alternatives should be considered, such as the technology to employ, or the most important features to implement. However, many factors can influence one’s decision-making, such as the decision maker’s personality.ObjectiveThis paper reports the state of the art with regard to the relationship between decision-makers’ personality and decision-making aspects.MethodWe conducted a Systematic Literature Review to search and analyze published primary studies that discuss the abovementioned relationship in the context of companies that develop any kind of product or service.ResultsDespite the recognized influence of personality in decision-making activities, we were not able to find any study in Software Engineering field that discusses this relationship. We included 15 studies and most of them are from Management field, excluding one from Information System field. From these studies, we identified 75 reported relationships between 28 different personality aspects and 30 different decision-making aspects.ConclusionThe interest in this topic born on 80’s and it has grown after 2002. However, despite the number of reported relationships, and the number of personalities and decision-making aspects investigated, more research on this topic is necessary. In particular, it is important to verify how someone’s personality influences the decision-making considering the software development context. This can help in improving how a decision is made in software engineering context."
Research article - A reference model-based user requirements elicitation process: Toward operational business-IT alignment in a co-creation value network,"AbstractContextTo improve operational business-IT alignment (BITA), the development of IT-based systems should be derived from business requirements. However, the requirements elicitation process is challenging and encounters several problems which might lead to acquiring low-quality user requirements and failure of systems development projects. Many of elicitation problems are also identified as being relevant in the BITA literature. We focus on one category of well-known elicitation problems, such as communication flaws.Until now, the majority of requirements elicitation studies with the aim of addressing operational BITA are based on an asking strategy. This elicitation strategy is suitable for relatively stable situations. To compensate for the limitation of this strategy in a more complex situation, e.g., a co-creation value network (VN) setting, using it in conjunction with other elicitation strategies is more likely to yield satisfactory results.ObjectiveTo contribute to operational BITA improvement in a VN setting by addressing one category of elicitation problems. For this purpose, we design and evaluate a reference model-based approach to facilitate the user requirements elicitation process.MethodTwo-phase research according to the design science approach is followed. In the design phase, a reference model-based user requirements elicitation process is designed. Also, as a proof of concept, two instances of this artifact are designed. Two reference models, respectively, describing customer knowledge management processes and customer knowledge management challenges in a VN setting are used separately in designing these two instances. In the evaluation phase, the applicability and usefulness of these instances are evaluated in two separate studies.ResultsA reference model supports asking-based user requirements elicitation process via a Delphi method in a complex context of a VN. It improves the user requirements elicitation process by addressing a set of recognized elicitation problems.ConclusionsThe reference model-based approach, by addressing the elicitation problems, contributes to user requirements elicitation process improvement in general and to a better operational BITA in the complex situation of a VN in particular."
Research article - A domain analysis of resource and requirements monitoring: Towards a comprehensive model of the software monitoring domain,"Abstract[Context] Complex and heterogeneous software systems need to be monitored as their full behavior often only emerges at runtime, e.g., when interacting with other systems or the environment. Software monitoring approaches observe and check properties or quality attributes of software systems during operation. Such approaches have been developed in diverse communities for various kinds of systems and purposes. For instance, requirements monitoring aims to check at runtime whether a software system adheres to its requirements, while resource or performance monitoring collects information about the consumption of computing resources by the monitored system. Many venues publish research on software monitoring, often using diverse terminology, and focusing on different monitoring aspects and phases. The lack of a comprehensive overview of existing research often leads to re-inventing the wheel. [Objective] We provide a domain model to structure and systematize the field of software monitoring, starting with requirements and resource monitoring. [Method] We developed an initial domain model based on (i) our extensive experiences with requirements and resource monitoring, (ii) earlier efforts to develop a comparison framework for monitoring approaches, and (iii) an earlier systematic literature review on requirements monitoring frameworks. We then systematically analyzed 47 existing requirements and resource monitoring approaches to iteratively refine the domain model and to develop a reference architecture for software monitoring approaches. [Results] Our domain model covers the key elements of monitoring approaches and allows analyzing their commonalities and differences. Together with the reference architecture, our domain model supports the development of integrated monitoring solutions. We provide details on 47 approaches we analyzed with the model to assess its coverage. We also evaluate the reference architecture by instantiating it for five different monitoring solutions. [Conclusions] We conclude that requirements and resource monitoring have more commonalities than differences, which is promising for the future integration of existing monitoring solutions."
Research article - Leveraging keyword-guided exploration to build test models for web applications,"AbstractContextDynamic exploration techniques, which automatically exercise possible user interface elements, have been used to explore user interface state flow graphs as test models for web applications. An exhaustive exploration may incur the well-known state explosion problem. In a limited amount of time, most existing dynamic exploration techniques tend to become mired in local or irrelevant regions of the web application due to not considering functionality semantics information. Hence, generated test models have often inadequate functionality coverage for deriving effective test cases.ObjectiveThis paper proposes a keyword-guided exploration strategy for automatic construction of web application test models. The goal is to generate incomplete test models with adequate functionality coverage in a given time budget for deriving test cases w.r.t. specified functionalities.MethodGiven very few keywords that describe specified functionalities, our strategy guides the exploration to discover user interface states and transitions among them that are relevant to the specified functionalities by computing similarity scores between text contents in web pages and given keywords. We use nine representative web applications to perform dynamic explorations in a given time budget and empirically evaluate functionality coverage, and other metrics, e.g., code coverage, the size of test model, the number of the test suite, path diversity, and DOM diversity.ResultsOur keyword-guided exploration strategy achieves a higher functionality coverage as compared with the generic and feedback-directed exploration strategies. Yet the significant improvement of functionality coverage achieved by our strategy is not exchanged at the cost of other metrics.ConclusionOur keyword-guided exploration strategy is more effective than the generic and feedback-directed exploration strategies in terms of functionality coverage. In a limited amount of time, test models generated with our strategy can be used to derive effective web application test cases."
Review article - State of the art in hybrid strategies for context reasoning: A systematic literature review,"AbstractContextSeveral strategies have been used to implement context reasoning, and a strategy that can be applied satisfactorily in different smart systems applications has not yet been found. Because of this, hybrid proposals for context reasoning are gaining prominence. These proposals allow the combination of two or more strategies.ObjectiveThis work aims to identify the state of the art in the context awareness field, considering papers that use hybrid strategies for context reasoning.MethodA Systematic Literature Review was explored, contributing to the identification of relevant works in the field, as well as the specification of criteria for its selection. In this review, we analyzed papers published between 2004 and 2018.ResultsDuring the process, we identified 3241 papers. After applying filtering and conditioning processes, ten papers about hybrid strategies for context reasoning were selected. We described, discussed, and compared the selected papers.ConclusionThe Systematic Literature Review showed that some researchers explore hybrid proposals, but these proposals do not offer flexibility regarding the reasoning strategies used. Thus, we noted that research efforts related to the topic are still necessary, mainly focusing on the development of dynamic approaches that allow the applications to choose how they want to use the different resources available."
Research article - An overview of a novel analysis approach for enhancing context awareness in smart environments,"AbstractContextThis work is part of context aware applications design and development, and smart environments in which context changes frequently.ObjectiveThe objective of the work is to facilitate the design and the development of context aware applications able to detect context changes and to predict context.MethodIn the paper, two analysis tasks are proposed. An analysis task for detection aiming at supporting application designers to conceive easily context aware applications able to detect context changes and an analysis task for prediction aiming at helping the application designers to conceive context aware applications able to predict context. The paper details also an analysis module that implements the functionalities of the analysis tasks. The analysis module helps the application developers to develop context aware applications. Finally, the paper introduces a case study related to smart buildings in order to show the usefulness of the analysis tasks.ResultsThe paper shows an application scenario related to smart buildings and particularly water consumption prediction. Also the paper presents experiments related to memory consumption introduced by the use of our analysis module.ConclusionsThe application scenario illustrates the usefulness of the analysis approach. The overhead introduced by the analysis module is negligeable."
Research article - A distributed event-driven architectural model based on situational awareness applied on internet of things,"AbstractContextThe IoT network is comprised of numerous and heterogeneous devices that are capable of generating large amounts of events. To enable the IoT paradigm, it is necessary to integrate, process, and react to events on the fly.ObjectiveThe goal of this paper is to support the increased demands of scalability, flexibility, autonomy, and heterogeneity for IoT event processing. A distributed architectural model based on Situational Awareness, named EXEHDA-SA, was designed to provide event collection, hybrid processing, and customizable and dynamic reaction features.MethodThe conception of the model was based on a middleware for ubiquitous computing called EXEHDA, thus benefiting from its already defined strategies. The proposal follows a multi-level strategy and consists of three hierarchically interconnected modular components.ResultsOur main contribution is the conception and validation of a model for event collection, processing and reaction for modern distributed environments. The contribution is evidenced through experiments performed on a prototype implemented on consolidated free and open source technologies. The experiments are made up of five case studies where each one evaluates a scenario for IoT demands.ConclusionThrough these case studies which were proposed in information security area, we demonstrated the feasibility of this proposal for deployment in IoT production environments. Furthermore, EXEHDA-SA is able to operate on different scenarios due to each component modularity and its consequent extensibility."
Research article - GoalD: A Goal-Driven deployment framework for dynamic and heterogeneous computing environments,"AbstractContextEmerging paradigms like Internet of Things and Smart Cities utilize advanced sensing and communication infrastructures, where heterogeneity is an inherited feature. Applications targeting such environments require adaptability and context-sensitivity to uncertain availability and failures in resources and their ad-hoc networks. Such heterogeneity is often hard to predict, making the deployment process a challenging task.ObjectiveThis paper proposes GoalD as a goal-driven framework to support autonomous deployment of heterogeneous computational resources to fulfill requirements, seen as goals, and their correlated components on one hand, and the variability space of the hosting computing and sensing environment on the other hand.MethodGoalD comprises an offline and an online stage to fulfill autonomous deployment by leveraging the use of goals. Deployment configuration strategies arise from the variability structure of the Contextual Goal Model as an underlying structure to guide autonomous planning by selecting available as well as suitable resources at runtime.ResultsWe evaluate GoalD on an existing exemplar from the self-adaptive systems community – the Tele Assistance Service provided by Weyns and Calinescu [1]. Furthermore, we evaluate the scalability of GoalD on a repository consisting of 430,500 artifacts. The evaluation results demonstrate the usefulness and scalability of GoalD in planning the deployment of a system with thousands of components in a few milliseconds.ConclusionGoalD is a framework to systematically tackle autonomous deployment in highly heterogeneous computing environments, partially unknown at design-time following a goal-oriented approach to achieve the user goals in a target environment. GoalD has demonstrated itself able to scale for deployment planning dealing with thousands of components in a few milliseconds."
