title,abstract
Symbolic Refinement of Extended State Machines with Applications to the Automatic Derivation of Sub-Components and Controllers,"Abstract Nowadays, extended state machines are prominent requirements specification techniques due to their capabilities of modeling complex systems in a compact way. These machines extend the standard state machines with variables and have transitions guarded by enabling predicates and may include variable update statements. Given a system modeled as an extended state machine, with possibly infinite state space and some non-controllable (parameterized) interactions, a pruning procedure is proposed to symbolically derive a maximal sub-machine of the original system that satisfies certain conditions; namely, some safeness and absence of undesirable deadlocks which could be produced during pruning. In addition, the user may specify, as predicates associated with states, some general goal assertions that should be preserved in the obtained sub-machine. Further, one may also specify some specific requirements such as the elimination of certain undesirable deadlocks at states, or fail states that should never be reached. Application examples are given considering deadlock avoidance and loops including infinite loops over non-controllable interactions showing that the procedure may not terminate. In addition, the procedure is applied for finding a controller of a system to be controlled. The approach generalizes existing work in respect to the considered extended machine model and the possibility of user defined control objectives written as assertions at states.Keywords Control Engineering Computing, Finite State Machines, Formal Specification, Formal Verification, Large Scale Systems, Prominent Requirements Specification Techniques, Standard State Machines, Extended State Machine, Possibly Infinite State Space, Noncontrollable Interactions, Maximal Sub Machine, Considered Extended Machine Model, System Recovery, Control Systems, Calculators, Facsimile, Electronic Mail, Unified Modeling Language, Computer Architecture, Requirements Specifications, Component Design And Refinement, Discrete Event Control Systems, Extended State Machines, Submodule Construction And Automatic Derivation Of A Component Behavior"
"A Systematic Literature Review on Bad Smells–5 W's: Which, When, What, Who, Where","Abstract Bad smells are sub-optimal code structures that may represent problems needing attention. We conduct an extensive literature review on bad smells relying on a large body of knowledge from 1990 to 2017. We show that some smells are much more studied in the literature than others, and also that some of them are intrinsically inter-related (which). We give a perspective on how the research has been driven across time (when). In particular, while the interest in duplicated code emerged before the reference publications by Fowler and Beck and by Brown et al., other types of bad smells only started to be studied after these seminal publications, with an increasing trend in the last decade. We analyzed aims, findings, and respective experimental settings, and observed that the variability of these elements may be responsible for some apparently contradictory findings on bad smells (what). Moreover, we could observe that, in general, papers tend to study different types of smells at once. However, only a small percentage of those papers actually investigate possible relations between the respective smells (co-studies), i.e., each smell tends to be studied in isolation. Despite of a few relations between some types of bad smells have been investigated, there are other possible relations for further investigation. We also report that authors have different levels of interest in the subject, some of them publishing sporadically and others continuously (who). We observed that scientific connections are ruled by a large “small world” connected graph among researchers and several small disconnected graphs. We also found that the communities studying duplicated code and other types of bad smells are largely separated. Finally, we observed that some venues are more likely to disseminate knowledge on Duplicate Code (which often is listed as a conference topic on its own), while others have a more balanced distribution among other smells (where). Finally, we provide a discussion on future directions for bad smell research.Keywords Graph Theory, Program Diagnostics, Software Maintenance, Systematic Literature Review, Bad Smells, Duplicated Code, Possible Relations, Bad Smell Research, Suboptimal Code Structures, Small World Connected Graph, Systematics, Bibliographies, Software, Measurement, Organizations, Tools, Cloning, Software Maintenance, Reengineering, Bad Smell"
Automatic Feature Learning for Predicting Vulnerable Software Components,"Abstract Code flaws or vulnerabilities are prevalent in software systems and can potentially cause a variety of problems including deadlock, hacking, information loss and system failure. A variety of approaches have been developed to try and detect the most likely locations of such code vulnerabilities in large code bases. Most of them rely on manually designing code features (e.g., complexity metrics or frequencies of code tokens) that represent the characteristics of the potentially problematic code to locate. However, all suffer from challenges in sufficiently capturing both semantic and syntactic representation of source code, an important capability for building accurate prediction models. In this paper, we describe a new approach, built upon the powerful deep learning Long Short Term Memory model, to automatically learn both semantic and syntactic features of code. Our evaluation on 18 Android applications and the Firefox application demonstrates that the prediction power obtained from our learned features is better than what is achieved by state of the art vulnerability prediction models, for both within-project prediction and cross-project prediction.Keywords Data Mining, Feature Extraction, Learning Artificial Intelligence, Public Domain Software, Security Of Data, Prediction Power, Art Vulnerability Prediction Models, Within Project Prediction, Cross Project Prediction, Automatic Feature Learning, Predicting Vulnerable Software Components, Software Systems, Information Loss, System Failure, Code Vulnerabilities, Code Bases, Code Features, Complexity Metrics, Code Tokens, Potentially Problematic Code, Semantic Representation, Syntactic Representation, Source Code, Important Capability, Accurate Prediction Models, Powerful Deep Learning Long Short Term Memory Model, Semantics, Software Systems, Predictive Models, Security, Feature Extraction, System Recovery, Software Vulnerability Prediction, Mining Software Engineering Repositories, Empirical Software Engineering"
Beyond Technical Aspects: How Do Community Smells Influence the Intensity of Code Smells?,"Abstract Code smells are poor implementation choices applied by developers during software evolution that often lead to critical flaws or failure. Much in the same way, community smells reflect the presence of organizational and socio-technical issues within a software community that may lead to additional project costs. Recent empirical studies provide evidence that community smells are often-if not always-connected to circumstances such as code smells. In this paper we look deeper into this connection by conducting a mixed-methods empirical study of 117 releases from 9 open-source systems. The qualitative and quantitative sides of our mixed-methods study were run in parallel and assume a mutually-confirmative connotation. On the one hand, we survey 162 developers of the 9 considered systems to investigate whether developers perceive relationship between community smells and the code smells found in those projects. On the other hand, we perform a fine-grained analysis into the 117 releases of our dataset to measure the extent to which community smells impact code smell intensity (i.e., criticality). We then propose a code smell intensity prediction model that relies on both technical and community-related aspects. The results of both sides of our mixed-methods study lead to one conclusion: community-related factors contribute to the intensity of code smells. This conclusion supports the joint use of community and code smells detection as a mechanism for the joint management of technical and social problems around software development communities.Keywords Consumer Behaviour, Organisational Aspects, Public Domain Software, Software Maintenance, Software Management, Software Metrics, Software Quality, Code Smells, Community Smells, Socio Technical Issues, Software Community, Recent Empirical Studies, Mixed Methods Empirical Study, Mixed Methods Study, Impact Code Smell Intensity, Code Smell Intensity Prediction Model, Community Related Aspects, Community Related Factors, Software Development Communities, Predictive Models, Software Engineering, Open Source Software, Convergence, Tools, Feature Extraction, Code Smells, Organizational Structure, Community Smells, Mixed Methods Study"
CBGA-ES+: A Cluster-Based Genetic Algorithm with Non-Dominated Elitist Selection for Supporting Multi-Objective Test Optimization,"Abstract Many real-world test optimization problems (e.g., test case prioritization) are multi-objective intrinsically and can be tackled using various multi-objective search algorithms (e.g., Non-dominated Sorting Genetic Algorithm (NSGA-II)). However, existing multi-objective search algorithms have certain randomness when selecting parent solutions for producing offspring solutions. In a worse case, suboptimal parent solutions may result in offspring solutions with bad quality, and thus affect the overall quality of the solutions in the next generation. To address such a challenge, we propose CBGA-ES+, a novel cluster-based genetic algorithm with non-dominated elitist selection to reduce the randomness when selecting the parent solutions to support multi-objective test optimization. We empirically compared CBGA-ES+ with random search and greedy (as baselines), four commonly used multi-objective search algorithms (i.e., Multi-objective Cellular genetic algorithm (MOCell), NSGA-II, Pareto Archived Evolution Strategy (PAES), and Strength Pareto Evolutionary Algorithm (SPEA2)), and the predecessor of CBGA-ES+ (named CBGA-ES) using five multi-objective test optimization problems with eight subjects (two industrial, one real world, and five open source). The results showed that CBGA-ES+ managed to significantly outperform the selected search algorithms for a majority of the experiments. Moreover, for the solutions in the same search space, CBGA-ES+ managed to perform better than CBGA-ES, MOCell, NSGA-II, PAES, and SPEA2 for 2.2, 13.6, 14.5, 17.4, and 9.9 percent, respectively. Regarding the running time of the algorithm, CBGA-ES+ was faster than CBGA-ES for all the experiments.Keywords Evolutionary Computation, Genetic Algorithms, Pareto Optimisation, Search Problems, Nondominated Elitist Selection, Real World Test Optimization Problems, Test Case Prioritization, Nondominated Sorting Genetic Algorithm, NSGA II, Multiobjective Search Algorithms, Offspring Solutions, Suboptimal Parent Solutions, Cluster Based Genetic Algorithm, Multiobjective Cellular Genetic Algorithm, Strength Pareto Evolutionary Algorithm, Search Algorithms, CBGA ES Sup Sup, Multiobjective Test Optimization, Pareto Archived Evolution Strategy, Optimization, Genetic Algorithms, Sociology, Statistics, Search Problems, Clustering Algorithms, Software Algorithms, Elitist Selection, Multi Objective Genetic Algorithm, Multi Objective Test Optimization, Search"
Evaluating Model-Driven Development Claims with Respect to Quality: A Family of Experiments,"Abstract Context: There is a lack of empirical evidence on the differences between model-driven development (MDD), where code is automatically derived from conceptual models, and traditional software development method, where code is manually written. In our previous work, we compared both methods in a baseline experiment concluding that quality of the software developed following MDD was significantly better only for more complex problems (with more function points). Quality was measured through test cases run on a functional system. Objective: This paper reports six replications of the baseline to study the impact of problem complexity on software quality in the context of MDD. Method: We conducted replications of two types: strict replications and object replications. Strict replications were similar to the baseline, whereas we used more complex experimental objects (problems) in the object replications. Results: MDD yields better quality independently of problem complexity with a moderate effect size. This effect is bigger for problems that are more complex. Conclusions: Thanks to the bigger size of the sample after aggregating replications, we discovered an effect that the baseline had not revealed due to the small sample size. The baseline results hold, which suggests that MDD yields better quality for more complex problems.Keywords Program Testing, Software Quality, Object Replications, Strict Replications, Complex Experimental Objects, MDD, Problem Complexity, Model Driven Development, Software Development, Function Points, Functional System, Software Quality, Test Cases, Unified Modeling Language, Productivity, Complexity Theory, Inspection, Model Driven Development, Software Quality, Automatic Programming, Methodologies, Validation"
A Study of Feature Scattering in the Linux Kernel,"Abstract Feature code is often scattered across a software system. Scattering is not necessarily bad if used with care, as witnessed by systems with highly scattered features that evolved successfully. Feature scattering, often realized with a pre-processor, circumvents limitations of programming languages and software architectures. Unfortunately, little is known about the principles governing scattering in large and long-living software systems. We present a longitudinal study of feature scattering in the Linux kernel, complemented by a survey with 74, and interviews with nine Linux kernel developers. We analyzed almost eight years of the kernel's history, focusing on its largest subsystem: device drivers. We learned that the ratio of scattered features remained nearly constant and that most features were introduced without scattering. Yet, scattering easily crosses subsystem boundaries, and highly scattered outliers exist. Scattering often addresses a performance-maintenance tradeoff (alleviating complicated APIs), hardware design limitations, and avoids code duplication. While developers do not consciously enforce scattering limits, they actually improve the system design and refactor code, thereby mitigating pre-processor idiosyncrasies or reducing its use.Keywords Device Drivers, Linux, Operating System Kernels, Software Maintenance, Source Code Software, Refactor Code, Feature Scattering, Feature Code, Software System, Linux Kernel Developers, System Design, Device Drivers, Scattering, Kernel, Linux, Interviews, Software Systems, Maintenance Engineering, Pre Processor Linux Kernel Feature Scattering"
Mining Fix Patterns for FindBugs Violations,"Abstract Several static analysis tools, such as Splint or FindBugs, have been proposed to the software development community to help detect security vulnerabilities or bad programming practices. However, the adoption of these tools is hindered by their high false positive rates. If the false positive rate is too high, developers may get acclimated to violation reports from these tools, causing concrete and severe bugs being overlooked. Fortunately, some violations are actually addressed and resolved by developers. We claim that those violations that are recurrently fixed are likely to be true positives, and an automated approach can learn to repair similar unseen violations. However, there is lack of a systematic way to investigate the distributions on existing violations and fixed ones in the wild, that can provide insights into prioritizing violations for developers, and an effective way to mine code and fix patterns which can help developers easily understand the reasons of leading violations and how to fix them. In this paper, we first collect and track a large number of fixed and unfixed violations across revisions of software. The empirical analyses reveal that there are discrepancies in the distributions of violations that are detected and those that are fixed, in terms of occurrences, spread and categories, which can provide insights into prioritizing violations. To automatically identify patterns in violations and their fixes, we propose an approach that utilizes convolutional neural networks to learn features and clustering to regroup similar instances. We then evaluate the usefulness of the identified fix patterns by applying them to unfixed violations. The results show that developers will accept and merge a majority (69/116) of fixes generated from the inferred fix patterns. It is also noteworthy that the yielded patterns are applicable to four real bugs in the Defects4J major benchmark for software testing and automated repair.Keywords Data Mining, Inference Mechanisms, Learning Artificial Intelligence, Neural Nets, Program Debugging, Program Diagnostics, Program Testing, Public Domain Software, Security Of Data, Software Engineering, Software Maintenance, Software Quality, Find Bugs Violations, Static Analysis Tools, Software Development Community, High False Positive Rates, False Positive Rate, Violation Reports, Similar Unseen Violations, Prioritizing Violations, Leading Violations, Unfixed Violations, Fixes, Identified Fix Patterns, Inferred Fix Patterns, Mining Fix Patterns, Tools, Static Analysis, Computer Bugs, Maintenance Engineering, Software, Java, Security, Fix Pattern, Pattern Mining, Program Repair, Findbugs Violation, Unsupervised Learning"
"Automatically ‘Verifying’ Discrete-Time Complex Systems through Learning, Abstraction and Refinement","Abstract Precisely modeling complex systems like cyber-physical systems is challenging, which often renders model-based system verification techniques like model checking infeasible. To overcome this challenge, we propose a method called LAR to automatically v e r if y ' s u c h c o m p ≤ x s y s t e m s t h r o u g h a c o m b ∈ a t i o n o f ≤ a r n ∈ g , | t | r a c t i o n and r e f ∈ e m e n t o m a s e t o f s y s t e m log t r a c e s . W e a s ∑ e t ˆ log t r a c e s and s a m p l ∈ g e q u e n c y a r e a d e q u a t e → ∩ t u r e v enough' behaviour of the system. Given a safety property and the concrete system log traces as input, LAR automatically learns and refines system models, and produces two kinds of outputs. One is a counterexample with a bounded probability of being spurious. The other is a probabilistic model based on which the given property is `verified'. The model can be viewed as a proof obligation, i.e., the property is verified if the model is correct. It can also be used for subsequent system analysis activities like runtime monitoring or model-based testing. Our method has been implemented as a self-contained software toolkit. The evaluation on multiple benchmark systems as well as a real-world water treatment system shows promising results.Keywords Computational Complexity, Distributed Processing, Formal Verification, Large Scale Systems, Learning Artificial Intelligence, Probability, Program Verification, Real World Water Treatment System, Multiple Benchmark Systems, Subsequent System Analysis Activities, Given Property, Probabilistic Model, System Models, Concrete System, Safety Property, Log Traces, Abstraction, Automatically Verify Such Complex Systems, LAR, Model Based System Verification Techniques, Cyber Physical Systems, Discrete Time Complex Systems, Probabilistic Logic, Model Checking, Analytical Models, Safety, Complex Systems, System Analysis And Design, Verification, Model Learning, Abstraction Refinement, Cyber Physical System"
2020 Index IEEE Transactions on Software Engineering Vol. 46,"Abstract This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index."
Automated Documentation of Android Apps,"Abstract Developers do not always have the knowledge needed to understand source code and must refer to different resources (e.g., teammates, documentation, the web). This non-trivial process, called program comprehension, is very time-consuming. While many approaches support the comprehension of a given code at hand, they are mostly focused on defining extractive summaries from the code (i.e., on selecting from a given piece of code the most important statements/comments to comprehend it). However, if the information needed to comprehend the code is not there, their usefulness is limited. We present ADANA, an approach to automatically inject comments describing a given piece of Android code. ADANA reuses the descriptions of similar and well-documented code snippets retrieved from various online resources. Our evaluation has shown that ADANA is able to aid the program comprehension process.Keywords Android Operating System, Document Handling, Internet, Mobile Computing, Program Diagnostics, Query Processing, Reverse Engineering, Software Maintenance, Program Comprehension Process, Online Resources, Well Documented Code Snippets, Android Code, ADANA, Given Piece, Defining Extractive Summaries, Given Code, Called Program Comprehension, Nontrivial Process, Teammates, Source Code, Android Apps, Automated Documentation, Knowledge Based Systems, Documentation, Java, Cloning, Asia, Task Analysis, Data Mining, Program Comprehension, Documentation, Android"
