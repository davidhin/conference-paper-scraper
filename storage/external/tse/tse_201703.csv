title,abstract
Improving Timeliness and Visibility in Publishing Software Engineering Research,"We believe that the role of TSE is to serve and connect the growing international community of software engineering researchers and practitioners. The TSE editorial board has continued to uphold the high standard of quality that has been a hallmark of the journal since its inception. In addition, we have worked in a number of areas to provide more timely and more visible content for the community. Timeliness. In 2015 we instituted certain paper review practices and this has led to a reduction in the time it takes to reach a decision and to publish accepted manuscripts. Specifically, the average number of days from submission of a manuscript to TSE until a final decision is sent to the authors has been reduced from 144 in 2014 to 98 in 2016. This represents a more than 6 week reduction in review time and brings the average time in review for TSE to just over 3 months. Review time varies of course, depending on whether a paper is rejected on first review or goes through major revisions, so the average is only part of the story. Our new practices have also reduced the time it takes from original submission to when the electronic version of an accepted manuscript is published. In 2014 this took, on average, 365 days, but we were able to reduce that by over 16 weeks to 250 days in 2016. The upshot is that, on average, accepted TSE manuscripts now appear online in just over 8 months. These improvements have been a team effort and we would like to thank John Grundy and Christine Shaughnessy, who worked with the editorial board to develop and implement strategies for improving the timeliness of TSE reviewing. The editorial board, and the community of reviewers, also deserves thanks for their part in implementing the new review practices. We believe that these efforts have maintained review quality. Evidence of this can be found in the fact that the TSE acceptance rate is the same, at 21.6%, in 2016 as it was in 2014, and the number of papers for which authors have questioned the review outcomes has decreased. We received feedback about review outcomes for 5 papers in 2014, 0.9% of submissions, and for 4 papers in 2016, 0.6% of submissions. Our goal is to continue to perform the highest-quality review, but to make sure that we expedite the review process so that results get out to the community as soon as possible. We believe that this is especially important as we continue to develop the journal-first publication model at TSE (more on that below). Visibility. The TSE editorial board has taken a leadership role in helping to establish a journal-first publication model for the software engineering research community. TSE established a journal-first paper category in January of 2016 and piloted journal-first publication in 2015 and 2016 in partnership with TOSEM, ESE, ICSE, FSE, and ESEC/FSE. We have now established a multi-year agreement with ICSE to present TSE papers at the conference. The details of how TSE content flows to ICSE are described on the journal web site: https://www.computer.org/web/tse/author . The development and implementation of journal-first publication for the software engineering community has been a team effort and we would like to thank all of our partners at TOSEM, ESE, ICSE, FSE, and ESEC/FSE, and especially Jane Cleland-Huang, who has supported these efforts as a TSE representative. There is reason to believe that this approach has value for the software engineering research community. In 2016, TSE received 216 journal-first manuscripts and 208 regular manuscripts; combined this represents an increase of almost 20 percent in submissions over 2015, with a majority pursuing journal-first publication. The organizers of ICSE 2017 extended 26 invitations to authors of TSE papers to present at the conference and with 21 accepting there will be a substantial body of TSE work presented this May in Buenos Aires. The journal-first process for ESEC/FSE 2017 is underway, so there will be even more opportunity to increase the visibility of TSE contributions going forward. In January of 2016 we created a Facebook community for TSE : https://www.facebook.com/ieeetse/ . Throughout the year we flowed information about accepted and featured papers to that page. The TSE Facebook presence is about to get much more interesting, however, since in January of 2017 we named Mei Nagappan the TSE “Information Director.” Mei has a number of initiatives in the works, including feature posts for all TSE journal-first papers that will be presented at upcoming conferences. Stay tuned to the page to connect with newly emerging TSE content.    People Make TSE Work The associate editors of TSE play a critical role. They assess manuscripts to make judgments about their appropriateness for the journal. When appropriate they commission a set of reviews from experts in the field. Perhaps most critically, when reviews are returned they interpret and synthesize the set of reviews to provide a coherent message and judgment to the authors about their paper. Two members of the editorial board retired in 2016: John Mylopolous and Tim Menzies. We thank each of them for their service, which, in some cases, is continuing as they shepherd papers through the review process. In 2016 TSE has been fortunate to add the following Associate Editors: Emilia Mendes, Miryung Kim, Andy Ko, Eric Bodden, and Tao Xie. We look forward to working with them over the coming year."
Automating Live Update for Generic Server Programs,"Abstract The pressing demand to deploy software updates without stopping running programs has fostered much research on live update systems in the past decades. Prior solutions, however, either make strong assumptions on the nature of the update or require extensive and error-prone manual effort, factors which discourage the adoption of live update. This paper presents Mutable Checkpoint-Restart (MCR), a new live update solution for generic (multiprocess and multithreaded) server programs written in C. Compared to prior solutions, MCR can support arbitrary software updates and automate most of the common live update operations. The key idea is to allow the running version to safely reach a quiescent state and then allow the new version to restart as similarly to a fresh program initialization as possible, relying on existing code paths to automatically restore the old program threads and reinitialize a relevant portion of the program data structures. To transfer the remaining data structures, MCR relies on a combination of precise and conservative garbage collection techniques to trace all the global pointers and apply the required state transformations on the fly. Experimental results on popular server programs (Apache httpd, nginx, OpenSSH and vsftpd) confirm that our techniques can effectively automate problems previously deemed difficult at the cost of negligible performance overhead (2 percent on average) and moderate memory overhead (3.9 × × on average, without optimizations).Keywords Servers, Data Structures, Convergence, Software, Manuals, System Recovery, Buildings, Garbage Collection, Live Update, DSU, Checkpoint Restart, Quiescence Detection, Record Replay"
CACheck: Detecting and Repairing Cell Arrays in Spreadsheets,"Abstract Spreadsheets are widely used by end users for numerical computation in their business. Spreadsheet cells whose computation is subject to the same semantics are often clustered in a row or column as a cell array. When a spreadsheet evolves, the cells in a cell array can degenerate due to ad hoc modifications. Such degenerated cell arrays no longer keep cells prescribing the same computational semantics, and are said to exhibit ambiguous computation smells. We propose CACheck, a novel technique that automatically detects and repairs smelly cell arrays by recovering their intended computational semantics. Our empirical study on the EUSES and Enron corpora finds that such smelly cell arrays are common. Our study also suggests that CACheck is useful for detecting and repairing real spreadsheet problems caused by smelly cell arrays. Compared with our previous work AmCheck, CACheck detects smelly cell arrays with higher precision and recall rate.Keywords Semantics, Maintenance Engineering, Software, Computer Science, Nonhomogeneous Media, Electronic Mail, Business, Ambiguous Computation Smell, Spreadsheet, Cell Array"
Dependence Guided Symbolic Execution,"Abstract Symbolic execution is a powerful technique for systematically exploring the paths of a program and generating the corresponding test inputs. However, its practical usage is often limited by the path explosion problem, that is, the number of explored paths usually grows exponentially with the increase of program size. In this paper, we argue that for the purpose of fault detection it is not necessary to systematically explore the paths, and propose a new symbolic execution approach to mitigate the path explosion problem by predicting and eliminating the redundant paths based on symbolic value. Our approach can achieve the equivalent fault detection capability as traditional symbolic execution without exhaustive path exploration. In addition, we develop a practical implementation called Dependence Guided Symbolic Execution (DGSE) to soundly approximate our approach. Through exploiting program dependence, DGSE can predict and eliminate the redundant paths at a reasonable computational cost. Our empirical study shows that the redundant paths are abundant and widespread in a program. Compared with traditional symbolic execution, DGSE only explores 6.96 to 96.57 percent of the paths and achieves a speedup of 1.02 Z_$\times$_Z to 49.56Z_$\times$_Z . We have released our tool and the benchmarks used to evaluate DGSEZ_$^\ast$_Z .Keywords Fault Detection, Explosions, Benchmark Testing, Electronic Mail, Computational Efficiency, Input Variables, Program Dependence, Symbolic Execution, Path Coverage"
Improving Automated Bug Triaging with Specialized Topic Model,"Abstract Bug triaging refers to the process of assigning a bug to the most appropriate developer to fix. It becomes more and more difficult and complicated as the size of software and the number of developers increase. In this paper, we propose a new framework for bug triaging, which maps the words in the bug reports (i.e., the term space) to their corresponding topics (i.e., the topic space). We propose a specialized topic modeling algorithm named multi-feature topic model (MTM) which extends Latent Dirichlet Allocation (LDA) for bug triaging. MTM considers product and component information of bug reports to map the term space to the topic space. Finally, we propose an incremental learning method named TopicMiner which considers the topic distribution of a new bug report to assign an appropriate fixer based on the affinity of the fixer to the topics. We pair TopicMiner with MTM (TopicMiner M T M M ). We have evaluated our solution on 5 large bug report datasets including GCC, OpenOffice, Mozilla, Netbeans, and Eclipse containing a total of 227,278 bug reports. We show that TopicMiner M T M M can achieve top-1 and top-5 prediction accuracies of 0.4831-0.6868, and 0.7686-0.9084, respectively. We also compare TopicMiner M T M M with Bugzie, LDA-KL, SVM-LDA, LDA-Activity, and Yang et al.'s approach. The results show that TopicMiner M T M M on average improves top-1 and top-5 prediction accuracies of Bugzie by 128.48 and 53.22 percent, LDA-KL by 262.91 and 105.97 percent, SVM-LDA by 205.89 and 110.48 percent, LDA-Activity by 377.60 and 176.32 percent, and Yang et al.'s approach by 59.88 and 13.70 percent, respectively.Keywords Software, Resource Management, Software Algorithms, Support Vector Machines, Learning Systems, Indexes, Computer Bugs, Topic Model, Developer, Bug Triaging, Feature Information"
