title,abstract
A Deep Learning Model for Estimating Story Points,"Abstract Although there has been substantial research in software analytics for effort estimation in traditional software projects, little work has been done for estimation in agile projects, especially estimating the effort required for completing user stories or issues. Story points are the most common unit of measure used for estimating the effort involved in completing a user story or resolving an issue. In this paper, we propose a prediction model for estimating story points based on a novel combination of two powerful deep learning architectures: long short-term memory and recurrent highway network. Our prediction system is end-to-end trainable from raw input data to prediction outcomes without any manual feature engineering. We offer a comprehensive dataset for story points-based estimation that contains 23,313 issues from 16 open source projects. An empirical evaluation demonstrates that our approach consistently outperforms three common baselines (Random Guessing, Mean, and Median methods) and six alternatives (e.g., using Doc2Vec and Random Forests) in Mean Absolute Error, Median Absolute Error, and the Standardized Accuracy.Keywords Learning Artificial Intelligence, Project Management, Public Domain Software, Software Architecture, Software Management, Software Analytics, Effort Estimation, Agile Projects, Prediction Model, End To End Trainable, Story Points Based Estimation, Software Projects, Open Source Projects, Deep Learning Architectures, Mean Absolute Error, Median Absolute Error, Standardized Accuracy, Project Management, Software Architecture, Learning Artificial Intelligence, Deep Learning, Software Analytics, Effort Estimation, Story Point Estimation, Deep Learning"
Design Rule Spaces: A New Model for Representing and Analyzing Software Architecture,"Abstract In this paper, we propose an architecture model called Design Rule Space (DRSpace). We model the architecture of a software system as multiple overlapping DRSpaces, reflecting the fact that any complex software system must contain multiple aspects, features, patterns, etc. We show that this model provides new ways to analyze software quality. In particular, we introduce an Architecture Root detection algorithm that captures DRSpaces containing large numbers of a project's bug-prone files, which are called Architecture Roots (ArchRoots). After investigating ArchRoots calculated from 15 open source projects, the following observations become clear: from 35 to 91 percent of a project's most bug-prone files can be captured by just 5 ArchRoots, meaning that bug-prone files are likely to be architecturally connected. Furthermore, these ArchRoots tend to live in the system for significant periods of time, serving as the major source of bug-proneness and high maintainability costs. Moreover, each ArchRoot reveals multiple architectural flaws that propagate bugs among files and this will incur high maintenance costs over time. The implication of our study is that the quality, in terms of bug-proneness, of a large, complex software project cannot be fundamentally improved without first fixing its architectural flaws.Keywords Computer Debugging, Software Architecture, Software Maintenance, Software Quality, Architecture Model, DR Space, Complex Software System, Multiple Aspects, Software Quality, Arch Root, Bug Prone Files, Complex Software Project, Software Architecture, Design Rule Spaces, Architecture Root Detection Algorithm, Computer Bugs, Computer Architecture, Software Architecture, Production Facilities, Analytical Models, Software Systems, Software Architecture, Reverse Engineering, Defect Prediction, Technical Debt, Code Smells, Bug Localization"
The Impact of Automated Parameter Optimization on Defect Prediction Models,"Abstract Defect prediction models-classifiers that identify defect-prone software modules-have configurable parameters that control their characteristics (e.g., the number of trees in a random forest). Recent studies show that these classifiers underperform when default settings are used. In this paper, we study the impact of automated parameter optimization on defect prediction models. Through a case study of 18 datasets, we find that automated parameter optimization: (1) improves AUC performance by up to 40 percentage points; (2) yields classifiers that are at least as stable as those trained using default settings; (3) substantially shifts the importance ranking of variables, with as few as 28 percent of the top-ranked variables in optimized classifiers also being top-ranked in non-optimized classifiers; (4) yields optimized settings for 17 of the 20 most sensitive parameters that transfer among datasets without a statistically significant drop in performance; and (5) adds less than 30 minutes of additional computation to 12 of the 26 studied classification techniques. While widely-used classification techniques like random forest and support vector machines are not optimization-sensitive, traditionally overlooked techniques like C5.0 and neural networks can actually outperform widely-used techniques after optimization is applied. This highlights the importance of exploring the parameter space when using parameter-sensitive classification techniques.Keywords Optimisation, Pattern Classification, Random Forests, Software Quality, Support Vector Machines, Automated Parameter Optimization, Random Forest, Nonoptimized Classifiers, Optimized Settings, 20 Most Sensitive Parameters, Parameter Space, Parameter Sensitive Classification Techniques, Defect Prediction Models, Defect Prone Software Modules, Support Vector Machines, Optimization, Predictive Models, Computational Modeling, Software, Neural Networks, Computational Efficiency, Power System Stability, Software Defect Prediction, Search Based Software Engineering, Experimental Design, Classification Techniques, Parameter Optimization, Grid Search, Random Search, Genetic Algorithm, Differential Evolution"
Toward Methodological Guidelines for Process Theories and Taxonomies in Software Engineering,"Abstract Software engineering is increasingly concerned with theory because the foundational knowledge comprising theories provides a crucial counterpoint to the practical knowledge expressed through methods and techniques. Fortunately, much guidance is available for generating and evaluating theories for explaining why things happen (variance theories). Unfortunately, little guidance is available concerning theories for explaining how things happen (process theories), or theories for analyzing and understanding situations (taxonomies). This paper therefore attempts to clarify the nature and functions of process theories and taxonomies in software engineering research, and to synthesize methodological guidelines for their generation and evaluation. It further advances the key insight that most process theories are taxonomies with additional propositions, which helps inform their evaluation. The proposed methodological guidance has many benefits: it provides a concise summary of existing guidance from reference disciplines, it adapts techniques from reference disciplines to the software engineering context, and it promotes approaches that better facilitate scientific consensus.Keywords Software Engineering, Process Theories, Taxonomies, Variance Theories, Software Engineering Context, Taxonomy, Software, Software Engineering, Guidelines, Measurement, Knowledge Engineering, Organisms, Research Methodology, Process Theory, Taxonomy, Theory For Analysis, Theory For Understanding, Model, Framework, Guidelines, Case Study, Grounded Theory, Questionnaire, Experiment, Action Research"
